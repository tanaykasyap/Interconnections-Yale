{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projects to process: [1231, 1247, 1257, 1261, 1266, 1274, 1276, 1279, 1280, 1289, 1290, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347]\n",
      "\n",
      "--- Processing project 1231 ---\n",
      "No Appendix A PDF (original or addendum) found for project 1231.\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1247\n",
      "\n",
      "--- Processing project 1257 ---\n",
      "No Appendix A PDF (original or addendum) found for project 1257.\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1261\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1266\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1274\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1276\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1279\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1280\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1289\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1290\n",
      "\n",
      "--- Processing project 1295 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1295\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.9295', '-116.5720')\n",
      "Base data extracted:\n",
      "{'q_id': ['1295'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.9295'], 'longitude': ['-116.5720'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Devers 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-Addendum_AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1295\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1295'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': [None]}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-Atchmnt2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-Addendum_AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-Addendum_AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-Atchmnt1_Addendum.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1295/02_phase_1_study/C9PI-SCE-Eastern-Q1295-Atchmnt1_Addendum.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1296 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1296\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.4940', '-113.0324')\n",
      "Base data extracted:\n",
      "{'q_id': ['1296'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.4940'], 'longitude': ['-113.0324'], 'capacity': [None], 'point_of_interconnection': ['Delaney-Colorado River 500 kV T/L']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Addendum_AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1296\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1296'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': [None]}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Atchmnt2_SDGE.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Atchmnt2_SDGE.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Atchmnt2_SCE.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Atchmnt2_SCE.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/Q1296-TOT834_Eastern_Attachment 2_C9P1_Addendum.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/Q1296-TOT834_Eastern_Attachment 2_C9P1_Addendum.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Atchmnt2_DCR.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Atchmnt2_DCR.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Addendum_AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Addendum_AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Addendum_Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Addendum_Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1296/02_phase_1_study/C9PI-SCE-Eastern-Q1296-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1297 ---\n",
      "No original Appendix A PDF found for project 1297. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1297\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.589', '-114.7853')\n",
      "Base data extracted:\n",
      "{'q_id': ['1297'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.589'], 'longitude': ['-114.7853'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Colorado River 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1297/02_phase_1_study/C9PI-SCE-Eastern-Q1297-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1297\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.589', '-114.7853')\n",
      "Base data extracted:\n",
      "{'q_id': ['1297'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.589'], 'longitude': ['-114.7853'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Colorado River 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1297/02_phase_1_study/C9PI-SCE-Eastern-Q1297-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1297/02_phase_1_study/C9PI-SCE-Eastern-Q1297-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1297/02_phase_1_study/C9PI-SCE-Eastern-Q1297-Atchmnt1_Revision.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1297/02_phase_1_study/C9PI-SCE-Eastern-Q1297-Atchmnt1_Revision.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1297/02_phase_1_study/Q1297-TOT794_Eastern_Attachment 2_C9P1 Revision1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1297/02_phase_1_study/Q1297-TOT794_Eastern_Attachment 2_C9P1 Revision1.pdf\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1298\n",
      "\n",
      "--- Processing project 1299 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1299\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.9410972', '-117.057561')\n",
      "Base data extracted:\n",
      "{'q_id': ['1299'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.9410972'], 'longitude': ['-117.057561'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s El Casco 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299-Addendum_AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1299\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1299'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': [None]}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299-Atchmnt2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299-Addendum_AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299-Addendum_AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299_Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299_Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299_Atchmnt1_Addendum.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1299/02_phase_1_study/C9PI-SCE-Eastern-Q1299_Atchmnt1_Addendum.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1300 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9PI-SCE-Eastern-Q1300-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1300\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.950260', '-116.571511')\n",
      "Base data extracted:\n",
      "{'q_id': ['1300'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.950260'], 'longitude': ['-116.571511'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Devers 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "Attempting to update base data from: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9P1-Q1300-Eastern-Addedum_AppendixA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1300\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1300'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': [None]}\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9PI-SCE-Eastern-Q1300-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9PI-SCE-Eastern-Q1300-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9PI-SCE-Eastern-Q1300-Atchmnt1_Addendum.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9PI-SCE-Eastern-Q1300-Atchmnt1_Addendum.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9PI-SCE-Eastern-Q1300-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9PI-SCE-Eastern-Q1300-Atchmnt2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9PI-SCE-Eastern-Q1300-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9PI-SCE-Eastern-Q1300-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9P1-Q1300-Eastern-Addedum_AppendixA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1300/02_phase_1_study/C9P1-Q1300-Eastern-Addedum_AppendixA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1301 ---\n",
      "No original Appendix A PDF found for project 1301. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1301\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.794', '-115.342')\n",
      "Base data extracted:\n",
      "{'q_id': ['1301'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.794'], 'longitude': ['-115.342'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Red Bluff 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1301/02_phase_1_study/C9PI-SCE-Eastern-Q1301-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1301\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.794', '-115.342')\n",
      "Base data extracted:\n",
      "{'q_id': ['1301'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.794'], 'longitude': ['-115.342'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Red Bluff 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1301/02_phase_1_study/C9PI-SCE-Eastern-Q1301-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1301/02_phase_1_study/C9PI-SCE-Eastern-Q1301-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1301/02_phase_1_study/C9PI-SCE-Eastern-Q1301-Atchmnt1_Revision.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1301/02_phase_1_study/C9PI-SCE-Eastern-Q1301-Atchmnt1_Revision.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1301/02_phase_1_study/Q1301-TOT825_Eastern_Attachment 2_C9P1 Revision.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1301/02_phase_1_study/Q1301-TOT825_Eastern_Attachment 2_C9P1 Revision.pdf\n",
      "\n",
      "--- Processing project 1302 ---\n",
      "No original Appendix A PDF found for project 1302. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1302\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.710169', '-115.267583')\n",
      "Base data extracted:\n",
      "{'q_id': ['1302'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.710169'], 'longitude': ['-115.267583'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Red Bluff 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1302/02_phase_1_study/C9PI-SCE-Eastern-Q1302-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1302\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('33.710169', '-115.267583')\n",
      "Base data extracted:\n",
      "{'q_id': ['1302'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['33.710169'], 'longitude': ['-115.267583'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Red Bluff 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1302/02_phase_1_study/Q1302-TOT830_Eastern_Attachment 2_C9P1 Revision.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1302/02_phase_1_study/Q1302-TOT830_Eastern_Attachment 2_C9P1 Revision.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1302/02_phase_1_study/C9PI-SCE-Eastern-Q1302-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1302/02_phase_1_study/C9PI-SCE-Eastern-Q1302-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1302/02_phase_1_study/C9PI-SCE-Eastern-Q1302-Atchmnt1_Revision.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1302/02_phase_1_study/C9PI-SCE-Eastern-Q1302-Atchmnt1_Revision.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1303\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1304\n",
      "\n",
      "--- Processing project 1305 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-AppndxA_NOL_Calcite Solar 1.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1305\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1305'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['100 MW Solar: Fifty-five (55) 1.872 MW at 0.95 power factor']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-AppndxA_2017.02.24_Addendum_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1305\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1305'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': [None]}\n",
      "Missing base data columns in first Appendix A PDF: ['latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-Atchmnt1_20170217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-Atchmnt1_20170217_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-AppndxA_2017.02.24_Addendum_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-AppndxA_2017.02.24_Addendum_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/Q1305-TOT786_NOL_Attachment 2_C9P1_Addendum_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/Q1305-TOT786_NOL_Attachment 2_C9P1_Addendum_Final.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-Atchmnt1_NOL_Calcite Solar 1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-Atchmnt1_NOL_Calcite Solar 1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-AppndxA_NOL_Calcite Solar 1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1305/02_phase_1_study/C9PI-Q1305-AppndxA_NOL_Calcite Solar 1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1306 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-AppndxA_NOL_Ghost Town Solar.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1306\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1306'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Kramer 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-RevisedAppndxA_2017.02.27_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1306\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1306'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Kramer 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-Atchmnt1_NOL_Ghost Town Solar.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-Atchmnt1_NOL_Ghost Town Solar.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-RevisedAppndxA_2017.02.27_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-RevisedAppndxA_2017.02.27_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/Q1306-TOT792_NOL_Attachment 2_C9P1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/Q1306-TOT792_NOL_Attachment 2_C9P1.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/Q1306-TOT792_NOL_Attachment 2_C9P1 Revision 022217_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/Q1306-TOT792_NOL_Attachment 2_C9P1 Revision 022217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/Q1306-TOT792_NOL_Attachment 2_C9P1 Revision 022217_Final.pdf flagged as addendum.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-Atchmnt1_20170217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-Atchmnt1_20170217_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-AppndxA_NOL_Ghost Town Solar.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1306/02_phase_1_study/C9PI-Q1306-AppndxA_NOL_Ghost Town Solar.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1307 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-AppndxA_NOL_Sand Solar.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1307\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.059', '-117.563')\n",
      "Base data extracted:\n",
      "{'q_id': ['1307'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': ['35.059'], 'longitude': ['-117.563'], 'capacity': [None], 'point_of_interconnection': ['Kramer 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-RevisedAppndxA_2017.02.27_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1307\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.059', '-117.563')\n",
      "Base data extracted:\n",
      "{'q_id': ['1307'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': ['35.059'], 'longitude': ['-117.563'], 'capacity': [None], 'point_of_interconnection': ['Kramer 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-RevisedAppndxA_2017.02.27_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-RevisedAppndxA_2017.02.27_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-Atchmnt1_20170217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-Atchmnt1_20170217_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/Q1307-TOT820_NOL_Attachment 2_C9P1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/Q1307-TOT820_NOL_Attachment 2_C9P1.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/Q1307-TOT820_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/Q1307-TOT820_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/Q1307-TOT820_NOL_Attachment 2_C9P1 Revision022217_Final.pdf flagged as addendum.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-Atchmnt1_NOL_Sand Solar.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-Atchmnt1_NOL_Sand Solar.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-AppndxA_NOL_Sand Solar.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1307/02_phase_1_study/C9PI-Q1307-AppndxA_NOL_Sand Solar.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1308 ---\n",
      "No original Appendix A PDF found for project 1308. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1308\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1308'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Coolwater 115 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/C9PI-Q1308-RevisedAppndxA_2017.02.17_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1308\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1308'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Coolwater 115 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/C9P1-VEA-Q1308-Barstow Solar-Appendix A-Attachment 2_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/C9P1-VEA-Q1308-Barstow Solar-Appendix A-Attachment 2_Final.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/C9PI-Q1308-RevisedAppndxA_2017.02.17_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/C9PI-Q1308-RevisedAppndxA_2017.02.17_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/Q1308-SCE_TOT808_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/Q1308-SCE_TOT808_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/Q1308-SCE_TOT808_NOL_Attachment 2_C9P1 Revision022217_Final.pdf flagged as addendum.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/C9PI-Q1308-Atchmnt1_20170228_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1308/02_phase_1_study/C9PI-Q1308-Atchmnt1_20170228_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1309 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-AppndxA_NOL_SEGS10 Solar.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1309\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1309'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Kramer 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-RevisedAppndxA_2017.02.17_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1309\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1309'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Kramer 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-AppndxA_NOL_SEGS10 Solar.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-AppndxA_NOL_SEGS10 Solar.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/Q1309-TOT805_NOL_Attachment 2_C9P1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/Q1309-TOT805_NOL_Attachment 2_C9P1.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-Atchmnt1_NOL_SEGS 10 Solar.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-Atchmnt1_NOL_SEGS 10 Solar.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-Atchmnt1_20170217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-Atchmnt1_20170217_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/Q1309-TOT805_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/Q1309-TOT805_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/Q1309-TOT805_NOL_Attachment 2_C9P1 Revision022217_Final.pdf flagged as addendum.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-RevisedAppndxA_2017.02.17_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1309/02_phase_1_study/C9PI-Q1309-RevisedAppndxA_2017.02.17_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1310 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-AppndxA_NOL_Coso Solar 2.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1310\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('36.078264', '-117.95')\n",
      "Base data extracted:\n",
      "{'q_id': ['1310'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': ['36.078264'], 'longitude': ['-117.95'], 'capacity': [None], 'point_of_interconnection': ['Inyokern 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-RevisedAppndxA_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1310\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('36.078264', '-117.95')\n",
      "Base data extracted:\n",
      "{'q_id': ['1310'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': ['36.078264'], 'longitude': ['-117.95'], 'capacity': [None], 'point_of_interconnection': ['Inyokern 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-AppndxA_NOL_Coso Solar 2.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-AppndxA_NOL_Coso Solar 2.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-Atchmnt1_NOL_Coso Solar 2.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-Atchmnt1_NOL_Coso Solar 2.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/Q1310-TOT803_NOL_Attachment 2_C9P1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/Q1310-TOT803_NOL_Attachment 2_C9P1.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-RevisedAppndxA_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-RevisedAppndxA_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-Atchmnt1_20170217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/C9PI-Q1310-Atchmnt1_20170217_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/Q1310-TOT803_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/Q1310-TOT803_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1310/02_phase_1_study/Q1310-TOT803_NOL_Attachment 2_C9P1 Revision022217_Final.pdf flagged as addendum.\n",
      "\n",
      "--- Processing project 1311 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1311/02_phase_1_study/C9PI-Q1311-AppndxA_NOL_Coso Solar 1.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1311\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('36.019909', '-117.88')\n",
      "Base data extracted:\n",
      "{'q_id': ['1311'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': ['36.019909'], 'longitude': ['-117.88'], 'capacity': [None], 'point_of_interconnection': ['Inyokern 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1311/02_phase_1_study/C9PI-Q1311-Atchmnt1_NOL_Coso Solar 1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1311/02_phase_1_study/C9PI-Q1311-Atchmnt1_NOL_Coso Solar 1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1311/02_phase_1_study/C9PI-Q1311-AppndxA_NOL_Coso Solar 1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1311/02_phase_1_study/C9PI-Q1311-AppndxA_NOL_Coso Solar 1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1311/02_phase_1_study/Q1311-TOT802_NOL_Attachment 2_C9P1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1311/02_phase_1_study/Q1311-TOT802_NOL_Attachment 2_C9P1.pdf\n",
      "\n",
      "--- Processing project 1312 ---\n",
      "No original Appendix A PDF found for project 1312. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1312\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: ected\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1312'], 'cluster': ['9'], 'req_deliverability': ['ected'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Coolwater 115 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/C9PI-Q1312-RevisedAppndxA_2017.02.22_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1312\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: ected\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1312'], 'cluster': ['9'], 'req_deliverability': ['ected'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Coolwater 115 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/Q1312-TOT812_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/Q1312-TOT812_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/Q1312-TOT812_NOL_Attachment 2_C9P1 Revision022217_Final.pdf flagged as addendum.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/C9PI-Q1312-RevisedAppndxA_2017.02.22_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/C9PI-Q1312-RevisedAppndxA_2017.02.22_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/C9PI-Q1312-Atchmnt1_20170224_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/C9PI-Q1312-Atchmnt1_20170224_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/C9PI-Q1312-Atchmnt1_NOL_Coolwater Solar 3.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/C9PI-Q1312-Atchmnt1_NOL_Coolwater Solar 3.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/Q1312-TOT812_NOL_Attachment 2_C9P1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1312/02_phase_1_study/Q1312-TOT812_NOL_Attachment 2_C9P1.pdf\n",
      "\n",
      "--- Processing project 1313 ---\n",
      "No original Appendix A PDF found for project 1313. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1313\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1313'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Coolwater 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/C9PI-Q1313-RevisedAppndxA_2017.02.22_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1313\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1313'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Coolwater 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/C9PI-Q1313-Atchmnt1_20170224_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/C9PI-Q1313-Atchmnt1_20170224_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/C9PI-Q1313-Atchmnt1_NOL_Coolwater Solar 2.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/C9PI-Q1313-Atchmnt1_NOL_Coolwater Solar 2.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/Q1313-TOT811_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/Q1313-TOT811_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/Q1313-TOT811_NOL_Attachment 2_C9P1 Revision022217_Final.pdf flagged as addendum.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/C9PI-Q1313-RevisedAppndxA_2017.02.22_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/C9PI-Q1313-RevisedAppndxA_2017.02.22_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/Q1313-TOT811_NOL_Attachment 2_C9P1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1313/02_phase_1_study/Q1313-TOT811_NOL_Attachment 2_C9P1.pdf\n",
      "\n",
      "--- Processing project 1314 ---\n",
      "No original Appendix A PDF found for project 1314. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1314\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1314'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Kramer 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/C9PI-Q1314-RevisedAppndxA_2017.02.22_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1314\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1314'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Kramer 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/Q1314-TOT810_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/Q1314-TOT810_NOL_Attachment 2_C9P1 Revision022217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/Q1314-TOT810_NOL_Attachment 2_C9P1 Revision022217_Final.pdf flagged as addendum.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/Q1314-TOT810_NOL_Attachment 2_C9P1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/Q1314-TOT810_NOL_Attachment 2_C9P1.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/C9PI-Q1314-Atchmnt1_NOL_Coolwater Solar 1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/C9PI-Q1314-Atchmnt1_NOL_Coolwater Solar 1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/C9PI-Q1314-RevisedAppndxA_2017.02.22_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/C9PI-Q1314-RevisedAppndxA_2017.02.22_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/C9PI-Q1314-Atchmnt1_20170224_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1314/02_phase_1_study/C9PI-Q1314-Atchmnt1_20170224_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1315 ---\n",
      "No original Appendix A PDF found for project 1315. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1315\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1315'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': [None]}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/C9PI-Q1315-RevisedAppndxA_2017.02.17_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1315\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1315'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': [None]}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection']\n",
      "After update, still missing: ['req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/C9PI-Q1315-Atchmnt1_NOL_Waller Solar Farm.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/C9PI-Q1315-Atchmnt1_NOL_Waller Solar Farm.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/Q1315-TOT829_NOL_Attachment 2_C9P1 Addendum022217_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/Q1315-TOT829_NOL_Attachment 2_C9P1 Addendum022217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/Q1315-TOT829_NOL_Attachment 2_C9P1 Addendum022217_Final.pdf flagged as addendum.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/Q1315-TOT829_NOL_Attachment 2_C9P1.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/Q1315-TOT829_NOL_Attachment 2_C9P1.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/C9PI-Q1315-RevisedAppndxA_2017.02.17_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/C9PI-Q1315-RevisedAppndxA_2017.02.17_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/C9PI-Q1315-Atchmnt1_20170217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1315/02_phase_1_study/C9PI-Q1315-Atchmnt1_20170217_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1316 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9PI-Q1316-AppndxA_NOL_High Desert View Solar Project.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1316\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.469558', '116.9')\n",
      "Base data extracted:\n",
      "{'q_id': ['1316'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.469558'], 'longitude': ['116.9'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Proposed Calcite 220 kV Switchrack']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9P1-Q1316-NOL-Addedum_AppendixA_Final.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1316\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1316'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': [None]}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9PI-Q1316-Atchmnt1_20170217_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9PI-Q1316-Atchmnt1_20170217_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/Q1316-TOT838_NOL_Attachment 2_C9P1_Addendum_Final.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/Q1316-TOT838_NOL_Attachment 2_C9P1_Addendum_Final.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9P1-Q1316-NOL-Addedum_AppendixA_Final.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9P1-Q1316-NOL-Addedum_AppendixA_Final.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9PI-Q1316-AppndxA_NOL_High Desert View Solar Project.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9PI-Q1316-AppndxA_NOL_High Desert View Solar Project.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9PI-Q1316-Atchmnt1_NOL_High Desert View Solar.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1316/02_phase_1_study/C9PI-Q1316-Atchmnt1_NOL_High Desert View Solar.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1317 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1317\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.110691', '-118.383076')\n",
      "Base data extracted:\n",
      "{'q_id': ['1317'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['35.110691'], 'longitude': ['-118.383076'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Highwind Substation 220 kV bus']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1317\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.110691', '-118.383076')\n",
      "Base data extracted:\n",
      "{'q_id': ['1317'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['35.110691'], 'longitude': ['-118.383076'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Highwind Substation 220 kV bus']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-RevisedAttachment 2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1317/02_phase_1_study/C9P1-SCE-Northern-Q1317-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1318 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1318\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.87', '-118.3786')\n",
      "Base data extracted:\n",
      "{'q_id': ['1318'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.87'], 'longitude': ['-118.3786'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1318\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.87', '-118.3786')\n",
      "Base data extracted:\n",
      "{'q_id': ['1318'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.87'], 'longitude': ['-118.3786'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-RevisedAttachment 2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1318/02_phase_1_study/C9P1-SCE-Northern-Q1318-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1319 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1319\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.87', '-118.3786')\n",
      "Base data extracted:\n",
      "{'q_id': ['1319'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.87'], 'longitude': ['-118.3786'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1319\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.87', '-118.3786')\n",
      "Base data extracted:\n",
      "{'q_id': ['1319'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.87'], 'longitude': ['-118.3786'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-RevisedAttachment 2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1319/02_phase_1_study/C9P1-SCE-Northern-Q1319-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1320 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1320\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.031', '-118.085')\n",
      "Base data extracted:\n",
      "{'q_id': ['1320'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['35.031'], 'longitude': ['-118.085'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Windhub Substation 220 kV bus']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1320\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.031', '-118.085')\n",
      "Base data extracted:\n",
      "{'q_id': ['1320'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['35.031'], 'longitude': ['-118.085'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Windhub Substation 220 kV bus']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1320/02_phase_1_study/C9P1-SCE-Northern-Q1320-RevisedAttachment 2.pdf\n",
      "\n",
      "--- Processing project 1321 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1321/02_phase_1_study/C9P1-SCE-Northern-Q1321-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1321\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.8419', '-119.0811')\n",
      "Base data extracted:\n",
      "{'q_id': ['1321'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': ['35.8419'], 'longitude': ['-119.0811'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Vestal Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1321/02_phase_1_study/C9P1-SCE-Northern-Q1321-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1321/02_phase_1_study/C9P1-SCE-Northern-Q1321-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1321/02_phase_1_study/C9P1-SCE-Northern-Q1321-AppndxA-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1321/02_phase_1_study/C9P1-SCE-Northern-Q1321-AppndxA-Atchmnt2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1321/02_phase_1_study/C9P1-SCE-Northern-Q1321-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1321/02_phase_1_study/C9P1-SCE-Northern-Q1321-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1322 ---\n",
      "No original Appendix A PDF found for project 1322. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1322\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.84166', '-118.4551')\n",
      "Base data extracted:\n",
      "{'q_id': ['1322'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.84166'], 'longitude': ['-118.4551'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1322/02_phase_1_study/C9P1-SCE-Northern-Q1322-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1322\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.84166', '-118.4551')\n",
      "Base data extracted:\n",
      "{'q_id': ['1322'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.84166'], 'longitude': ['-118.4551'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1322/02_phase_1_study/C9P1-SCE-Northern-Q1322-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1322/02_phase_1_study/C9P1-SCE-Northern-Q1322-RevisedAttachment 2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1322/02_phase_1_study/C9P1-SCE-Northern-Q1322-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1322/02_phase_1_study/C9P1-SCE-Northern-Q1322-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1322/02_phase_1_study/C9P1-SCE-Northern-Q1322-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1322/02_phase_1_study/C9P1-SCE-Northern-Q1322-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1323 ---\n",
      "No original Appendix A PDF found for project 1323. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1323\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.84166', '-118.4551')\n",
      "Base data extracted:\n",
      "{'q_id': ['1323'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.84166'], 'longitude': ['-118.4551'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1323/02_phase_1_study/C9P1-SCE-Northern-Q1323-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1323\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.84166', '-118.4551')\n",
      "Base data extracted:\n",
      "{'q_id': ['1323'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.84166'], 'longitude': ['-118.4551'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1323/02_phase_1_study/C9P1-SCE-Northern-Q1323-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1323/02_phase_1_study/C9P1-SCE-Northern-Q1323-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1323/02_phase_1_study/C9P1-SCE-Northern-Q1323-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1323/02_phase_1_study/C9P1-SCE-Northern-Q1323-RevisedAttachment 2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1323/02_phase_1_study/C9P1-SCE-Northern-Q1323-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1323/02_phase_1_study/C9P1-SCE-Northern-Q1323-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1324 ---\n",
      "No Appendix A PDF (original or addendum) found for project 1324.\n",
      "\n",
      "--- Processing project 1325 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1325/02_phase_1_study/C9P1-SCE-Northern-Q1325-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1325\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.018693', '-118.212211')\n",
      "Base data extracted:\n",
      "{'q_id': ['1325'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['35.018693'], 'longitude': ['-118.212211'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Vincent 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1325/02_phase_1_study/C9P1-SCE-Northern-Q1325-AppndxA-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1325/02_phase_1_study/C9P1-SCE-Northern-Q1325-AppndxA-Atchmnt2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1325/02_phase_1_study/C9P1-SCE-Northern-Q1325-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1325/02_phase_1_study/C9P1-SCE-Northern-Q1325-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1325/02_phase_1_study/C9P1-SCE-Northern-Q1325-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1325/02_phase_1_study/C9P1-SCE-Northern-Q1325-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1326 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1326/02_phase_1_study/C9P1-SCE-Northern-Q1326-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1326\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.9565663889', '-18.25609166')\n",
      "Base data extracted:\n",
      "{'q_id': ['1326'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.9565663889'], 'longitude': ['-18.25609166'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Vincent 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1326/02_phase_1_study/C9P1-SCE-Northern-Q1326-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1326/02_phase_1_study/C9P1-SCE-Northern-Q1326-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1326/02_phase_1_study/C9P1-SCE-Northern-Q1326-AppndxA-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1326/02_phase_1_study/C9P1-SCE-Northern-Q1326-AppndxA-Atchmnt2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1326/02_phase_1_study/C9P1-SCE-Northern-Q1326-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1326/02_phase_1_study/C9P1-SCE-Northern-Q1326-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1327 ---\n",
      "No original Appendix A PDF found for project 1327. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1327\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.831219', '-118.365769')\n",
      "Base data extracted:\n",
      "{'q_id': ['1327'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.831219'], 'longitude': ['-118.365769'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1327/02_phase_1_study/C9P1-SCE-Northern-Q1327-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1327\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.831219', '-118.365769')\n",
      "Base data extracted:\n",
      "{'q_id': ['1327'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.831219'], 'longitude': ['-118.365769'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1327/02_phase_1_study/C9P1-SCE-Northern-Q1327-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1327/02_phase_1_study/C9P1-SCE-Northern-Q1327-RevisedAttachment 2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1327/02_phase_1_study/C9P1-SCE-Northern-Q1327-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1327/02_phase_1_study/C9P1-SCE-Northern-Q1327-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1327/02_phase_1_study/C9P1-SCE-Northern-Q1327-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1327/02_phase_1_study/C9P1-SCE-Northern-Q1327-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1328 ---\n",
      "No original Appendix A PDF found for project 1328. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1328\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.875672', '-118.319569')\n",
      "Base data extracted:\n",
      "{'q_id': ['1328'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.875672'], 'longitude': ['-118.319569'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1328/02_phase_1_study/C9P1-SCE-Northern-Q1328-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1328\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.875672', '-118.319569')\n",
      "Base data extracted:\n",
      "{'q_id': ['1328'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.875672'], 'longitude': ['-118.319569'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1328/02_phase_1_study/C9P1-SCE-Northern-Q1328-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1328/02_phase_1_study/C9P1-SCE-Northern-Q1328-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1328/02_phase_1_study/C9P1-SCE-Northern-Q1328-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1328/02_phase_1_study/C9P1-SCE-Northern-Q1328-RevisedAttachment 2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1328/02_phase_1_study/C9P1-SCE-Northern-Q1328-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1328/02_phase_1_study/C9P1-SCE-Northern-Q1328-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1329 ---\n",
      "No original Appendix A PDF found for project 1329. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1329\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.986843', '-118.')\n",
      "Base data extracted:\n",
      "{'q_id': ['1329'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.986843'], 'longitude': ['-118.'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1329/02_phase_1_study/C9P1-SCE-Northern-Q1329-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1329\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.986843', '-118.')\n",
      "Base data extracted:\n",
      "{'q_id': ['1329'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.986843'], 'longitude': ['-118.'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1329/02_phase_1_study/C9P1-SCE-Northern-Q1329-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1329/02_phase_1_study/C9P1-SCE-Northern-Q1329-RevisedAttachment 2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1329/02_phase_1_study/C9P1-SCE-Northern-Q1329-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1329/02_phase_1_study/C9P1-SCE-Northern-Q1329-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1329/02_phase_1_study/C9P1-SCE-Northern-Q1329-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1329/02_phase_1_study/C9P1-SCE-Northern-Q1329-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1330 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1330\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.692326', '-118.367667')\n",
      "Base data extracted:\n",
      "{'q_id': ['1330'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.692326'], 'longitude': ['-118.367667'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Antelope 66 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt8.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt8.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt2A.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt2A.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1330/02_phase_1_study/C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt2.pdf\n",
      "\n",
      "--- Processing project 1331 ---\n",
      "No original Appendix A PDF found for project 1331. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1331\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.220792', '-117.977442')\n",
      "Base data extracted:\n",
      "{'q_id': ['1331'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': ['35.220792'], 'longitude': ['-117.977442'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Windhub 220 kV']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1331/02_phase_1_study/C9P1-SCE-Northern-Q1331-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1331\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: elected\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.220792', '-117.977442')\n",
      "Base data extracted:\n",
      "{'q_id': ['1331'], 'cluster': ['9'], 'req_deliverability': ['elected'], 'latitude': ['35.220792'], 'longitude': ['-117.977442'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Windhub 220 kV']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1331/02_phase_1_study/C9P1-SCE-Northern-Q1331-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1331/02_phase_1_study/C9P1-SCE-Northern-Q1331-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1331/02_phase_1_study/C9P1-SCE-Northern-Q1331-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1331/02_phase_1_study/C9P1-SCE-Northern-Q1331-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1331/02_phase_1_study/C9P1-SCE-Northern-Q1331-Revised_Attachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1331/02_phase_1_study/C9P1-SCE-Northern-Q1331-Revised_Attachment 2.pdf\n",
      "\n",
      "--- Processing project 1332 ---\n",
      "No original Appendix A PDF found for project 1332. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1332\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.290619', '-118.002203')\n",
      "Base data extracted:\n",
      "{'q_id': ['1332'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['35.290619'], 'longitude': ['-118.002203'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1332/02_phase_1_study/C9P1-SCE-Northern-Q1332-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1332\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.290619', '-118.002203')\n",
      "Base data extracted:\n",
      "{'q_id': ['1332'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['35.290619'], 'longitude': ['-118.002203'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1332/02_phase_1_study/C9P1-SCE-Northern-Q1332-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1332/02_phase_1_study/C9P1-SCE-Northern-Q1332-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1332/02_phase_1_study/C9P1-SCE-Northern-Q1332-RevisedAttachment 2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1332/02_phase_1_study/C9P1-SCE-Northern-Q1332-RevisedAttachment 2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1332/02_phase_1_study/C9P1-SCE-Northern-Q1332-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1332/02_phase_1_study/C9P1-SCE-Northern-Q1332-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1333 ---\n",
      "No original Appendix A PDF found for project 1333. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1333\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.880725', '-118.531746')\n",
      "Base data extracted:\n",
      "{'q_id': ['1333'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.880725'], 'longitude': ['-118.531746'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1333/02_phase_1_study/C9P1-SCE-Northern-Q1333-RevisedAppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1333\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.880725', '-118.531746')\n",
      "Base data extracted:\n",
      "{'q_id': ['1333'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['34.880725'], 'longitude': ['-118.531746'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Whirlwind 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1333/02_phase_1_study/C9P1-SCE-Northern-Q1333-AppndxA-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1333/02_phase_1_study/C9P1-SCE-Northern-Q1333-AppndxA-Atchmnt2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1333/02_phase_1_study/C9P1-SCE-Northern-Q1333-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1333/02_phase_1_study/C9P1-SCE-Northern-Q1333-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1333/02_phase_1_study/C9P1-SCE-Northern-Q1333-RevisedAppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1333/02_phase_1_study/C9P1-SCE-Northern-Q1333-RevisedAppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1334 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1334/02_phase_1_study/C9P1-SCE-Northern-Q1334-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1334\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1334'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Santa Clara 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1334/02_phase_1_study/C9P1-SCE-Northern-Q1334-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1334/02_phase_1_study/C9P1-SCE-Northern-Q1334-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1334/02_phase_1_study/C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1334/02_phase_1_study/C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1334/02_phase_1_study/C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1334/02_phase_1_study/C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1334/02_phase_1_study/C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt2A.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1334/02_phase_1_study/C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt2A.pdf\n",
      "\n",
      "--- Processing project 1335 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1335/02_phase_1_study/C9P1-SCE-Northern-Q1335-AppndxA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1335\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('34.955231', '-118.864169')\n",
      "Base data extracted:\n",
      "{'q_id': ['1335'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': ['34.955231'], 'longitude': ['-118.864169'], 'capacity': [None], 'point_of_interconnection': ['Participating TO\u2019s Pastoria 220 kV Substation']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1335/02_phase_1_study/C9P1-SCE-Northern-Q1335-AppndxA-Atchmnt1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1335/02_phase_1_study/C9P1-SCE-Northern-Q1335-AppndxA-Atchmnt1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1335/02_phase_1_study/C9P1-SCE-Northern-Q1335-AppndxA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1335/02_phase_1_study/C9P1-SCE-Northern-Q1335-AppndxA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1335/02_phase_1_study/C9P1-SCE-Northern-Q1335-AppndxA-Atchmnt2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1335/02_phase_1_study/C9P1-SCE-Northern-Q1335-AppndxA-Atchmnt2.pdf\n",
      "\n",
      "--- Processing project 1336 ---\n",
      "No original Appendix A PDF found for project 1336. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1336\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.0878', '-114.6683')\n",
      "Base data extracted:\n",
      "{'q_id': ['1336'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['35.0878'], 'longitude': ['-114.6683'], 'capacity': [None], 'point_of_interconnection': ['Mohave Switchyard']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1336/02_phase_1_study/C9P1-SCE-EOP-Q1336-AppendixA-Revision01.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1336\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: Full\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.0878', '-114.6683')\n",
      "Base data extracted:\n",
      "{'q_id': ['1336'], 'cluster': ['9'], 'req_deliverability': ['Full'], 'latitude': ['35.0878'], 'longitude': ['-114.6683'], 'capacity': [None], 'point_of_interconnection': ['Mohave Switchyard']}\n",
      "Missing base data columns in first Appendix A PDF: ['capacity']\n",
      "After update, still missing: ['capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1336/02_phase_1_study/C9P1-SCE-EOP-Q1336-AppendixA-Attachment2-Revision01.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1336/02_phase_1_study/C9P1-SCE-EOP-Q1336-AppendixA-Attachment2-Revision01.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1336/02_phase_1_study/C9P1-SCE-EOP-Q1336-AppendixA-Revision01.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1336/02_phase_1_study/C9P1-SCE-EOP-Q1336-AppendixA-Revision01.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1336/02_phase_1_study/C9PI-SCE-EOP-Q1336-AppendixA-Attachment1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1336/02_phase_1_study/C9PI-SCE-EOP-Q1336-AppendixA-Attachment1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1336/02_phase_1_study/C9P1-SCE-EOP-Q1336-AppendixA-Attachment1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1336/02_phase_1_study/C9P1-SCE-EOP-Q1336-AppendixA-Attachment1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1337\n",
      "\n",
      "--- Processing project 1338 ---\n",
      "No original Appendix A PDF found for project 1338. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1338\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1338'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Participating TO-owned Eldorado 220 kV Switchyard']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1338/02_phase_1_study/C9P1-SCE-EOP-Q1338-AppendixA-Revision01.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1338\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1338'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Participating TO-owned Eldorado 220 kV Switchyard']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1338/02_phase_1_study/C9P1-SCE-EOP-Q1338-AppendixA-Attachment2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1338/02_phase_1_study/C9P1-SCE-EOP-Q1338-AppendixA-Attachment2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1338/02_phase_1_study/C9P1-SCE-EOP-Q1338-AppendixA-Attachment1-Revision01.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1338/02_phase_1_study/C9P1-SCE-EOP-Q1338-AppendixA-Attachment1-Revision01.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1338/02_phase_1_study/C9P1-SCE-EOP-Q1338-AppendixA-Revision01.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1338/02_phase_1_study/C9P1-SCE-EOP-Q1338-AppendixA-Revision01.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1339 ---\n",
      "No original Appendix A PDF found for project 1339. Using addendum PDF for base data extraction.\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1339\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1339'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Participating TO-owned Eldorado 220 kV Switchyard']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1339/02_phase_1_study/C9P1-SCE-EOP-Q1339-AppendixA-Revision01.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1339\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "GPS coordinates not found.\n",
      "Base data extracted:\n",
      "{'q_id': ['1339'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': [None], 'longitude': [None], 'capacity': [None], 'point_of_interconnection': ['Participating TO-owned Eldorado 220 kV Switchyard']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'latitude', 'longitude', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'latitude', 'longitude', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1339/02_phase_1_study/C9P1-SCE-EOP-Q1339-AppendixA-Revision01.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1339/02_phase_1_study/C9P1-SCE-EOP-Q1339-AppendixA-Revision01.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1339/02_phase_1_study/C9P1-SCE-EOP-Q1339-AppendixA-Attachment2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1339/02_phase_1_study/C9P1-SCE-EOP-Q1339-AppendixA-Attachment2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1339/02_phase_1_study/C9P1-SCE-EOP-Q1339-AppendixA-Attachment1-Revision01.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1339/02_phase_1_study/C9P1-SCE-EOP-Q1339-AppendixA-Attachment1-Revision01.pdf\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1340\n",
      "\n",
      "--- Processing project 1341 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1341/02_phase_1_study/C9P1-VEA-EOP-Q1341-AppendixA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1341\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('36.0514', '-115.7519')\n",
      "Base data extracted:\n",
      "{'q_id': ['1341'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': ['36.0514'], 'longitude': ['-115.7519'], 'capacity': [None], 'point_of_interconnection': ['250 MW 0.5 miles, 795 kcmil Aluminum Conductor Steel']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1341/02_phase_1_study/C9P1-VEA-EOP-Q1341-AppendixA-Attachment2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1341/02_phase_1_study/C9P1-VEA-EOP-Q1341-AppendixA-Attachment2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1341/02_phase_1_study/C9P1-VEA-EOP-Q1341-AppendixA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1341/02_phase_1_study/C9P1-VEA-EOP-Q1341-AppendixA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1341/02_phase_1_study/C9P1-VEA-EOP-Q1341-AppendixA-Attachment1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1341/02_phase_1_study/C9P1-VEA-EOP-Q1341-AppendixA-Attachment1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1341/02_phase_1_study/C9P1-SCE-EOP-Q1341-AppendixA-Attachment2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1341/02_phase_1_study/C9P1-SCE-EOP-Q1341-AppendixA-Attachment2.pdf\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1342\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1343\n",
      "\n",
      "--- Processing project 1344 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-EOP-Q1344-AppendixA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1344\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('36.1627', '-115.8858')\n",
      "Base data extracted:\n",
      "{'q_id': ['1344'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': ['36.1627'], 'longitude': ['-115.8858'], 'capacity': [None], 'point_of_interconnection': ['700 MW 2.67 miles, 1590 kcmil Aluminum Conductor']}\n",
      "Scraped base data from addendum Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-Q1344-Copper Rays-Appendix A-revision-01.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1344\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('36.1627', '-115.8858')\n",
      "Base data extracted:\n",
      "{'q_id': ['1344'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': ['36.1627'], 'longitude': ['-115.8858'], 'capacity': [None], 'point_of_interconnection': ['700 MW 2.67 miles, 1590 kcmil Aluminum Conductor']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-Q1344-Copper Rays-Appendix A-Attachment 2_Revision-01.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-Q1344-Copper Rays-Appendix A-Attachment 2_Revision-01.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-Q1344-Copper Rays-Appendix A-Attachment 2_Revision-01.pdf flagged as addendum.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-Q1344-Copper Rays-Appendix A-Attachment 1-Revision-01.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-Q1344-Copper Rays-Appendix A-Attachment 1-Revision-01.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-SCE-VEA-EOP-Q1344-AppendixA-Attachment1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-SCE-VEA-EOP-Q1344-AppendixA-Attachment1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-SCE-EOP-Q1344-AppendixA-Attachment2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-SCE-EOP-Q1344-AppendixA-Attachment2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-EOP-Q1344-AppendixA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-EOP-Q1344-AppendixA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-Q1344-Copper Rays-Appendix A-revision-01.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1344/02_phase_1_study/C9P1-VEA-Q1344-Copper Rays-Appendix A-revision-01.pdf is not an Attachment 2 PDF. Skipping.\n",
      "\n",
      "--- Processing project 1345 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1345/02_phase_1_study/C9P1-VEA-EOP-Q1345-AppendixA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1345\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('36.5821', '-115.')\n",
      "Base data extracted:\n",
      "{'q_id': ['1345'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': ['36.5821'], 'longitude': ['-115.'], 'capacity': [None], 'point_of_interconnection': ['200 MW 0.5 miles, 1272 kcmil Aluminum Conductor']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1345/02_phase_1_study/C9P1-VEA-EOP-Q1345-AppendixA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1345/02_phase_1_study/C9P1-VEA-EOP-Q1345-AppendixA.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1345/02_phase_1_study/C9P1-SCE-EOP-Q1345-AppendixA-Attachment2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1345/02_phase_1_study/C9P1-SCE-EOP-Q1345-AppendixA-Attachment2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1345/02_phase_1_study/C9P1-SCE-VEA-EOP-Q1345-AppendixA-Attachment1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1345/02_phase_1_study/C9P1-SCE-VEA-EOP-Q1345-AppendixA-Attachment1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1345/02_phase_1_study/C9P1-VEA-EOP-Q1345-AppendixA-Attachment2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1345/02_phase_1_study/C9P1-VEA-EOP-Q1345-AppendixA-Attachment2.pdf\n",
      "Project folder not found: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1346\n",
      "\n",
      "--- Processing project 1347 ---\n",
      "Scraped base data from original Appendix A PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1347/02_phase_1_study/C9P1-VEA-EOP-Q1347-AppendixA.pdf\n",
      "Extracting base data from Appendix A PDF...\n",
      "Extracted Queue ID: 1347\n",
      "Extracted Cluster Number: 9\n",
      "Extracted Deliverability Status: None\n",
      "Extracted Capacity: None\n",
      "Found project coordinates: ('35.517564', '-115.152834')\n",
      "Base data extracted:\n",
      "{'q_id': ['1347'], 'cluster': ['9'], 'req_deliverability': [None], 'latitude': ['35.517564'], 'longitude': ['-115.152834'], 'capacity': [None], 'point_of_interconnection': ['309.4 MW 22 miles, 593 kcmil duplex All Aluminum Alloy']}\n",
      "Missing base data columns in first Appendix A PDF: ['req_deliverability', 'capacity']\n",
      "After update, still missing: ['req_deliverability', 'capacity']\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1347/02_phase_1_study/C9P1-SCE-EOP-Q1347-AppendixA-Attachment2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1347/02_phase_1_study/C9P1-SCE-EOP-Q1347-AppendixA-Attachment2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1347/02_phase_1_study/C9P1-SCE-VEA-EOP-Q1347-AppendixA-Attachment1.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1347/02_phase_1_study/C9P1-SCE-VEA-EOP-Q1347-AppendixA-Attachment1.pdf is not an Attachment 2 PDF. Skipping.\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1347/02_phase_1_study/C9P1-VEA-EOP-Q1347-AppendixA-Attachment2.pdf\n",
      "Scraped this Attachment 2 PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1347/02_phase_1_study/C9P1-VEA-EOP-Q1347-AppendixA-Attachment2.pdf\n",
      "Accessing PDF: /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1347/02_phase_1_study/C9P1-VEA-EOP-Q1347-AppendixA.pdf\n",
      "--> /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/data/1347/02_phase_1_study/C9P1-VEA-EOP-Q1347-AppendixA.pdf is not an Attachment 2 PDF. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_2120/4181385699.py:651: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(clean_string_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns reordered for originals as per specification.\n",
      "\n",
      "Data successfully saved to /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/output/Cluster 9/03_raw/rawdata_cluster9_style_J_originals.csv\n",
      "\n",
      "Columns reordered for addendums as per specification.\n",
      "\n",
      "Data successfully saved to /Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/output/Cluster 9/03_raw/rawdata_cluster9_style_J_addendums.csv\n",
      "\n",
      "=== Scraping Summary ===\n",
      "Total Projects Processed: 44\n",
      "Total Projects Scraped: 44\n",
      "Total Projects Skipped: 0\n",
      "Total Projects Missing: 17\n",
      "Total PDFs Accessed: 182\n",
      "Total PDFs Scraped: 64\n",
      "Total PDFs Skipped: 118\n",
      "\n",
      "List of Scraped Projects: [1295, 1296, 1297, 1299, 1300, 1301, 1302, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1341, 1344, 1345, 1347]\n",
      "\n",
      "List of Skipped Projects: []\n",
      "\n",
      "List of Missing Projects: [1247, 1261, 1266, 1274, 1276, 1279, 1280, 1289, 1290, 1298, 1303, 1304, 1337, 1340, 1342, 1343, 1346]\n",
      "\n",
      "List of Scraped PDFs: ['C9PI-SCE-Eastern-Q1295-Atchmnt2.pdf', 'C9PI-SCE-Eastern-Q1296-Atchmnt2_SDGE.pdf', 'C9PI-SCE-Eastern-Q1296-Atchmnt2_SCE.pdf', 'Q1296-TOT834_Eastern_Attachment 2_C9P1_Addendum.pdf', 'C9PI-SCE-Eastern-Q1296-Atchmnt2_DCR.pdf', 'Q1297-TOT794_Eastern_Attachment 2_C9P1 Revision1.pdf', 'C9PI-SCE-Eastern-Q1299-Atchmnt2.pdf', 'C9PI-SCE-Eastern-Q1300-Atchmnt2.pdf', 'Q1301-TOT825_Eastern_Attachment 2_C9P1 Revision.pdf', 'Q1302-TOT830_Eastern_Attachment 2_C9P1 Revision.pdf', 'Q1305-TOT786_NOL_Attachment 2_C9P1_Addendum_Final.pdf', 'Q1306-TOT792_NOL_Attachment 2_C9P1.pdf', 'Q1306-TOT792_NOL_Attachment 2_C9P1 Revision 022217_Final.pdf', 'Q1307-TOT820_NOL_Attachment 2_C9P1.pdf', 'Q1307-TOT820_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'C9P1-VEA-Q1308-Barstow Solar-Appendix A-Attachment 2_Final.pdf', 'Q1308-SCE_TOT808_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1309-TOT805_NOL_Attachment 2_C9P1.pdf', 'Q1309-TOT805_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1310-TOT803_NOL_Attachment 2_C9P1.pdf', 'Q1310-TOT803_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1311-TOT802_NOL_Attachment 2_C9P1.pdf', 'Q1312-TOT812_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1312-TOT812_NOL_Attachment 2_C9P1.pdf', 'Q1313-TOT811_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1313-TOT811_NOL_Attachment 2_C9P1.pdf', 'Q1314-TOT810_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1314-TOT810_NOL_Attachment 2_C9P1.pdf', 'Q1315-TOT829_NOL_Attachment 2_C9P1 Addendum022217_Final.pdf', 'Q1315-TOT829_NOL_Attachment 2_C9P1.pdf', 'Q1316-TOT838_NOL_Attachment 2_C9P1_Addendum_Final.pdf', 'C9P1-SCE-Northern-Q1317-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1318-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1319-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1320-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1321-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1322-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1323-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1325-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1326-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1327-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1328-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1329-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt2A.pdf', 'C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1331-Revised_Attachment 2.pdf', 'C9P1-SCE-Northern-Q1332-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1333-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt2A.pdf', 'C9P1-SCE-Northern-Q1335-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-EOP-Q1336-AppendixA-Attachment2-Revision01.pdf', 'C9P1-SCE-EOP-Q1338-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1338-AppendixA-Attachment1-Revision01.pdf', 'C9P1-SCE-EOP-Q1339-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1339-AppendixA-Attachment1-Revision01.pdf', 'C9P1-VEA-EOP-Q1341-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1341-AppendixA-Attachment2.pdf', 'C9P1-VEA-Q1344-Copper Rays-Appendix A-Attachment 2_Revision-01.pdf', 'C9P1-SCE-EOP-Q1344-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1345-AppendixA-Attachment2.pdf', 'C9P1-VEA-EOP-Q1345-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1347-AppendixA-Attachment2.pdf', 'C9P1-VEA-EOP-Q1347-AppendixA-Attachment2.pdf']\n",
      "\n",
      "List of Skipped PDFs: ['C9PI-SCE-Eastern-Q1295-AppndxA.pdf', 'C9PI-SCE-Eastern-Q1295-Atchmnt1.pdf', 'C9PI-SCE-Eastern-Q1295-Addendum_AppndxA.pdf', 'C9PI-SCE-Eastern-Q1295-Atchmnt1_Addendum.pdf', 'C9PI-SCE-Eastern-Q1296-AppndxA.pdf', 'C9PI-SCE-Eastern-Q1296-Addendum_AppndxA.pdf', 'C9PI-SCE-Eastern-Q1296-Addendum_Atchmnt1.pdf', 'C9PI-SCE-Eastern-Q1296-Atchmnt1.pdf', 'C9PI-SCE-Eastern-Q1297-RevisedAppndxA.pdf', 'C9PI-SCE-Eastern-Q1297-Atchmnt1_Revision.pdf', 'C9PI-SCE-Eastern-Q1299-AppndxA.pdf', 'C9PI-SCE-Eastern-Q1299-Addendum_AppndxA.pdf', 'C9PI-SCE-Eastern-Q1299_Atchmnt1.pdf', 'C9PI-SCE-Eastern-Q1299_Atchmnt1_Addendum.pdf', 'C9PI-SCE-Eastern-Q1300-AppndxA.pdf', 'C9PI-SCE-Eastern-Q1300-Atchmnt1_Addendum.pdf', 'C9PI-SCE-Eastern-Q1300-Atchmnt1.pdf', 'C9P1-Q1300-Eastern-Addedum_AppendixA.pdf', 'C9PI-SCE-Eastern-Q1301-RevisedAppndxA.pdf', 'C9PI-SCE-Eastern-Q1301-Atchmnt1_Revision.pdf', 'C9PI-SCE-Eastern-Q1302-RevisedAppndxA.pdf', 'C9PI-SCE-Eastern-Q1302-Atchmnt1_Revision.pdf', 'C9PI-Q1305-Atchmnt1_20170217_Final.pdf', 'C9PI-Q1305-AppndxA_2017.02.24_Addendum_Final.pdf', 'C9PI-Q1305-Atchmnt1_NOL_Calcite Solar 1.pdf', 'C9PI-Q1305-AppndxA_NOL_Calcite Solar 1.pdf', 'C9PI-Q1306-Atchmnt1_NOL_Ghost Town Solar.pdf', 'C9PI-Q1306-RevisedAppndxA_2017.02.27_Final.pdf', 'C9PI-Q1306-Atchmnt1_20170217_Final.pdf', 'C9PI-Q1306-AppndxA_NOL_Ghost Town Solar.pdf', 'C9PI-Q1307-RevisedAppndxA_2017.02.27_Final.pdf', 'C9PI-Q1307-Atchmnt1_20170217_Final.pdf', 'C9PI-Q1307-Atchmnt1_NOL_Sand Solar.pdf', 'C9PI-Q1307-AppndxA_NOL_Sand Solar.pdf', 'C9PI-Q1308-RevisedAppndxA_2017.02.17_Final.pdf', 'C9PI-Q1308-Atchmnt1_20170228_Final.pdf', 'C9PI-Q1309-AppndxA_NOL_SEGS10 Solar.pdf', 'C9PI-Q1309-Atchmnt1_NOL_SEGS 10 Solar.pdf', 'C9PI-Q1309-Atchmnt1_20170217_Final.pdf', 'C9PI-Q1309-RevisedAppndxA_2017.02.17_Final.pdf', 'C9PI-Q1310-AppndxA_NOL_Coso Solar 2.pdf', 'C9PI-Q1310-Atchmnt1_NOL_Coso Solar 2.pdf', 'C9PI-Q1310-RevisedAppndxA_Final.pdf', 'C9PI-Q1310-Atchmnt1_20170217_Final.pdf', 'C9PI-Q1311-Atchmnt1_NOL_Coso Solar 1.pdf', 'C9PI-Q1311-AppndxA_NOL_Coso Solar 1.pdf', 'C9PI-Q1312-RevisedAppndxA_2017.02.22_Final.pdf', 'C9PI-Q1312-Atchmnt1_20170224_Final.pdf', 'C9PI-Q1312-Atchmnt1_NOL_Coolwater Solar 3.pdf', 'C9PI-Q1313-Atchmnt1_20170224_Final.pdf', 'C9PI-Q1313-Atchmnt1_NOL_Coolwater Solar 2.pdf', 'C9PI-Q1313-RevisedAppndxA_2017.02.22_Final.pdf', 'C9PI-Q1314-Atchmnt1_NOL_Coolwater Solar 1.pdf', 'C9PI-Q1314-RevisedAppndxA_2017.02.22_Final.pdf', 'C9PI-Q1314-Atchmnt1_20170224_Final.pdf', 'C9PI-Q1315-Atchmnt1_NOL_Waller Solar Farm.pdf', 'C9PI-Q1315-RevisedAppndxA_2017.02.17_Final.pdf', 'C9PI-Q1315-Atchmnt1_20170217_Final.pdf', 'C9PI-Q1316-Atchmnt1_20170217_Final.pdf', 'C9P1-Q1316-NOL-Addedum_AppendixA_Final.pdf', 'C9PI-Q1316-AppndxA_NOL_High Desert View Solar Project.pdf', 'C9PI-Q1316-Atchmnt1_NOL_High Desert View Solar.pdf', 'C9P1-SCE-Northern-Q1317-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1317-AppndxA.pdf', 'C9P1-SCE-Northern-Q1317-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1318-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1318-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1318-AppndxA.pdf', 'C9P1-SCE-Northern-Q1319-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1319-AppndxA.pdf', 'C9P1-SCE-Northern-Q1319-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1320-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1320-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1320-AppndxA.pdf', 'C9P1-SCE-Northern-Q1321-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1321-AppndxA.pdf', 'C9P1-SCE-Northern-Q1322-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1322-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1323-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1323-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1325-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1325-AppndxA.pdf', 'C9P1-SCE-Northern-Q1326-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1326-AppndxA.pdf', 'C9P1-SCE-Northern-Q1327-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1327-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1328-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1328-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1329-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1329-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt8.pdf', 'C9P1-SCE-Northern-Q1330-AppndxA.pdf', 'C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1331-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1331-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1332-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1332-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1333-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1333-RevisedAppndxA.pdf', 'C9P1-SCE-Northern-Q1334-AppndxA.pdf', 'C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1335-AppndxA-Atchmnt1.pdf', 'C9P1-SCE-Northern-Q1335-AppndxA.pdf', 'C9P1-SCE-EOP-Q1336-AppendixA-Revision01.pdf', 'C9PI-SCE-EOP-Q1336-AppendixA-Attachment1.pdf', 'C9P1-SCE-EOP-Q1336-AppendixA-Attachment1.pdf', 'C9P1-SCE-EOP-Q1338-AppendixA-Revision01.pdf', 'C9P1-SCE-EOP-Q1339-AppendixA-Revision01.pdf', 'C9P1-VEA-EOP-Q1341-AppendixA.pdf', 'C9P1-VEA-EOP-Q1341-AppendixA-Attachment1.pdf', 'C9P1-VEA-Q1344-Copper Rays-Appendix A-Attachment 1-Revision-01.pdf', 'C9P1-SCE-VEA-EOP-Q1344-AppendixA-Attachment1.pdf', 'C9P1-VEA-EOP-Q1344-AppendixA.pdf', 'C9P1-VEA-Q1344-Copper Rays-Appendix A-revision-01.pdf', 'C9P1-VEA-EOP-Q1345-AppendixA.pdf', 'C9P1-SCE-VEA-EOP-Q1345-AppendixA-Attachment1.pdf', 'C9P1-SCE-VEA-EOP-Q1347-AppendixA-Attachment1.pdf', 'C9P1-VEA-EOP-Q1347-AppendixA.pdf']\n",
      "\n",
      "List of Addendum PDFs: ['Q1306-TOT792_NOL_Attachment 2_C9P1 Revision 022217_Final.pdf', 'Q1307-TOT820_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1308-SCE_TOT808_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1309-TOT805_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1310-TOT803_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1312-TOT812_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1313-TOT811_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1314-TOT810_NOL_Attachment 2_C9P1 Revision022217_Final.pdf', 'Q1315-TOT829_NOL_Attachment 2_C9P1 Addendum022217_Final.pdf', 'C9P1-VEA-Q1344-Copper Rays-Appendix A-Attachment 2_Revision-01.pdf']\n",
      "\n",
      "List of Original PDFs: ['C9PI-SCE-Eastern-Q1295-Atchmnt2.pdf', 'C9PI-SCE-Eastern-Q1296-Atchmnt2_SDGE.pdf', 'C9PI-SCE-Eastern-Q1296-Atchmnt2_SCE.pdf', 'Q1296-TOT834_Eastern_Attachment 2_C9P1_Addendum.pdf', 'C9PI-SCE-Eastern-Q1296-Atchmnt2_DCR.pdf', 'Q1297-TOT794_Eastern_Attachment 2_C9P1 Revision1.pdf', 'C9PI-SCE-Eastern-Q1299-Atchmnt2.pdf', 'C9PI-SCE-Eastern-Q1300-Atchmnt2.pdf', 'Q1301-TOT825_Eastern_Attachment 2_C9P1 Revision.pdf', 'Q1302-TOT830_Eastern_Attachment 2_C9P1 Revision.pdf', 'Q1305-TOT786_NOL_Attachment 2_C9P1_Addendum_Final.pdf', 'Q1306-TOT792_NOL_Attachment 2_C9P1.pdf', 'Q1307-TOT820_NOL_Attachment 2_C9P1.pdf', 'C9P1-VEA-Q1308-Barstow Solar-Appendix A-Attachment 2_Final.pdf', 'Q1309-TOT805_NOL_Attachment 2_C9P1.pdf', 'Q1310-TOT803_NOL_Attachment 2_C9P1.pdf', 'Q1311-TOT802_NOL_Attachment 2_C9P1.pdf', 'Q1312-TOT812_NOL_Attachment 2_C9P1.pdf', 'Q1313-TOT811_NOL_Attachment 2_C9P1.pdf', 'Q1314-TOT810_NOL_Attachment 2_C9P1.pdf', 'Q1315-TOT829_NOL_Attachment 2_C9P1.pdf', 'Q1316-TOT838_NOL_Attachment 2_C9P1_Addendum_Final.pdf', 'C9P1-SCE-Northern-Q1317-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1318-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1319-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1320-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1321-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1322-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1323-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1325-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1326-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1327-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1328-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1329-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt2A.pdf', 'C9P1-SCE-Northern-Q1330-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1331-Revised_Attachment 2.pdf', 'C9P1-SCE-Northern-Q1332-RevisedAttachment 2.pdf', 'C9P1-SCE-Northern-Q1333-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-Northern-Q1334-AppndxA-Atchmnt2A.pdf', 'C9P1-SCE-Northern-Q1335-AppndxA-Atchmnt2.pdf', 'C9P1-SCE-EOP-Q1336-AppendixA-Attachment2-Revision01.pdf', 'C9P1-SCE-EOP-Q1338-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1338-AppendixA-Attachment1-Revision01.pdf', 'C9P1-SCE-EOP-Q1339-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1339-AppendixA-Attachment1-Revision01.pdf', 'C9P1-VEA-EOP-Q1341-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1341-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1344-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1345-AppendixA-Attachment2.pdf', 'C9P1-VEA-EOP-Q1345-AppendixA-Attachment2.pdf', 'C9P1-SCE-EOP-Q1347-AppendixA-Attachment2.pdf', 'C9P1-VEA-EOP-Q1347-AppendixA-Attachment2.pdf']\n",
      "\n",
      "List of Style N PDFs (Skipped due to 'Network Upgrade Type'): []\n",
      "\n",
      "Total Number of Style N PDFs: 0\n",
      "\n",
      "Number of Original PDFs Scraped: 54\n",
      "Number of Addendum PDFs Scraped: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_2120/4181385699.py:651: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(clean_string_cell)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import traceback\n",
    "import pdfplumber\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------- Configuration -------------------\n",
    "BASE_DIRECTORY = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/03_data\"\n",
    "OUTPUT_CSV_PATH_ORIGINAL = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/03_raw/rawdata_cluster9_style_J_originals.csv\"\n",
    "OUTPUT_CSV_PATH_ADDENDUM = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/03_raw/rawdata_cluster9_style_J_addendums.csv\"\n",
    "LOG_FILE_PATH = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/03_raw/scraping_cluster9_style_J_log.txt\"\n",
    "PROJECT_RANGE = range(1223, 1348)  # Original range #(1831, 2193)\n",
    "\n",
    "# Read the CSV file containing processed projects (with q_id column)\n",
    "processed_csv_path = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/all_clusters/costs_phase_1_all_clusters_total1.csv\"  # UPDATE THIS PATH\n",
    "processed_df = pd.read_csv(processed_csv_path)\n",
    "# Convert q_id values to numeric then to int for filtering\n",
    "processed_q_ids = pd.to_numeric(processed_df['q_id'], errors='coerce').dropna().astype(int).unique()\n",
    "projects_to_process = sorted([q_id for q_id in PROJECT_RANGE if q_id not in processed_q_ids])\n",
    "\n",
    "# ------------------- Global Tracking Variables -------------------\n",
    "core_originals = pd.DataFrame()\n",
    "core_addendums = pd.DataFrame()\n",
    "\n",
    "scraped_projects = set()\n",
    "skipped_projects = set()\n",
    "missing_projects = set()\n",
    "scraped_pdfs = []\n",
    "skipped_pdfs = []\n",
    "addendum_pdfs = []\n",
    "original_pdfs = []\n",
    "style_n_pdfs = []  # Not used in this version but kept for consistency\n",
    "\n",
    "total_pdfs_accessed = 0\n",
    "total_pdfs_scraped = 0\n",
    "total_pdfs_skipped = 0\n",
    "\n",
    "# ------------------- Helper Function for Logging -------------------\n",
    "def log_msg(msg, log_file):\n",
    "    \"\"\"Prints a message to both the log file and console.\"\"\"\n",
    "    print(msg, file=log_file)\n",
    "    print(msg)\n",
    "\n",
    "# ------------------- Other Helper Functions -------------------\n",
    "def clean_column_headers(headers):\n",
    "    \"\"\"Cleans column headers by normalizing and removing unwanted characters.\"\"\"\n",
    "    cleaned_headers = []\n",
    "    for header in headers:\n",
    "        if header is None:\n",
    "            header = \"\"\n",
    "        elif isinstance(header, str):\n",
    "            header = header.lower()\n",
    "            header = re.sub(r'\\s+', ' ', header)\n",
    "            header = re.sub(r'\\(.*?\\)', '', header)\n",
    "            header = re.sub(r'[^a-zA-Z0-9\\s]', '', header)\n",
    "            header = header.strip()\n",
    "        cleaned_headers.append(header)\n",
    "    return cleaned_headers\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    \"\"\"Cleans string cells by removing newlines and trimming spaces.\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        return value.replace('\\n', ' ').strip()\n",
    "    elif value is None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return str(value).replace('\\n', ' ').strip()\n",
    "\n",
    "def contains_phrase(row, phrase):\n",
    "    \"\"\"Checks if any cell in a row contains a specific phrase.\"\"\"\n",
    "    regex_pattern = re.sub(r\"\\s+\", r\"\\\\s*\", phrase)\n",
    "    pattern = re.compile(regex_pattern, flags=re.IGNORECASE)\n",
    "    return row.astype(str).apply(lambda cell: bool(pattern.search(cell))).any()\n",
    "\n",
    "def extract_specific_phrase(title):\n",
    "    \"\"\"\n",
    "    Extracts a specific phrase from the table title based on predefined keywords.\n",
    "    \"\"\"\n",
    "    phrases = [\n",
    "        \"PTO\",\n",
    "        \"Reliability Network Upgrade\",\n",
    "        \"Area Delivery Network Upgrade\",\n",
    "        \"Local Delivery Network\",\n",
    "        \"Other Potential Network Upgrade\",\n",
    "        \"Area Delivery Network Upgrades\",\n",
    "        \"Conditionally Assigned Network Upgrades\",\n",
    "        \"Local Off-Peak Network Upgrade\",\n",
    "        \"ADNU\",\n",
    "        \"LDNU\",\n",
    "        \"RNU\"\n",
    "    ]\n",
    "    for phrase in phrases:\n",
    "        if re.search(rf\"\\b{re.escape(phrase)}\\b(?=\\d|\\W|$)\", title, re.IGNORECASE):\n",
    "            return phrase\n",
    "    return title  # Fallback if no specific phrase is found\n",
    "\n",
    "def reorder_columns(df):\n",
    "    \"\"\"\n",
    "    Reorders the columns of the DataFrame based on the specified order.\n",
    "    \"\"\"\n",
    "    desired_order = [\n",
    "        \"q_id\",\n",
    "        \"cluster\",\n",
    "        \"req_deliverability\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"capacity\",\n",
    "        \"point_of_interconnection\"\n",
    "    ]\n",
    "    existing_desired = [col for col in desired_order if col in df.columns]\n",
    "    remaining = [col for col in df.columns if col not in existing_desired]\n",
    "    new_order = existing_desired + remaining\n",
    "    return df[new_order]\n",
    "\n",
    "def search_gps_coordinates(text, log_file):\n",
    "    \"\"\"Search for GPS coordinates using multiple patterns.\"\"\"\n",
    "    gps_coords = re.search(r\"gps coordinates:\\s*([\\d\\.\\-]+),\\s*([\\d\\.\\-]+)\", text, re.IGNORECASE)\n",
    "    if gps_coords:\n",
    "        log_msg(f\"Found GPS coordinates: {gps_coords.groups()}\", log_file)\n",
    "        return gps_coords.groups()\n",
    "    project_coords = re.search(r\"latitude[:\\s]*([\\d\\.\\-]+)[^\\d]+longitude[:\\s]*([\\d\\.\\-]+)\", text, re.IGNORECASE)\n",
    "    if project_coords:\n",
    "        log_msg(f\"Found project coordinates: {project_coords.groups()}\", log_file)\n",
    "        return project_coords.groups()\n",
    "    gps_coords_directional = re.search(r\"gps coordinates:\\s*([\\d\\.\\-]+)\\s*[nNsS],\\s*([\\d\\.\\-]+)\\s*[eEwW]\", text, re.IGNORECASE)\n",
    "    if gps_coords_directional:\n",
    "        lat, lon = gps_coords_directional.groups()\n",
    "        latitude = lat if \"N\" in text.upper() else f\"-{lat}\"\n",
    "        longitude = lon if \"E\" in text.upper() else f\"-{lon}\"\n",
    "        log_msg(f\"Found directional GPS coordinates: {(latitude, longitude)}\", log_file)\n",
    "        return (latitude, longitude)\n",
    "    log_msg(\"GPS coordinates not found.\", log_file)\n",
    "    return (None, None)\n",
    "\n",
    "# ------------------- Appendix PDF Check -------------------\n",
    "def is_appendix_pdf(pdf_path):\n",
    "    \"\"\"Returns True if the first page of the PDF contains 'Appendix A'.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            if not pdf.pages:\n",
    "                return False\n",
    "            first_page_text = pdf.pages[0].extract_text() or \"\"\n",
    "            return \"Appendix A\" in first_page_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# ------------------- Base Data & Table 1 Extraction (Appendix A Only) -------------------\n",
    "def extract_table1(pdf_path, log_file):\n",
    "    \"\"\"\n",
    "    Extracts the Point of Interconnection from Table 1 in the provided PDF.\n",
    "    This function is intended to run only on the Appendix A PDF.\n",
    "    Now it searches for pages containing \"Table A.2\", \"Table B.2\" or \"Table C.2\"\n",
    "    and within the tables it looks for either \"Point of Interconnection\" or \"POI\".\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing {pdf_path} for Table 1 extraction...\", file=log_file)\n",
    "    point_of_interconnection = None\n",
    "    # Modified to match either \"Point of Interconnection\" or \"POI\"\n",
    "    poi_pattern = re.compile(r\"(Point\\s+of\\s+Interconnection|POI)\", re.IGNORECASE)\n",
    "    table_settings_list = [\n",
    "        {\"horizontal_strategy\": \"text\", \"vertical_strategy\": \"lines\", \"snap_tolerance\": 1},\n",
    "        {\"horizontal_strategy\": \"lines\", \"vertical_strategy\": \"lines\", \"snap_tolerance\": 2}\n",
    "    ]\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            table1_pages = []\n",
    "            # Modified regex: look for \"Table A.2\", \"Table B.2\" or \"Table C.2\"\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                text = page.extract_text() or \"\"\n",
    "                if re.search(r\"Table\\s*[ABC]\\.1\\b\", text, re.IGNORECASE):\n",
    "                    table1_pages.append(i)\n",
    "            if not table1_pages:\n",
    "                print(\"No Table 1 found in the PDF.\", file=log_file)\n",
    "                return None\n",
    "            first_page = table1_pages[0]\n",
    "            last_page = table1_pages[-1]\n",
    "            scrape_start = first_page\n",
    "            scrape_end = last_page + 2\n",
    "            print(f\"Table 1 starts on page {scrape_start + 1} and ends on page {scrape_end + 1}\", file=log_file)\n",
    "            extraction_successful = False\n",
    "            for page_number in range(scrape_start, min(scrape_end + 1, len(pdf.pages))):\n",
    "                page = pdf.pages[page_number]\n",
    "                print(f\"\\nScraping tables on page {page_number + 1} for Table 1...\", file=log_file)\n",
    "                for attempt, table_settings in enumerate(table_settings_list, start=1):\n",
    "                    print(f\"Attempt {attempt} with settings: {table_settings}\", file=log_file)\n",
    "                    tables = page.find_tables(table_settings=table_settings)\n",
    "                    print(f\"Found {len(tables)} table(s) on page {page_number + 1}\", file=log_file)\n",
    "                    for table_index, table in enumerate(tables, start=1):\n",
    "                        tab = table.extract()\n",
    "                        if not tab:\n",
    "                            print(f\"Table {table_index} on page {page_number + 1} is empty.\", file=log_file)\n",
    "                            continue\n",
    "                        for row_index, row in enumerate(tab, start=1):\n",
    "                            for cell_index, cell in enumerate(row, start=1):\n",
    "                                if cell and poi_pattern.search(cell):\n",
    "                                    poi_col_index = cell_index  # 1-based index\n",
    "                                    adjacent_col_index = poi_col_index + 1\n",
    "                                    if adjacent_col_index <= len(row):\n",
    "                                        poi_value = clean_string_cell(row[adjacent_col_index - 1])\n",
    "                                        if poi_value:\n",
    "                                            point_of_interconnection = poi_value\n",
    "                                            print(f\"Found POI: '{point_of_interconnection}' (Page {page_number + 1}, Table {table_index}, Row {row_index})\", file=log_file)\n",
    "                                            extraction_successful = True\n",
    "                                            break\n",
    "                                        else:\n",
    "                                            print(f\"POI label found but adjacent value empty (Page {page_number + 1}, Table {table_index}, Row {row_index}).\", file=log_file)\n",
    "                                            poi_value_parts = []\n",
    "                                            current_row_idx = row_index - 1\n",
    "                                            start_scan = max(0, current_row_idx - 2)\n",
    "                                            end_scan = min(len(tab), current_row_idx + 3)\n",
    "                                            for scan_row_index in range(start_scan, end_scan):\n",
    "                                                if scan_row_index == current_row_idx:\n",
    "                                                    continue\n",
    "                                                scan_row = tab[scan_row_index]\n",
    "                                                if adjacent_col_index - 1 < len(scan_row):\n",
    "                                                    scan_cell = clean_string_cell(scan_row[adjacent_col_index - 1])\n",
    "                                                    if scan_cell and not poi_pattern.search(scan_cell):\n",
    "                                                        poi_value_parts.append(scan_cell)\n",
    "                                            if poi_value_parts:\n",
    "                                                point_of_interconnection = \" \".join(poi_value_parts)\n",
    "                                                print(f\"Concatenated POI: '{point_of_interconnection}'\", file=log_file)\n",
    "                                                extraction_successful = True\n",
    "                                                break\n",
    "                                    else:\n",
    "                                        print(f\"POI label found but no adjacent column (Page {page_number + 1}, Table {table_index}, Row {row_index}).\", file=log_file)\n",
    "                            if extraction_successful:\n",
    "                                break\n",
    "                        if extraction_successful:\n",
    "                            break\n",
    "                    if extraction_successful:\n",
    "                        break\n",
    "                if extraction_successful:\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Table 1 in {pdf_path}: {e}\", file=log_file)\n",
    "        print(traceback.format_exc(), file=log_file)\n",
    "        return None\n",
    "    if not extraction_successful:\n",
    "        if point_of_interconnection is not None and point_of_interconnection != \"\":\n",
    "            print(\"POI label found but no value.\", file=log_file)\n",
    "            return \"Value Missing\"\n",
    "        else:\n",
    "            print(\"POI not found in Table 1.\", file=log_file)\n",
    "            return None\n",
    "    return point_of_interconnection\n",
    "\n",
    "\n",
    "def extract_base_data(pdf_path, project_id, log_file):\n",
    "    \"\"\"\n",
    "    Extracts base data from the Appendix A PDF.\n",
    "    (This function is meant to run only on a PDF verified as an Appendix A PDF.)\n",
    "    \"\"\"\n",
    "    if not is_appendix_pdf(pdf_path):\n",
    "        log_msg(f\"Skipping base extraction because {pdf_path} is not an Appendix A PDF.\", log_file)\n",
    "        return pd.DataFrame()\n",
    "    log_msg(\"Extracting base data from Appendix A PDF...\", log_file)\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as pdf_file:\n",
    "            reader = PyPDF2.PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "        text = clean_string_cell(text)\n",
    "        #queue_id = re.search(r\"q[\\s_-]*(\\d+)\", text, re.IGNORECASE)\n",
    "        #queue_id = queue_id.group(1) if queue_id else str(project_id)\n",
    "        queue_id = str(project_id)\n",
    "        log_msg(f\"Extracted Queue ID: {queue_id}\", log_file)\n",
    "        #clusters = re.findall(r\"queue[\\s_-]*cluster[\\s_-]*(\\d+)\", text, re.IGNORECASE)\n",
    "        #if '14' in clusters:\n",
    "        #    cluster_number = '14'\n",
    "        #elif clusters:\n",
    "        #    cluster_number = max(clusters, key=lambda x: int(x))\n",
    "        #else:\n",
    "        #   cluster_number = '14'\n",
    "        clusters = re.findall(r\"queue[\\s_-]*cluster[\\s_-]*(\\d+)\", text, re.IGNORECASE)\n",
    "        cluster_number = '9'    \n",
    "        log_msg(f\"Extracted Cluster Number: {cluster_number}\", log_file)\n",
    "        deliverability_status = re.search(r\"(\\w+)\\s*capacity deliverability status\", text, re.IGNORECASE)\n",
    "        deliverability_status = deliverability_status.group(1) if deliverability_status else None\n",
    "        log_msg(f\"Extracted Deliverability Status: {deliverability_status}\", log_file)\n",
    "        capacity = re.search(r\"total rated output of (\\d+)\\s*mw\", text, re.IGNORECASE)\n",
    "        if capacity:\n",
    "            capacity = int(capacity.group(1))\n",
    "        else:\n",
    "            capacity2 = re.search(r\"(\\d+)\\s*mw\", text)\n",
    "            capacity = int(capacity2.group(1)) if capacity2 else None\n",
    "        log_msg(f\"Extracted Capacity: {capacity}\", log_file)\n",
    "        poi_value = extract_table1(pdf_path, log_file)\n",
    "        latitude, longitude = search_gps_coordinates(text, log_file)\n",
    "        base_data = {\n",
    "            \"q_id\": [queue_id],\n",
    "            \"cluster\": [cluster_number],\n",
    "            \"req_deliverability\": [deliverability_status],\n",
    "            \"latitude\": [latitude],\n",
    "            \"longitude\": [longitude],\n",
    "            \"capacity\": [capacity],\n",
    "            \"point_of_interconnection\": [poi_value]\n",
    "        }\n",
    "        log_msg(\"Base data extracted:\", log_file)\n",
    "        log_msg(str(base_data), log_file)\n",
    "        return pd.DataFrame(base_data)\n",
    "    except Exception as e:\n",
    "        log_msg(f\"Error extracting base data from {pdf_path}: {e}\", log_file)\n",
    "        print(traceback.format_exc(), file=log_file)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ------------------- Attachment 2 Processing & Merging -------------------\n",
    "# compile once at module scope for a tiny speed boost\n",
    "_ATTACHMENT2_PATTERN = re.compile(r'Attachment\\s*\\W*\\s*2', re.IGNORECASE)\n",
    "\n",
    "def is_attachment2_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Returns True if the first page of the PDF contains something like\n",
    "    'Attachment 2', 'Attachment#2', 'Attachment - 2', 'attachment@2', etc.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            if not pdf.pages:\n",
    "                return False\n",
    "            text = pdf.pages[0].extract_text() or \"\"\n",
    "            return bool(_ATTACHMENT2_PATTERN.search(text))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "_ADDENDUM_PATTERN = re.compile(r'(Addendum|Revision)\\s*\\W*\\s*\\d+', re.IGNORECASE)\n",
    "\n",
    "\n",
    "def is_addendum_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Returns True if the first page of the PDF contains 'Addendum' or 'Revision', optionally\n",
    "    followed by a separator (colon, -, @, or #) and a number (e.g., \"Addendum #1\", \"Addendum: 2\", or \"Revision-1\").\n",
    "    Uses regex matching for robustness.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            if not pdf.pages:\n",
    "                return False\n",
    "            text = pdf.pages[0].extract_text() or \"\"\n",
    "            return bool(_ADDENDUM_PATTERN.search(text))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "        return False\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_unique_headers(headers):\n",
    "    \"\"\"\n",
    "    Appends a suffix to duplicate headers to make them unique.\n",
    "    \"\"\"\n",
    "    seen = {}\n",
    "    unique_headers = []\n",
    "    for header in headers:\n",
    "        if header in seen:\n",
    "            seen[header] += 1\n",
    "            unique_headers.append(f\"{header}_{seen[header]}\")\n",
    "        else:\n",
    "            seen[header] = 1\n",
    "            unique_headers.append(header)\n",
    "    return unique_headers\n",
    "\n",
    " \n",
    "\n",
    "def extract_first_table(pdf_path, log_file):\n",
    "    \"\"\"\n",
    "    Extracts the *first* non-empty table from the entire PDF.\n",
    "    Then, on the *same page* where that first table was found, searches for:\n",
    "      - A table that contains \"Other Potential\" (as before)\n",
    "      - A table that contains \"Area Delivery Network Upgrades\"\n",
    "    If the ADN table is not found on the same page, it checks the next page.\n",
    "    Finally, it merges any extra tables found with the first table row-wise.\n",
    "    \"\"\"\n",
    "    import pdfplumber\n",
    "    import pandas as pd\n",
    "    \n",
    "    first_table_df = pd.DataFrame()\n",
    "    found_page_index = None\n",
    "\n",
    "    try:\n",
    "        # 1) Find the *first* non-empty table in the PDF\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page_index, page in enumerate(pdf.pages):\n",
    "                tables = page.extract_tables()\n",
    "                for table in tables:\n",
    "                    if table and any(any(cell and cell.strip() for cell in row) for row in table):\n",
    "                        df = pd.DataFrame(table)\n",
    "                        if not df.empty:\n",
    "                            headers = df.iloc[0].tolist()\n",
    "                            headers = make_unique_headers(headers)\n",
    "                            df.columns = headers\n",
    "                            df = df[1:].reset_index(drop=True)\n",
    "                            # Remove duplicate column names (safeguard)\n",
    "                            df = df.loc[:, ~df.columns.duplicated()]\n",
    "                            first_table_df = df\n",
    "                            found_page_index = page_index\n",
    "                            break  # Stop looking at more tables on this page\n",
    "                if found_page_index is not None:\n",
    "                    break  # Stop after the first table is found\n",
    "\n",
    "            # If no table was found at all, just return empty DataFrame\n",
    "            if first_table_df.empty:\n",
    "                return first_table_df\n",
    "\n",
    "            # 2) On that page (and potentially the next page) look for extra tables:\n",
    "            #    one containing \"Other Potential\" and one containing \"Area Delivery Network Upgrades\"\n",
    "            other_table_df = pd.DataFrame()\n",
    "            adn_table_df = pd.DataFrame()\n",
    "            if found_page_index is not None:\n",
    "                page = pdf.pages[found_page_index]\n",
    "                tables = page.extract_tables()\n",
    "                for table in tables:\n",
    "                    if table and any(any(cell and cell.strip() for cell in row) for row in table):\n",
    "                        # Check for \"Other Potential\" and \"Area Delivery Network Upgrades\"\n",
    "                        found_other = any(\n",
    "                            cell and \"other potential\" in cell.lower() \n",
    "                            for row in table for cell in row\n",
    "                        )\n",
    "                        found_adn = any(\n",
    "                            cell and \"area delivery network upgrades\" in cell.lower() \n",
    "                            for row in table for cell in row\n",
    "                        )\n",
    "                        if found_other and other_table_df.empty:\n",
    "                            df_other = pd.DataFrame(table)\n",
    "                            if not df_other.empty:\n",
    "                                headers = df_other.iloc[0].tolist()\n",
    "                                headers = make_unique_headers(headers)\n",
    "                                df_other.columns = headers\n",
    "                                df_other = df_other[1:].reset_index(drop=True)\n",
    "                                df_other = df_other.loc[:, ~df_other.columns.duplicated()]\n",
    "                                other_table_df = df_other\n",
    "                        if found_adn and adn_table_df.empty:\n",
    "                            df_adn = pd.DataFrame(table)\n",
    "                            if not df_adn.empty:\n",
    "                                headers = df_adn.iloc[0].tolist()\n",
    "                                headers = make_unique_headers(headers)\n",
    "                                df_adn.columns = headers\n",
    "                                df_adn = df_adn[1:].reset_index(drop=True)\n",
    "                                df_adn = df_adn.loc[:, ~df_adn.columns.duplicated()]\n",
    "                                adn_table_df = df_adn\n",
    "                        if not other_table_df.empty and not adn_table_df.empty:\n",
    "                            break\n",
    "\n",
    "                # If ADN table not found on the same page, check the next page (if available)\n",
    "                if adn_table_df.empty and found_page_index + 1 < len(pdf.pages):\n",
    "                    next_page = pdf.pages[found_page_index + 1]\n",
    "                    tables = next_page.extract_tables()\n",
    "                    for table in tables:\n",
    "                        if table and any(any(cell and cell.strip() for cell in row) for row in table):\n",
    "                            found_adn = any(\n",
    "                                cell and \"area delivery network upgrades\" in cell.lower()\n",
    "                                for row in table for cell in row\n",
    "                            )\n",
    "                            if found_adn:\n",
    "                                df_adn = pd.DataFrame(table)\n",
    "                                if not df_adn.empty:\n",
    "                                    headers = df_adn.iloc[0].tolist()\n",
    "                                    headers = make_unique_headers(headers)\n",
    "                                    df_adn.columns = headers\n",
    "                                    df_adn = df_adn[1:].reset_index(drop=True)\n",
    "                                    df_adn = df_adn.loc[:, ~df_adn.columns.duplicated()]\n",
    "                                    adn_table_df = df_adn\n",
    "                                    break\n",
    "\n",
    "            # 3) Merge the tables if any extra tables were found\n",
    "            # 3) Vertically stack each table \u2014 preserving separate prefixes \u2014 so values never share a row\n",
    "            dfs = [first_table_df]\n",
    "\n",
    "            if not other_table_df.empty:\n",
    "                dfs.append(other_table_df.add_prefix(\"OtherPotential_\"))\n",
    "\n",
    "            if not adn_table_df.empty:\n",
    "                dfs.append(adn_table_df.add_prefix(\"ADN_\"))\n",
    "\n",
    "            merged_df = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "            return merged_df\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting table from {pdf_path}: {e}\", file=log_file)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "def update_base_data(existing_df, new_df):\n",
    "    \"\"\"\n",
    "    For each column in existing_df (assumed to be a single-row DataFrame),\n",
    "    if the value is missing (empty string, \"None\", or NA), update it with the corresponding\n",
    "    value from new_df (if provided and not missing).\n",
    "    Returns the updated DataFrame.\n",
    "    \"\"\"\n",
    "    for col in existing_df.columns:\n",
    "        existing_val = existing_df.at[0, col]\n",
    "        # Use pd.isna() to check for NA values.\n",
    "        if pd.isna(existing_val) or existing_val == \"\" or existing_val == \"None\":\n",
    "            if col in new_df.columns:\n",
    "                new_val = new_df.at[0, col]\n",
    "                if not (pd.isna(new_val) or new_val == \"\" or new_val == \"None\"):\n",
    "                    existing_df.at[0, col] = new_val\n",
    "    return existing_df\n",
    "\n",
    "\n",
    "\n",
    "def process_attachment2_for_project(project_id, log_file):\n",
    "    \"\"\"\n",
    "    For the given project:\n",
    "      1. Identify all original (non\u2011revision) Appendix A PDFs and any addendum (revision) Appendix A PDFs \n",
    "         in the project's \"02_phase_1_study\" folder.\n",
    "      2. If an original exists, use the first original for base data extraction.\n",
    "         Otherwise, if only an addendum exists, use that for base data extraction.\n",
    "      3. If any base data column is missing, iterate through additional PDFs (if available) to update the missing columns.\n",
    "      4. Then proceed to scrape Attachment 2 PDFs and merge the base data (duplicated for each row) with\n",
    "         the extracted table (using the first row as header).\n",
    "         (Attachment 2 PDFs will be routed as before based solely on whether each PDF is flagged as addendum.)\n",
    "    \"\"\"\n",
    "    global total_pdfs_accessed, total_pdfs_scraped, total_pdfs_skipped\n",
    "    project_folder = os.path.join(BASE_DIRECTORY, str(project_id), \"02_phase_1_study\")\n",
    "    if not os.path.exists(project_folder):\n",
    "        log_msg(f\"Project folder not found: {project_folder}\", log_file)\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Gather all original (non\u2011revision) Appendix A PDFs and any addendum PDFs\n",
    "    original_appendix_pdfs = []\n",
    "    addendum_appendix_pdf = None\n",
    "    for f in os.listdir(project_folder):\n",
    "        if not f.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        pdf_path = os.path.join(project_folder, f)\n",
    "        if is_appendix_pdf(pdf_path):\n",
    "            if is_addendum_pdf(pdf_path):\n",
    "                if not addendum_appendix_pdf:\n",
    "                    addendum_appendix_pdf = f\n",
    "            else:\n",
    "                original_appendix_pdfs.append(f)\n",
    "    \n",
    "    # Determine which file to use for base data extraction.\n",
    "    if not original_appendix_pdfs:\n",
    "        if addendum_appendix_pdf:\n",
    "            log_msg(f\"No original Appendix A PDF found for project {project_id}. Using addendum PDF for base data extraction.\", log_file)\n",
    "            base_pdf = addendum_appendix_pdf\n",
    "            base_data_df = extract_base_data(os.path.join(project_folder, base_pdf), project_id, log_file)\n",
    "        else:\n",
    "            log_msg(f\"No Appendix A PDF (original or addendum) found for project {project_id}.\", log_file)\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "    else:\n",
    "        base_pdf = original_appendix_pdfs[0]\n",
    "        log_msg(f\"Scraped base data from original Appendix A PDF: {os.path.join(project_folder, base_pdf)}\", log_file)\n",
    "        base_data_df = extract_base_data(os.path.join(project_folder, base_pdf), project_id, log_file)\n",
    "\n",
    "    # Process addendum base data similarly.\n",
    "    if addendum_appendix_pdf:\n",
    "        addendum_base_pdf_path = os.path.join(project_folder, addendum_appendix_pdf)\n",
    "        log_msg(f\"Scraped base data from addendum Appendix A PDF: {addendum_base_pdf_path}\", log_file)\n",
    "        addendum_base_data_df = extract_base_data(addendum_base_pdf_path, project_id, log_file)\n",
    "        if addendum_base_data_df.empty:\n",
    "            addendum_base_data_df = base_data_df.copy()\n",
    "    else:\n",
    "        addendum_base_data_df = base_data_df.copy()\n",
    "\n",
    "    # Check for missing values in base_data_df (assumed single-row DataFrame)\n",
    "    missing = [col for col in base_data_df.columns if pd.isna(base_data_df.at[0, col]) or base_data_df.at[0, col] in [\"\", \"None\"]]\n",
    "    if missing:\n",
    "        log_msg(f\"Missing base data columns in first Appendix A PDF: {missing}\", log_file)\n",
    "        # Iterate over additional original PDFs to update missing values.\n",
    "        for other_pdf in original_appendix_pdfs[1:]:\n",
    "            other_pdf_path = os.path.join(project_folder, other_pdf)\n",
    "            log_msg(f\"Attempting to update base data from: {other_pdf_path}\", log_file)\n",
    "            new_base_df = extract_base_data(other_pdf_path, project_id, log_file)\n",
    "            base_data_df = update_base_data(base_data_df, new_base_df)\n",
    "            missing = [col for col in base_data_df.columns if pd.isna(base_data_df.at[0, col]) or base_data_df.at[0, col] in [\"\", \"None\"]]\n",
    "            if not missing:\n",
    "                break\n",
    "        if missing:\n",
    "            log_msg(f\"After update, still missing: {missing}\", log_file)\n",
    "        else:\n",
    "            log_msg(\"Successfully updated all missing base data.\", log_file)\n",
    "\n",
    "    # Now process Attachment 2 PDFs.\n",
    "    attachment_data_list = []      # Regular Attachment 2 PDFs\n",
    "    attachment_addendum_list = []  # Addendum Attachment 2 PDFs\n",
    "\n",
    "    for f in os.listdir(project_folder):\n",
    "        if not f.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "        pdf_path = os.path.join(project_folder, f)\n",
    "        log_msg(f\"Accessing PDF: {pdf_path}\", log_file)\n",
    "        total_pdfs_accessed += 1\n",
    "        if is_attachment2_pdf(pdf_path):\n",
    "            log_msg(f\"Scraped this Attachment 2 PDF: {pdf_path}\", log_file)\n",
    "            table_df = extract_first_table(pdf_path, log_file)\n",
    "            if table_df.empty:\n",
    "                log_msg(f\"--> No table found in {pdf_path}. Skipping.\", log_file)\n",
    "                skipped_pdfs.append(f)\n",
    "                total_pdfs_skipped += 1\n",
    "                continue\n",
    "\n",
    "            # (If needed, rename common columns; if not, comment this block out)\n",
    "            common_cols = set(base_data_df.columns) & set(table_df.columns)\n",
    "            for col in common_cols:\n",
    "                table_df.rename(columns={col: f\"{col}_table\"}, inplace=True)\n",
    "\n",
    "            # Determine base data for this Attachment 2 PDF based solely on its own revision status.\n",
    "            if is_addendum_pdf(pdf_path):\n",
    "                log_msg(f\"--> {pdf_path} flagged as addendum.\", log_file)\n",
    "                base_df = addendum_base_data_df\n",
    "                addendum_pdfs.append(f)\n",
    "            else:\n",
    "                base_df = base_data_df\n",
    "                original_pdfs.append(f)\n",
    "\n",
    "            # Ensure unique column names\n",
    "            base_df = base_df.loc[:, ~base_df.columns.duplicated()]\n",
    "            table_df = table_df.loc[:, ~table_df.columns.duplicated()]\n",
    "\n",
    "            # Duplicate base data for each row of the table and merge side-by-side.\n",
    "            repeated_base = pd.concat([base_df] * len(table_df), ignore_index=True)\n",
    "            merged_df = pd.concat([repeated_base, table_df], axis=1)\n",
    "            if is_addendum_pdf(pdf_path):\n",
    "                attachment_addendum_list.append(merged_df)\n",
    "            else:\n",
    "                attachment_data_list.append(merged_df)\n",
    "            scraped_pdfs.append(f)\n",
    "            total_pdfs_scraped += 1\n",
    "        else:\n",
    "            log_msg(f\"--> {pdf_path} is not an Attachment 2 PDF. Skipping.\", log_file)\n",
    "            skipped_pdfs.append(f)\n",
    "            total_pdfs_skipped += 1\n",
    "\n",
    "    if not attachment_data_list and not attachment_addendum_list:\n",
    "        skipped_projects.add(project_id)\n",
    "    else:\n",
    "        scraped_projects.add(project_id)\n",
    "\n",
    "    project_attachment_df = pd.concat(attachment_data_list, ignore_index=True) if attachment_data_list else pd.DataFrame()\n",
    "    project_attachment_addendum_df = pd.concat(attachment_addendum_list, ignore_index=True) if attachment_addendum_list else pd.DataFrame()\n",
    "    return project_attachment_df, project_attachment_addendum_df\n",
    "\n",
    "\n",
    "\n",
    "# ------------------- CSV Saving & Summary Functions -------------------\n",
    "def save_to_csv(df, output_csv_path, data_type):\n",
    "    \"\"\"Cleans the DataFrame and saves it to a CSV file.\"\"\"\n",
    "    if df.empty:\n",
    "        print(f\"No data to save for {data_type}.\")\n",
    "        return\n",
    "    df = df.applymap(clean_string_cell)\n",
    "    df = df[~df.apply(lambda row: contains_phrase(row, \"Type of Upgrade\"), axis=1)]\n",
    "    df = reorder_columns(df)\n",
    "    print(f\"\\nColumns reordered for {data_type} as per specification.\")\n",
    "    if 'q_id' in df.columns:\n",
    "        df['q_id'] = pd.to_numeric(df['q_id'], errors='coerce')\n",
    "    try:\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"\\nData successfully saved to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {data_type} data to CSV: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "# ------------------- Main Processing Function -------------------\n",
    "def process_pdfs_in_folder():\n",
    "    \"\"\"\n",
    "    Processes all projects in ascending order (filtered via projects_to_process).\n",
    "    For each project, it:\n",
    "      - Checks for the project folder.\n",
    "      - Processes Attachment 2 PDFs by merging base data (from Appendix A PDFs) with\n",
    "        scraped table data (only the first nonempty table).\n",
    "      - Aggregates results across projects.\n",
    "    After processing, it saves the combined results to CSV files and prints a summary.\n",
    "    \"\"\"\n",
    "    global core_originals, core_addendums, total_pdfs_accessed, total_pdfs_scraped, total_pdfs_skipped\n",
    "    all_attachment_data = []\n",
    "    all_attachment_addendum_data = []\n",
    "\n",
    "    os.makedirs(os.path.dirname(LOG_FILE_PATH), exist_ok=True)\n",
    "    with open(LOG_FILE_PATH, 'w') as log_file:\n",
    "        log_msg(f\"Projects to process: {projects_to_process}\", log_file)\n",
    "        for project_id in projects_to_process:\n",
    "            project_folder = os.path.join(BASE_DIRECTORY, str(project_id))\n",
    "            if not os.path.exists(project_folder):\n",
    "                missing_projects.add(project_id)\n",
    "                log_msg(f\"Project folder not found: {project_folder}\", log_file)\n",
    "                continue\n",
    "            log_msg(f\"\\n--- Processing project {project_id} ---\", log_file)\n",
    "            proj_attach_df, proj_attach_add_df = process_attachment2_for_project(project_id, log_file)\n",
    "            if not proj_attach_df.empty:\n",
    "                all_attachment_data.append(proj_attach_df)\n",
    "            if not proj_attach_add_df.empty:\n",
    "                all_attachment_addendum_data.append(proj_attach_add_df)\n",
    "        \n",
    "        if all_attachment_data:\n",
    "            core_originals = pd.concat(all_attachment_data, ignore_index=True)\n",
    "            save_to_csv(core_originals, OUTPUT_CSV_PATH_ORIGINAL, \"originals\")\n",
    "        else:\n",
    "            log_msg(\"\\nNo Attachment 2 data processed for regular PDFs.\", log_file)\n",
    "        \n",
    "        if all_attachment_addendum_data:\n",
    "            core_addendums = pd.concat(all_attachment_addendum_data, ignore_index=True)\n",
    "            save_to_csv(core_addendums, OUTPUT_CSV_PATH_ADDENDUM, \"addendums\")\n",
    "        else:\n",
    "            log_msg(\"\\nNo Attachment 2 data processed for addendum PDFs.\", log_file)\n",
    "\n",
    "        total_projects_processed = len(scraped_projects) + len(skipped_projects)\n",
    "        log_msg(\"\\n=== Scraping Summary ===\", log_file)\n",
    "        log_msg(f\"Total Projects Processed: {total_projects_processed}\", log_file)\n",
    "        log_msg(f\"Total Projects Scraped: {len(scraped_projects)}\", log_file)\n",
    "        log_msg(f\"Total Projects Skipped: {len(skipped_projects)}\", log_file)\n",
    "        log_msg(f\"Total Projects Missing: {len(missing_projects)}\", log_file)\n",
    "        log_msg(f\"Total PDFs Accessed: {total_pdfs_accessed}\", log_file)\n",
    "        log_msg(f\"Total PDFs Scraped: {total_pdfs_scraped}\", log_file)\n",
    "        log_msg(f\"Total PDFs Skipped: {total_pdfs_skipped}\", log_file)\n",
    "        log_msg(\"\\nList of Scraped Projects: \" + str(sorted(scraped_projects)), log_file)\n",
    "        log_msg(\"\\nList of Skipped Projects: \" + str(sorted(skipped_projects)), log_file)\n",
    "        log_msg(\"\\nList of Missing Projects: \" + str(sorted(missing_projects)), log_file)\n",
    "        log_msg(\"\\nList of Scraped PDFs: \" + str(scraped_pdfs), log_file)\n",
    "        log_msg(\"\\nList of Skipped PDFs: \" + str(skipped_pdfs), log_file)\n",
    "        log_msg(\"\\nList of Addendum PDFs: \" + str(addendum_pdfs), log_file)\n",
    "        log_msg(\"\\nList of Original PDFs: \" + str(original_pdfs), log_file)\n",
    "        log_msg(\"\\nList of Style N PDFs (Skipped due to 'Network Upgrade Type'): \" + str(style_n_pdfs), log_file)\n",
    "        log_msg(\"\\nTotal Number of Style N PDFs: \" + str(len(style_n_pdfs)), log_file)\n",
    "        log_msg(\"\\nNumber of Original PDFs Scraped: \" + str(len([pdf for pdf in scraped_pdfs if pdf in original_pdfs])), log_file)\n",
    "        log_msg(\"Number of Addendum PDFs Scraped: \" + str(len([pdf for pdf in scraped_pdfs if pdf in addendum_pdfs])), log_file)\n",
    "\n",
    "# ------------------- Main -------------------\n",
    "def main():\n",
    "    process_pdfs_in_folder()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain COlumn names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: ['q_id', 'cluster', 'req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection', 'project_q1295tot789', 'unnamed_8', 'none_2', 'none_3', 'none_4', 'none_5', 'none_6', 'none_7', 'adn_project_q1295tot789', 'adn_none', 'adn_none_2', 'adn_none_3', 'adn_none_4', 'adn_none_5', 'adn_none_6', 'adn_none_7', 'element', 'interconnection_facilities_costs_x_1000_constant_dollar_2016', 'reliability_network_upgrades_costs_x_1000_constant_dollar_2016', 'delivery_network_upgrades_costs_x_1000_constant_dollar_2016', 'distribution_upgrades_costs_x_1000_constant_dollar_2016', 'total_estimated_costs_x_1000_constant_dollar_2016', 'total_estimated_costs_x_1000_escalated_constant_dollars_2022', 'estimated_time_to_construct_months_note_345_6', 'od_dollar_escalation_duration_months_note_345_6', 'adn_element', 'adn_interconnection_facilities_costs_x_1000_constant_dollar_2016', 'adn_reliability_network_upgrades_costs_x_1000_constant_dollar_2016', 'adn_delivery_network_upgrades_costs_x_1000_constant_dollar_2016', 'adn_distribution_upgrades_costs_x_1000_constant_dollar_2016', 'adn_total_estimated_costs_x_1000_constant_dollar_2016', 'adn_total_estimated_costs_x_1000_escalated_constant_dollars_2022', 'adn_estimated_time_to_construct_months_note_345_6', 'adn_od_dollar_escalation_duration_months_note_345_6', 'project_q1296tot834', 'adn_project_q1296tot834', 'total_estimated_costs_x_1000_escalated_constant_dollars_2021', 'project_q1297tot794', 'otherpotential_project_q1297tot794', 'otherpotential_none', 'otherpotential_none_2', 'otherpotential_none_3', 'otherpotential_none_4', 'otherpotential_none_5', 'otherpotential_none_6', 'otherpotential_none_7', 'adn_project_q1297tot794', 'project_q1299tot813', 'adn_project_q1299tot813', 'project_q1300tot822', 'adn_project_q1300tot822', 'project_q1301tot825_updated_as_of_2132017', 'adn_project_q1301tot825_updated_as_of_2132017', 'project_q1302tot830_updated_as_of_2132017', 'adn_project_q1302tot830_updated_as_of_2132017', 'project_q1305tot786_updated_as_of_2162017', 'adn_project_q1305tot786_updated_as_of_2162017', 'project_q1306tot792', 'adn_project_q1306tot792', 'project_q1307tot820', 'adn_project_q1307tot820', 'total_estimated_costs_x_1000_constant_dollar_2017', 'total_estimated_costs_x_1000_escalated_constant_dollars_od_year', 'estimated_time_to_construct_months_note_345_9_10', 'none_8', 'od_dollar_escalation_duration_months_note_345_9_10', 'none_9', 'none_10', 'otherpotential_other_potential_network_upgrades_note_1112', 'adn_area_delivery_network_upgrades', 'adn_total_estimated_costs_x_1000_constant_dollar_2017', 'adn_total_estimated_costs_x_1000_escalated_constant_dollars_od_year', 'adn_estimated_time_to_construct_months_note_345_9_10', 'adn_od_dollar_escalation_duration_months_note_345_9_10', 'project_q1309tot805', 'adn_project_q1309tot805', 'project_q1310tot803', 'adn_project_q1310tot803', 'project_q1311tot802', 'adn_project_q1311tot802', 'project_q1312tot812', 'adn_project_q1312tot812', 'project_q1313tot811', 'adn_project_q1313tot811', 'project_q1314tot810', 'adn_project_q1314tot810', 'project_q1315tot829', 'adn_project_q1315tot829', 'project_q1316_tot838_updated_as_of_2162017', 'adn_project_q1316_tot838_updated_as_of_2162017', 'project_q1317tot791_updated_as_of_2132017', 'adn_project_q1317tot791_updated_as_of_2132017', 'project_q1318tot790_updated_as_of_2132017', 'adn_project_q1318tot790_updated_as_of_2132017', 'project_q1319tot793_updated_as_of_2132017', 'adn_project_q1319tot793_updated_as_of_2132017', 'project_q1320tot807_updated_as_of_2132017', 'adn_project_q1320tot807_updated_as_of_2132017', 'project_q1321tot814', 'adn_project_q1321tot814', 'project_q1322tot795_updated_as_of_2132017', 'adn_project_q1322tot795_updated_as_of_2132017', 'project_q1323tot821_updated_as_of_2132017', 'adn_project_q1323tot821_updated_as_of_2132017', 'project_q1325tot818', 'adn_project_q1325tot818', 'project_q1326tot817', 'adn_project_q1326tot817', 'project_q1327tot806_updated_as_of_2132017', 'adn_project_q1327tot806_updated_as_of_2132017', 'project_q1328tot815_updated_as_of_2132017', 'adn_project_q1328tot815_updated_as_of_2132017', 'project_q1329tot823_updated_as_of_2132017', 'adn_project_q1329tot823_updated_as_of_2132017', 'project', 'antelope_66kv_relay_coordination_study', 'moorpark_c_66kv', 'project_q1330_tot827', 'adn_project_q1330_tot827', 'project_q1331tot828_updated_as_of_2132017', 'adn_project_q1331tot828_updated_as_of_2132017', 'project_q1332tot826_updated_as_of_2132017', 'adn_project_q1332tot826_updated_as_of_2132017', 'project_q1333tot824', 'adn_project_q1333tot824', 'project_q1334tot787', 'adn_project_q1334tot787', 'antelope_66kv', 'project_q1335tot833', 'adn_project_q1335tot833', 'project_q1336_tot804', 'otherpotential_project_q1336_tot804', 'adn_project_q1336_tot804', 'project_q1338tot801', 'adn_project_q1338tot801', 'project_q1339tot809', 'adn_project_q1339tot809', 'project_q1341tot796', 'otherpotential_project_q1341tot796', 'adn_project_q1341tot796', 'project_q1344tot797', 'otherpotential_project_q1344tot797', 'adn_project_q1344tot797', 'project_q1345tot836', 'otherpotential_project_q1345tot836', 'adn_project_q1345tot836', 'project_q1347tot837', 'otherpotential_project_q1347tot837', 'adn_project_q1347tot837']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/2710428394.py:6: DtypeWarning: Columns (2,7,15,24,25,26,28,29,32,35,37,38,41,42,43,44,45,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,151,152,153,154,155) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/output/Cluster 9/03_raw/rawdata_cluster9_style_J_originals.csv', dtype={'estimated_time_to_construct': str})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/03_raw/rawdata_cluster9_style_J_originals.csv', dtype={'estimated_time_to_construct': str})\n",
    "\n",
    "df['q_id'] = df['q_id'].astype('Int64')\n",
    "df['cluster'] = df['cluster'].astype('Int64')\n",
    "\n",
    "\n",
    "def clean_column_headers(headers):\n",
    "    \"\"\"Cleans column headers by normalizing and removing unwanted characters.\"\"\"\n",
    "    cleaned_headers = []  # Initialize an empty list to hold the cleaned header names.\n",
    "    for header in headers:  # Iterate over each header in the input.\n",
    "        if header is None:\n",
    "            header = \"\"  # If the header is None, set it to an empty string.\n",
    "        elif isinstance(header, str):  # Otherwise, if the header is a string:\n",
    "            #header = header.lower()  # Convert the header to lowercase.\n",
    "            header = re.sub(r'\\s+', ' ', header)  # Replace one or more whitespace characters with a single space.\n",
    "            #header = re.sub(r'\\(.*?\\)', '', header)  # Remove any text within parentheses (non-greedy).\n",
    "            header = re.sub(r'[^a-zA-Z0-9\\s()/+=_]', '', header)  # Remove any character that is not a letter, number, or whitespace.\n",
    "            header = header.strip()  # Remove any leading or trailing whitespace.\n",
    "        cleaned_headers.append(header)  # Append the cleaned header to the list.\n",
    "    return cleaned_headers  # Return the list of cleaned headers.\n",
    "\n",
    "\n",
    "\n",
    "df.columns = clean_column_headers(df.columns)\n",
    "\n",
    "def convert_to_snake_case(column_name):\n",
    "    column_name = column_name.strip().lower()\n",
    "    column_name = re.sub(r'[\\s\\-]+', '_', column_name)\n",
    "    column_name = re.sub(r'[^\\w]', '', column_name)\n",
    "    return column_name\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    if isinstance(value, str):\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "        value = value.replace('\\n', ' ').strip()\n",
    "    return value\n",
    "\n",
    "df = df.map(clean_string_cell)\n",
    "df.columns = [convert_to_snake_case(col) for col in df.columns]\n",
    "print(\"After cleaning:\", df.columns.tolist())\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itemized and Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: ['q_id', 'cluster', 'req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection', 'type_of_upgrade', 'upgrade', 'estimated_cost_x_1000', 'escalated_cost_x_1000', 'estimated_time_to_construct', 'item', 'max_time_to_construct']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_itemized.csv', dtype={'estimated_time_to_construct': str})\n",
    "\n",
    "df['q_id'] = df['q_id'].astype('Int64')\n",
    "df['cluster'] = df['cluster'].astype('Int64')\n",
    "\n",
    "\n",
    "def clean_column_headers(headers):\n",
    "    \"\"\"Cleans column headers by normalizing and removing unwanted characters.\"\"\"\n",
    "    cleaned_headers = []  # Initialize an empty list to hold the cleaned header names.\n",
    "    for header in headers:  # Iterate over each header in the input.\n",
    "        if header is None:\n",
    "            header = \"\"  # If the header is None, set it to an empty string.\n",
    "        elif isinstance(header, str):  # Otherwise, if the header is a string:\n",
    "            #header = header.lower()  # Convert the header to lowercase.\n",
    "            header = re.sub(r'\\s+', ' ', header)  # Replace one or more whitespace characters with a single space.\n",
    "            #header = re.sub(r'\\(.*?\\)', '', header)  # Remove any text within parentheses (non-greedy).\n",
    "            header = re.sub(r'[^a-zA-Z0-9\\s()/+=_]', '', header)  # Remove any character that is not a letter, number, or whitespace.\n",
    "            header = header.strip()  # Remove any leading or trailing whitespace.\n",
    "        cleaned_headers.append(header)  # Append the cleaned header to the list.\n",
    "    return cleaned_headers  # Return the list of cleaned headers.\n",
    "\n",
    "\n",
    "\n",
    "df.columns = clean_column_headers(df.columns)\n",
    "\n",
    "def convert_to_snake_case(column_name):\n",
    "    column_name = column_name.strip().lower()\n",
    "    column_name = re.sub(r'[\\s\\-]+', '_', column_name)\n",
    "    column_name = re.sub(r'[^\\w]', '', column_name)\n",
    "    return column_name\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    if isinstance(value, str):\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "        value = value.replace('\\n', ' ').strip()\n",
    "    return value\n",
    "\n",
    "df = df.map(clean_string_cell)\n",
    "df.columns = [convert_to_snake_case(col) for col in df.columns]\n",
    "print(\"After cleaning:\", df.columns.tolist())\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Originals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_2120/4099114739.py:6: DtypeWarning: Columns (2,7,15,24,25,26,28,29,32,35,37,38,41,42,43,44,45,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,151,152,153,154,155) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/pdf_scraper/output/Cluster 9/03_raw/rawdata_cluster9_style_J_originals.csv', dtype={'estimated_time_to_construct': str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itemized rows saved to 'costs_phase_1_cluster_14_itemized.csv'.\n",
      "Filtered Total rows saved to 'costs_phase_1_cluster_14_total.csv'.\n",
      "['PTO_IF' 'RNU' 'ADNU' 'Distribution Upgrades' 'LDNU']\n",
      "[1295 1296 1297 1299 1300 1301 1302 1305 1306 1307 1308 1309 1310 1311\n",
      " 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1325 1326\n",
      " 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1338 1339 1341 1344\n",
      " 1345 1347]\n",
      "[9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_2120/4099114739.py:881: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/03_raw/rawdata_cluster9_style_J_originals.csv', dtype={'estimated_time_to_construct': str})\n",
    "\n",
    "#df['q_id'] = df['q_id'].astype('Int64')\n",
    "df['cluster'] = df['cluster'].astype('Int64')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_column_headers(headers):\n",
    "    \"\"\"Cleans column headers by normalizing and removing unwanted characters.\"\"\"\n",
    "    cleaned_headers = []  # Initialize an empty list to hold the cleaned header names.\n",
    "    for header in headers:  # Iterate over each header in the input.\n",
    "        if header is None:\n",
    "            header = \"\"  # If the header is None, set it to an empty string.\n",
    "        elif isinstance(header, str):  # Otherwise, if the header is a string:\n",
    "            #header = header.lower()  # Convert the header to lowercase.\n",
    "            header = re.sub(r'\\s+', ' ', header)  # Replace one or more whitespace characters with a single space.\n",
    "            #header = re.sub(r'\\(.*?\\)', '', header)  # Remove any text within parentheses (non-greedy).\n",
    "            header = re.sub(r'[^a-zA-Z0-9\\s()/+=_]', '', header)  # Remove any character that is not a letter, number, or whitespace.\n",
    "            header = header.strip()  # Remove any leading or trailing whitespace.\n",
    "        cleaned_headers.append(header)  # Append the cleaned header to the list.\n",
    "    return cleaned_headers  # Return the list of cleaned headers.\n",
    "\n",
    "df.columns = clean_column_headers(df.columns)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#STEP 2: NAMING CONVENTION\n",
    "def convert_to_snake_case(column_name):\n",
    "    column_name = column_name.strip().lower()\n",
    "    column_name = re.sub(r'[\\s\\-]+', '_', column_name)\n",
    "    column_name = re.sub(r'[^\\w]', '', column_name)\n",
    "    return column_name\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    if isinstance(value, str):\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "        value = value.replace('\\n', ' ').strip()\n",
    "    return value\n",
    "\n",
    "df = df.map(clean_string_cell)\n",
    "df.columns = [convert_to_snake_case(col) for col in df.columns]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def move_dollar_values(df, source_column, target_column):\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, if the value in `source_column` starts with a '$',\n",
    "    move that value to `target_column` and clear the value in the source column.\n",
    "\n",
    "    Parameters:\n",
    "      df (pd.DataFrame): The input DataFrame.\n",
    "      source_column (str): The column to check for values starting with '$'.\n",
    "      target_column (str): The column to move the values into.\n",
    "\n",
    "    Returns:\n",
    "      pd.DataFrame: The modified DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure target_column exists; if not, create it filled with empty strings.\n",
    "    if target_column not in df.columns:\n",
    "        df[target_column] = \"\"\n",
    "    \n",
    "    # Create a boolean mask for rows where the source column starts with '$'\n",
    "    mask = df[source_column].astype(str).str.startswith('$', na=False)\n",
    "    \n",
    "    # Move the values: assign the source values to the target column where the mask is True.\n",
    "    df.loc[mask, target_column] = df.loc[mask, source_column]\n",
    "    \n",
    "    # Clear the source column values for those rows (set to empty string)\n",
    "    df.loc[mask, source_column] = \"\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Move values from 'unnamed_8' to a new column 'moved_value'\n",
    "#df = move_dollar_values(df, 'none_5', 'total_estimated_costs_x_1000_escalated_constant_dollars_od_year')\n",
    "\n",
    "\n",
    "#df = move_dollar_values(df, 'none_3','total_estimated_costs_x_1000_constant_dollar_2020')\n",
    "\n",
    "def remove_dollar_values_and_fill_nan(df, column):\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, if the value in the specified column starts with '$',\n",
    "    set that value to NaN. Also, replace any empty strings in that column with NaN.\n",
    "\n",
    "    Parameters:\n",
    "      df (pd.DataFrame): The input DataFrame.\n",
    "      column (str): The column to check and clean.\n",
    "\n",
    "    Returns:\n",
    "      pd.DataFrame: The modified DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure the column is treated as string\n",
    "    df[column] = df[column].astype(str)\n",
    "    \n",
    "    # Set values starting with '$' to NaN\n",
    "    mask = df[column].str.startswith('$', na=False)\n",
    "    df.loc[mask, column] = np.nan\n",
    "    \n",
    "    # Replace any remaining empty strings with NaN\n",
    "    df[column] = df[column].replace(\"\", np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = remove_dollar_values_and_fill_nan(df, 'unnamed_8')\n",
    "\n",
    "\n",
    "def insert_phrase_if_missing(df, target_columns, phrase=\"Area Delivery Network Upgrades\"):\n",
    "    \"\"\"\n",
    "    For each q_id group in df, for each column in target_columns:\n",
    "      - Check the first row (by current order) that is non-empty (not NaN, not blank, not 'na').\n",
    "      - If that cell does NOT contain the given phrase (case-insensitive),\n",
    "        insert a new row above it (within that q_id group) that sets that column to phrase,\n",
    "        leaving other columns as empty strings.\n",
    "    \n",
    "    Returns a new DataFrame with the added rows.\n",
    "    \"\"\"\n",
    "    # Work on a copy and reset index; create a temporary \"order\" column for precise control.\n",
    "    df = df.copy().reset_index(drop=True)\n",
    "    df[\"order\"] = df.index.astype(float)\n",
    "    \n",
    "    new_rows = []\n",
    "    \n",
    "    # Process each q_id group\n",
    "    for qid, group in df.groupby(\"q_id\", sort=False):\n",
    "        # For each target column, find the first non-empty cell.\n",
    "        for col in target_columns:\n",
    "            # We'll iterate over the group's index in order.\n",
    "            first_idx = None\n",
    "            first_val = None\n",
    "            for idx in group.index:\n",
    "                val = group.loc[idx, col]\n",
    "                # Convert to string and strip spaces.\n",
    "                # Treat NaN, empty strings, or \"na\"/\"NA\" as empty.\n",
    "                val_str = \"\" if pd.isna(val) else str(val).strip()\n",
    "                if val_str == \"\" or val_str.lower() == \"na\":\n",
    "                    continue\n",
    "                first_idx = idx\n",
    "                first_val = val_str\n",
    "                break\n",
    "            # If we found a non-empty value and it doesn't contain our phrase, insert a row.\n",
    "            if first_idx is not None:\n",
    "                if phrase.lower() not in first_val.lower():\n",
    "                    # Create a new row with the same q_id; leave all columns blank except col.\n",
    "                    new_row = {c: \"\" for c in df.columns if c != \"order\"}\n",
    "                    new_row[\"q_id\"] = qid\n",
    "                    new_row[col] = phrase\n",
    "                    # Set its order to be a bit before the first non-empty row.\n",
    "                    new_order = group.loc[first_idx, \"order\"] - 0.1\n",
    "                    new_row[\"order\"] = new_order\n",
    "                    new_rows.append(new_row)\n",
    "    \n",
    "    # If any rows were added, append them and sort by q_id then order.\n",
    "    if new_rows:\n",
    "        new_rows_df = pd.DataFrame(new_rows)\n",
    "        df = pd.concat([df, new_rows_df], ignore_index=True)\n",
    "        df = df.sort_values(by=[\"q_id\", \"order\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Drop the temporary order column.\n",
    "    df = df.drop(columns=[\"order\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = insert_phrase_if_missing(df, ['adn_area_delivery_network_upgrades'], phrase=\"Area Delivery Network Upgrades\")  \n",
    "\n",
    "\n",
    "def move_numeric_values(df, source_column, target_column):\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, if the value in `source_column` is purely numeric\n",
    "    (i.e. contains only an optional negative sign, digits, and an optional decimal part),\n",
    "    then move that value to `target_column` and clear the source cell.\n",
    "    \n",
    "    Parameters:\n",
    "      df (pd.DataFrame): The input DataFrame.\n",
    "      source_column (str): The column to check for numeric values.\n",
    "      target_column (str): The column to move the numeric values into.\n",
    "      \n",
    "    Returns:\n",
    "      pd.DataFrame: The modified DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure target_column exists\n",
    "    if target_column not in df.columns:\n",
    "        df[target_column] = np.nan\n",
    "\n",
    "    # Define a function to check if a value is purely numeric\n",
    "    def is_pure_numeric(val):\n",
    "        # If the value is already numeric (int, float) and not NaN, we consider it numeric.\n",
    "        if isinstance(val, (int, float)) and not pd.isna(val):\n",
    "            return True\n",
    "        # Otherwise, if it's a string, strip whitespace and check using regex.\n",
    "        if isinstance(val, str):\n",
    "            val_str = val.strip()\n",
    "            # Regex explanation:\n",
    "            # ^           : start of string\n",
    "            # -?          : optional minus sign\n",
    "            # \\d+         : one or more digits\n",
    "            # (\\.\\d+)?    : optional decimal point followed by one or more digits\n",
    "            # $           : end of string\n",
    "            if re.fullmatch(r'-?\\d+(\\.\\d+)?', val_str):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Create a boolean mask where the source_column values are pure numeric\n",
    "    mask = df[source_column].apply(is_pure_numeric)\n",
    "\n",
    "    # Move the values: assign the source values to the target column where the mask is True.\n",
    "    df.loc[mask, target_column] = df.loc[mask, source_column]\n",
    "    \n",
    "    # Clear the source column values for those rows (set to NaN)\n",
    "    df.loc[mask, source_column] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = move_numeric_values(df, 'otherpotential_none_3', 'otherpotential_none_5')\n",
    "df = move_numeric_values(df, 'otherpotential_none_4', 'otherpotential_none_6')\n",
    "df = move_numeric_values(df, 'otherpotential_none', 'otherpotential_none_3')\n",
    "df = move_numeric_values(df, 'otherpotential_none_2', 'otherpotential_none_4')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def merge_columns(df):\n",
    "\n",
    "    merge_columns_dict = {\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "        \"one_time_costs_b\": [\n",
    "            \"none_2\",\n",
    "            'adn_none_2',\n",
    "        ],\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "\n",
    " \n",
    "    \n",
    "        \"type_of_upgrade\": [\n",
    "            \n",
    "             'cost_category', \n",
    "           \n",
    "            \"cost_category_notes_1a_to_1f\",\n",
    "           \n",
    "            'other_potential_cost', \n",
    "            'other_potential_network_cost',\n",
    "            'area_delivery_network_upgrades', \n",
    "            'otherpotential_other_potential_network_upgrades_note_1h',\n",
    "            'adn_area_delivery_network_upgrades',\n",
    "            'project_q1295tot789',\n",
    "            'project_q1296tot834', \n",
    "             'project_q1297tot794', \n",
    "              'project_q1299tot813', \n",
    "              'project_q1300tot822', \n",
    "              'project_q1301tot825', \n",
    "              'project_q1302tot830', 'project_q1305tot786_updated_as_of_2162017', \n",
    "              'project_q1305tot786', 'project_q1306tot792', 'project_q1307tot820',\n",
    "              'other_potential_network_upgrades_note_1112', 'area_delivery_network_upgrades', 'project_q1309tot805', 'project_q1310tot803', 'project_q1311tot802', 'project_q1312tot812', 'project_q1313tot811', \n",
    "              'project_q1314tot810', 'project_q1315tot829', 'project_q1316_tot838_updated_as_of_2162017', 'project_q1316_tot838', 'project_q1317tot791', 'project_q1318tot790', 'project_q1319tot793', 'project_q1320tot807', \n",
    "              'project_q1321tot814', 'project_q1322tot795', 'project_q1323tot821', 'project_q1324tot819', 'project_q1325tot818', 'project_q1326tot817', 'project_q1327tot806', 'project_q1328tot815', 'project_q1329tot823', \n",
    "              'project', 'antelope_66kv_relay_coordination_study', 'moorpark_c_66kv', 'project_q1330_tot827', 'project_q1331tot828', 'project_q1332tot826', 'project_q1333tot824', 'project_q1334tot787',\n",
    "                'antelope_66kv', 'project_q1335tot833', 'project_q1336_tot804', 'project_q1338tot801', 'project_q1339tot809', \n",
    "                'qc9_phase_ii_study_report_attachment_2_escalated_cost_and_time_to_construct_for_interconnection_facilities_reliability_network_upgrades_delivery_network_upgrades_and_distribution_upgrades_project_q1341tot796_updated_as_of11132017',\n",
    "                  'project_q1341tot796', 'cost_category_notes_1a_to_1f',\n",
    "                  'other_potential_network_upgrades_note_1h', 'project_q1344tot797', 'project_q1345tot836', 'project_q1347tot837',\n",
    "                   'element', \n",
    "                   'adn_project_q1295tot789',\n",
    "                   'adn_element',\n",
    "                   'adn_project_q1296tot834', 'otherpotential_project_q1297tot794', \n",
    "                   'adn_project_q1297tot794', 'adn_project_q1299tot813', 'adn_project_q1300tot822', 'project_q1301tot825_updated_as_of_2132017', 'adn_project_q1301tot825_updated_as_of_2132017', 'adn_project_q1301tot825', 'project_q1302tot830_updated_as_of_2132017', 'adn_project_q1302tot830_updated_as_of_2132017', 'adn_project_q1302tot830', 'adn_project_q1305tot786_updated_as_of_2162017',\n",
    "                     'adn_project_q1305tot786', 'adn_project_q1306tot792', 'adn_project_q1307tot820', 'otherpotential_other_potential_network_upgrades_note_1112', \n",
    " \n",
    "            'adn_project_q1309tot805', 'adn_project_q1310tot803', 'adn_project_q1311tot802', 'adn_project_q1312tot812', 'adn_project_q1313tot811', 'adn_project_q1314tot810',\n",
    "              'adn_project_q1315tot829', 'adn_project_q1316_tot838_updated_as_of_2162017', 'adn_project_q1316_tot838', 'project_q1317tot791_updated_as_of_2132017', \n",
    "              'adn_project_q1317tot791_updated_as_of_2132017', 'adn_project_q1317tot791', 'project_q1318tot790_updated_as_of_2132017', 'adn_project_q1318tot790_updated_as_of_2132017', \n",
    "              'adn_project_q1318tot790', 'adn_project_q1319tot793', 'project_q1319tot793_updated_as_of_2132017', 'adn_project_q1319tot793_updated_as_of_2132017', 'adn_project_q1320tot807', \n",
    "              'project_q1320tot807_updated_as_of_2132017', 'adn_project_q1320tot807_updated_as_of_2132017', 'adn_project_q1321tot814', 'project_q1322tot795_updated_as_of_2132017', \n",
    "              'adn_project_q1322tot795_updated_as_of_2132017', 'adn_project_q1322tot795', 'project_q1323tot821_updated_as_of_2132017', 'adn_project_q1323tot821_updated_as_of_2132017', 'adn_project_q1323tot821',\n",
    "                'adn_project_q1324tot819', 'project_q1324tot819_updated_as_of_2132017', 'adn_project_q1324tot819_updated_as_of_2132017', 'adn_project_q1325tot818', 'adn_project_q1326tot817', \n",
    "                'project_q1327tot806_updated_as_of_2132017', 'adn_project_q1327tot806_updated_as_of_2132017', 'adn_project_q1327tot806', 'project_q1328tot815_updated_as_of_2132017',\n",
    "                'adn_project_q1328tot815_updated_as_of_2132017', 'adn_project_q1328tot815', 'project_q1329tot823_updated_as_of_2132017', 'adn_project_q1329tot823_updated_as_of_2132017',\n",
    "                  'adn_project_q1329tot823', 'adn_project_q1330_tot827', 'adn_project_q1331tot828', 'project_q1331tot828_updated_as_of_2132017', 'adn_project_q1331tot828_updated_as_of_2132017', \n",
    "                  'project_q1332tot826_updated_as_of_2132017', 'adn_project_q1332tot826_updated_as_of_2132017', 'adn_project_q1332tot826', 'adn_project_q1333tot824', 'adn_project_q1334tot787', \n",
    "                  'adn_project_q1335tot833', 'otherpotential_project_q1336_tot804', 'adn_project_q1336_tot804', 'adn_project_q1338tot801', 'adn_project_q1339tot809', 'otherpotential_project_q1341tot796', \n",
    "            'adn_project_q1341tot796', 'otherpotential_project_q1344tot797', 'adn_project_q1344tot797', 'otherpotential_project_q1345tot836', 'adn_project_q1345tot836', 'otherpotential_project_q1347tot837', 'adn_project_q1347tot837',\n",
    "            \"unnamed_8\",\n",
    "           \n",
    "         \n",
    "            \n",
    " \n",
    "             \n",
    "        ],\n",
    "        \"escalated_cost_x_1000\": [\n",
    "            \"total_escalated_costs_wo_itcc\",\n",
    "            \"total_estimated_costs_x_1000_escalated_constant_dollars_od_year\",\n",
    "            \"none_4\",\n",
    "             'otherpotential_none_4',\n",
    "            'total_escalated_costs_in_1000s',\n",
    "            'escalated_cost_in_1000s_note_8',\n",
    "            'total_estimated_costs_x',\n",
    "             'total_escalated_costs_in_1000s', \n",
    "             'total_escalated_costs_to_od_year_in_1000s',\n",
    "              'total_estimated_costs_x_1000_escalated_constant_dollars_od_year',\n",
    "              \n",
    "              'adn_unnamed_5',\n",
    "              'adn_none_4',\n",
    "              'total_estimated_costs_x_1000_escalated_constant_dollars_2022', \n",
    "             \n",
    "              'total_estimated_costs_x_1000_escalated_constant_dollars_od_year',\n",
    "              'total_estimated_costs_x_1000_escalated_constant_dollars_2021',\n",
    "              'adn_total_estimated_costs_x_1000_escalated_constant_dollars_2022',\n",
    "              'adn_total_estimated_costs_x_1000_escalated_constant_dollars_od_year',\n",
    "             \n",
    "              \n",
    "            \n",
    "\n",
    "        ],\n",
    "        \"estimated_cost_x_1000\": [\n",
    "            \"none_3\",\n",
    "            'total_costs_wo_itcc_cab',\n",
    "            'total_estimated_costs_x_1000_constant_dollar_2017',\n",
    "             'otherpotential_none_3',\n",
    "            \n",
    "            'adn_unnamed_2',\n",
    "            'adn_none_3',\n",
    "            'adn_total_estimated_costs_x_1000_constant_dollar_2017',\n",
    "            'total_estimated_costs_x_1000_constant_dollar_2018',\n",
    "        \n",
    "            'total_estimated_costs_x_1000_constant_dollar_2016', \n",
    "            'total_estimated_costs_x_1000_escalated_constant_dollars_2021', \n",
    "            'total_estimated_costs_x_1000_constant_dollar_2017', \n",
    "            'adn_interconnection_facilities_costs_x_1000_constant_dollar_2016', 'adn_reliability_network_upgrades_costs_x_1000_constant_dollar_2016', \n",
    "            'adn_delivery_network_upgrades_costs_x_1000_constant_dollar_2016', \n",
    "            'adn_distribution_upgrades_costs_x_1000_constant_dollar_2016',\n",
    "              'adn_total_estimated_costs_x_1000_constant_dollar_2016', \n",
    "             \n",
    "\n",
    "           #     'interconnection_facilities_costs_x_1000_constant_dollar_2016', 'reliability_network_upgrades_costs_x_1000_constant_dollar_2016', \n",
    "            #'delivery_network_upgrades_costs_x_1000_constant_dollar_2016', 'distribution_upgrades_costs_x_1000_constant_dollar_2016', \n",
    " \n",
    "        ],\n",
    "        \"estimated_time_to_construct\": [\n",
    "            'estimated_time_for_licensing_permitting_construction_months',\n",
    "            'estimated_time_to_construct_months',\n",
    "            'estimated_time_to_construct_months2',\n",
    "            'estimated_time_to_construct_months',\n",
    "            'estimated_time_to_construct_months',\n",
    "            'estimated_time_to_construct_months_note_1g',\n",
    "            'estimated_time_to_construct_months_note_1g',\n",
    "            'estimated_time_to_construct_months',\n",
    "            \"none_5\",\n",
    "            'estimated_time_to_construct_months',\n",
    "            'upgrade_duration_months',\n",
    "            'estimated_time_to_construct_months_note_12', \n",
    "            'adnu_duration_months',\n",
    "            'estimated_time_to',\n",
    "      \n",
    "            'none_12',\n",
    "            'estimated_duration_months',\n",
    "            'otherpotential_none_5',\n",
    "            'adn_unnamed_8', \n",
    "            'adn_none_5',\n",
    "            'adn_estimated_time_to_construct_months', \n",
    "            'estimated_time_to_construct_months_note_345_6', \n",
    "            'estimated_time_to_construct_months_note_345_9_10',\n",
    "            'estimated_time_to_construct_months_note_1g',\n",
    "            'adn_estimated_time_to_construct_months_note_345_6', \n",
    "            'adn_estimated_time_to_construct_months_note_345_9_10',\n",
    "            \n",
    "        ],\n",
    "        \"description\": [\"description\"],\n",
    "        \"capacity\": [\n",
    "            \"capacity\",\n",
    "            \"project size\",\n",
    "            \"project mw\",\n",
    "            \"mw at poi\"\n",
    "        ],\n",
    " \n",
    "        \"max_time_to_construct\": [\n",
    "            'maximum_escalation_duration_months',\n",
    "            'od_dollar_escalation_duration_months',\n",
    "            'od_dollar_escalation_duration_months',\n",
    "            'od_dollar_escalation_duration_months_note1g',\n",
    "            'od_dollar_escalation_duration_months_note1g',\n",
    "            \"none_6\",\n",
    "            'maximum_escalation_duration_months',\n",
    "            'od_dollar_escalation',\n",
    "            'maximum_project_duration_months',\n",
    "            'otherpotential_none_6',\n",
    "            'adn_unnamed_11', \n",
    "            'adn_none_6',\n",
    "            \n",
    "            'adn_od_dollar_escalation_duration_months',\n",
    "            'od_dollar_escalation_duration_months_note_345_6',\n",
    "            'od_dollar_escalation_duration_months_note_345_9_10', \n",
    "             'od_dollar_escalation_duration_months_note_1g',\n",
    "             'adn_od_dollar_escalation_duration_months_note_345_6',\n",
    "             'adn_od_dollar_escalation_duration_months_note_345_9_10',\n",
    "            \n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "        # Identify unnamed columns\n",
    "    unnamed_columns = [col for col in df.columns if pd.isna(col) or col.strip() == \"\" or col.startswith(\"Unnamed\")]\n",
    "    if unnamed_columns:\n",
    "        merge_columns_dict[\"type_of_upgrade\"].extend(unnamed_columns)\n",
    "\n",
    "    for new_col, old_cols in merge_columns_dict.items():\n",
    "        existing_cols = [col for col in old_cols if col in df.columns]\n",
    "        if existing_cols:\n",
    "            df[new_col] = df[existing_cols].bfill(axis=1).iloc[:, 0]\n",
    "            cols_to_drop = [col for col in existing_cols if col != new_col]\n",
    "            if cols_to_drop:\n",
    "                df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = merge_columns(df)\n",
    "df.drop([   'adn_none', 'adn_none_7','otherpotential_none_2','otherpotential_none', 'otherpotential_none_7',\n",
    "         'one_time_costs_b','none_8', 'none_9', 'none_7' ,'none_10',  'interconnection_facilities_costs_x_1000_constant_dollar_2016', 'reliability_network_upgrades_costs_x_1000_constant_dollar_2016', \n",
    "            'delivery_network_upgrades_costs_x_1000_constant_dollar_2016', 'distribution_upgrades_costs_x_1000_constant_dollar_2016', ], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def reorder_columns(df):\n",
    "    \"\"\"\n",
    "    Reorders the columns of the DataFrame based on the specified order.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to reorder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The reordered DataFrame.\n",
    "    \"\"\"\n",
    "    desired_order = [\n",
    "        \"q_id\",\n",
    "        \"cluster\",\n",
    "        \"req_deliverability\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"capacity\",\n",
    "        \"point_of_interconnection\",\n",
    "        \"type_of_upgrade\",\n",
    "        \"upgrade\",\n",
    "        \"description\",\n",
    "        \"cost_allocation_factor\",\n",
    "        \"estimated_cost_x_1000\",\n",
    "        \"escalated_cost_x_1000\",\n",
    " \n",
    "        \"estimated_time_to_construct\",\n",
    "    ]\n",
    "\n",
    "    # Start with desired columns that exist in the DataFrame\n",
    "    existing_desired = [col for col in desired_order if col in df.columns]\n",
    "\n",
    "    # Then add the remaining columns\n",
    "    remaining = [col for col in df.columns if col not in existing_desired]\n",
    "\n",
    "    # Combine the two lists\n",
    "    new_order = existing_desired + remaining\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    df = df[new_order]\n",
    "\n",
    "    return df        \n",
    "\n",
    "\n",
    "df= reorder_columns(df)\n",
    "\n",
    "\n",
    "\n",
    "df = df[~df.apply(lambda row: row.astype(str).isin([\"Constant 2016 Dollar in $1000s (Estimate)\", \"Eastern\",\"Note (h)\"]).any(), axis=1)]\n",
    "df = df[~df.apply(lambda row: any(str(cell).startswith(\"Project #:\") for cell in row), axis=1)]\n",
    "df = df[~df.apply(lambda row: any(str(cell).startswith(\"Location Constrained Resource Interconnection Facilities\") for cell in row), axis=1)]\n",
    "\n",
    "\n",
    "\n",
    "df = df[df['type_of_upgrade'].notna() & (df['type_of_upgrade'].astype(str).str.strip() != \"\")]\n",
    "\n",
    "df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/03_raw/rawdata_cluster9_style_J.csv', index=False)\n",
    "\n",
    "\n",
    "def process_upgrade_columns(df):\n",
    "    \"\"\"\n",
    "    Given a DataFrame df with a column \"type_of_upgrade\" that contains both group headers and upgrade data,\n",
    "    this function:\n",
    "      1. Inserts a new column \"upgrade\" as a duplicate of \"type_of_upgrade\" (placed immediately after it).\n",
    "      2. Renames rows in \"type_of_upgrade\" that contain specific phrases as follows:\n",
    "           - If it contains \"Interconnection Facilities\", rename to \"PTO_IF\" (or \"PTO_IF Total\" if \"Total\" is present)\n",
    "           - If it contains \"Reliability Network Upgrade\", rename to \"RNU\" (or \"RNU Total\" if \"Total\" is present)\n",
    "           - If it contains \"Local Delivery Network Upgrades\", rename to \"LDNU\" (or \"LDNU Total\" if \"Total\" is present)\n",
    "           - If it contains \"Area Deliverability Network Upgrades\", rename to \"ADNU\" (or \"ADNU Total\" if \"Total\" is present)\n",
    "           - If it contains \"Distribution Upgrades\", leave it as is.\n",
    "      3. Creates a temporary column that only holds the header values (from rows that were detected as header rows) and forward-fills it downward.\n",
    "         The forward fill stops (i.e. does not fill into a row) if that row\u2019s original \"type_of_upgrade\" contains any of the \"total\" indicators.\n",
    "      4. Replaces \"type_of_upgrade\" with the forward-filled header values.\n",
    "      5. Drops the rows that originally were header rows.\n",
    "      6. This deletes any rows which are either Total or Subtotal or Total cost assigned, the reason is some proejcts have multiple pdfs thus we rather calculate the total in the end.\n",
    "      \n",
    "    Returns the updated DataFrame.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 1. Create a new column \"upgrade\" immediately after \"type_of_upgrade\"\n",
    "    loc = df.columns.get_loc(\"type_of_upgrade\")\n",
    "    df.insert(loc+1, \"upgrade\", df[\"type_of_upgrade\"])\n",
    "    \n",
    "    # 2. Define a helper to rename header rows.\n",
    "    def rename_header(val):\n",
    "        # If the cell contains any of these phrases, rename accordingly.\n",
    "        # We'll check using the substring test (case-sensitive) per your request.\n",
    "        if \"Interconnection Facilities\" in val:\n",
    "            return \"PTO_IF\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        elif \"Reliability Network Upgrade\" in val:\n",
    "            return \"RNU\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        elif \"Local Delivery Network Upgrades\" in val:\n",
    "            return \"LDNU\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        elif \"Area Deliverability Network Upgrades\" in val:\n",
    "            return \"ADNU\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        elif \"Distribution Upgrades\" in val:\n",
    "            return val  # leave unchanged\n",
    "        elif \"Conditional Assigned Network Upgrades\" in val:\n",
    "            return  (\"Total \" if \"Total\" in val else \"\") + \"CANU\" \n",
    "        elif \"Non-Allocated IRNU\" in val:\n",
    "            return  (\"Total \" if \"Total\" in val else \"\") + \"Non-Allocated IRNU\"\n",
    "        elif \"Area Delivery Network Upgrades\" in val:\n",
    "            return \"ADNU\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        else:\n",
    "            return val\n",
    "    \n",
    "    # 3. Identify header rows. We consider a row to be a header row if its \"type_of_upgrade\" cell \n",
    "    # contains any of the target phrases.\n",
    "    target_phrases = [\n",
    "        \"Interconnection Facilities\",\n",
    "        \"Reliability Network Upgrade\",\n",
    "        \"Local Delivery Network Upgrades\",\n",
    "        \"Area Deliverability Network Upgrades\",\n",
    "        \"Distribution Upgrades\",\n",
    "        \"Conditional Assigned Network Upgrades\",\n",
    "        \"Non-Allocated IRNU\",\n",
    "        \"Area Delivery Network Upgrades\",\n",
    "\n",
    "    ]\n",
    "    # Create a boolean mask for header rows.\n",
    "    header_mask = df[\"type_of_upgrade\"].apply(lambda x: any(phrase in x for phrase in target_phrases))\n",
    "    \n",
    "    # Apply renaming to the header rows.\n",
    "    df.loc[header_mask, \"type_of_upgrade\"] = df.loc[header_mask, \"type_of_upgrade\"].apply(rename_header)\n",
    "    \n",
    "    # 4. Create a temporary column 'header_temp' that holds only the header rows, then forward fill it.\n",
    "    df[\"header_temp\"] = df[\"type_of_upgrade\"].where(header_mask)\n",
    "    df[\"header_temp\"] = df[\"header_temp\"].ffill()\n",
    "    \n",
    "    # We want to stop the forward fill if we encounter a row that indicates totals.\n",
    "    # Define a simple function that returns True if a cell contains \"Total\" or \"Subtotal\" or \"Total cost assigned\".\n",
    "    def is_total_indicator(val):\n",
    "        return (\"Total\" in val) or (\"Subtotal\" in val) or (\"Total cost assigned\" in val)\n",
    "    \n",
    "    # For rows that themselves are total indicators in the \"upgrade\" column, do not forward-fill (set header_temp to NaN)\n",
    "    df.loc[df[\"upgrade\"].apply(lambda x: is_total_indicator(x)), \"header_temp\"] = None\n",
    "    \n",
    "    # Now, replace the \"type_of_upgrade\" column with the forward-filled header\n",
    "    df[\"type_of_upgrade\"] = df[\"header_temp\"]\n",
    "    df.drop(\"header_temp\", axis=1, inplace=True)\n",
    "    \n",
    "    # 5. Finally, drop the rows that were header rows (i.e. where header_mask is True)\n",
    "    df = df[~header_mask].reset_index(drop=True)\n",
    "    \n",
    "    # Also, drop any rows that have an empty \"type_of_upgrade\"\n",
    "    df = df[df[\"type_of_upgrade\"].notna() & (df[\"type_of_upgrade\"].str.strip() != \"\")]\n",
    "    \n",
    "    return df\n",
    "\n",
    " \n",
    "\n",
    "df = process_upgrade_columns(df)\n",
    "\n",
    "\n",
    "df = df[~df.apply(lambda row: any(str(cell).startswith(\"Total Escalated Costs w/o ITCC\") for cell in row), axis=1)] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "mappings = {\n",
    " \"PTO\": 'PTO_IF',\n",
    " \"PNU\": \"OPNU\",\n",
    " \"PTO's Interconnection Facilities\": \"PTO_IF\",\n",
    " \"RNUs, Estimated Costs, and Estimated Time to Construct Summary\": \"RNU\",\n",
    " \"Non-Allocated IRNU\": \"RNU\",\n",
    " \"Total Non-Allocated IRNU\": \"Total RNU\",\n",
    " }\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "  \n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: mappings.get(x, x) if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['item'] = df.apply(\n",
    "    lambda row: 'no' if (\n",
    "        (pd.notna(row.get('type_of_upgrade')) and 'Total' in str(row['type_of_upgrade'])) or\n",
    "        (pd.notna(row.get('cost_allocation_factor')) and 'Total' in str(row['cost_allocation_factor']))\n",
    "    ) else 'yes',\n",
    "    axis=1\n",
    ")\n",
    "   \n",
    "\n",
    "\n",
    " \n",
    "   \n",
    " \n",
    " \n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "# Step 7: Remove $ signs and convert to numeric\n",
    "import re\n",
    "\n",
    "def clean_currency(value):\n",
    "    \"\"\"\n",
    "    Cleans a string by explicitly removing $, *, (Note 2), and similar patterns,\n",
    "    then converts it to a numeric value.\n",
    "    \"\"\"\n",
    "    if isinstance(value, str):\n",
    "        # Explicitly remove $, *, and any \"(Note ...)\"\n",
    "        value = value.replace('$', '').replace('*', '')\n",
    "        value = re.sub(r'\\(Note \\d+\\)', '', value)  # Remove patterns like \"(Note 2)\"\n",
    "        value = value.replace(',', '').strip()  # Remove commas and extra spaces\n",
    "    try:\n",
    "        return pd.to_numeric(value)\n",
    "    except ValueError:\n",
    "        return pd.NA  # Return NaN for invalid entries\n",
    "\n",
    "\n",
    "# Clean the specific columns\n",
    "for col in ['estimated_cost_x_1000', 'escalated_cost_x_1000']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "df = df.drop_duplicates(subset=['q_id','type_of_upgrade','upgrade', 'estimated_cost_x_1000', 'escalated_cost_x_1000'])   \n",
    "\n",
    "df = df[~df['upgrade'].astype(str).isin([\n",
    "    \"CANUIRNU\", \n",
    "    \"CANUGRNU\", \n",
    "    \"SCD\",\n",
    "    \"CANU-LDNU\",\n",
    "    \"IRNUs\",\n",
    "    \"GRNUs\",\n",
    "    \"Maximum Cost Responsibility (Network Upgrades)\",\n",
    "    \"Network Upgrade\",\n",
    "\n",
    "\n",
    "])]\n",
    "\n",
    "\n",
    "\n",
    "# Create Total rows\n",
    "new_rows = []\n",
    "columns_to_sum = ['estimated_cost_x_1000', 'escalated_cost_x_1000']\n",
    "columns_to_populate = ['cluster', 'req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection']\n",
    "\n",
    "for q_id, group in df.groupby('q_id', as_index=False):\n",
    "    unique_upgrades = group['type_of_upgrade'].dropna().unique()\n",
    "    for upgrade in unique_upgrades:\n",
    "        if pd.isna(upgrade):\n",
    "            continue\n",
    "        \n",
    "        rows = group[group['type_of_upgrade'] == upgrade]\n",
    "\n",
    "                # Check if a Total row already exists for this (q_id, upgrade)\n",
    "        total_exists = group[\n",
    "            (group['type_of_upgrade'] == upgrade) & (group['item'] == 'no')\n",
    "        ].shape[0] > 0\n",
    "        \n",
    "        if total_exists:\n",
    "             \n",
    "            continue\n",
    "\n",
    "\n",
    " \n",
    "        \n",
    "        \n",
    "        if not total_exists:\n",
    "            # If only one row exists, duplicate it as the total row\n",
    "            if len(rows) == 1:\n",
    "\n",
    "                total_row = {col: '' for col in df.columns}  # Initialize all columns as empty strings\n",
    "\n",
    "                # Populate the necessary fields\n",
    "                total_row['q_id'] = q_id\n",
    "                total_row['type_of_upgrade'] = f\"Total {upgrade}\"\n",
    "                total_row['item'] = 'no'\n",
    "\n",
    "                # Populate specified columns from the existing row\n",
    "                first_row = rows.iloc[0]\n",
    "                for col in columns_to_populate:\n",
    "                    if col in df.columns:\n",
    "                        total_row[col] = first_row[col]\n",
    "\n",
    "                # Sum the numeric columns (single row, so it remains the same)\n",
    "                for col in columns_to_sum:\n",
    "                    if col in rows.columns:\n",
    "                        total_row[col] = rows[col].sum()\n",
    "                    else:\n",
    "                        total_row[col] = 0  # Default to 0 if column is missing\n",
    "\n",
    "                new_rows.append(total_row)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "            \n",
    "            # If multiple rows exist, sum numeric columns and create a total row\n",
    "            elif len(rows) > 1:\n",
    "                total_row = {col: '' for col in df.columns}  # Initialize all columns as empty strings\n",
    "\n",
    "                # Populate the necessary fields\n",
    "                total_row['q_id'] = q_id\n",
    "                total_row['type_of_upgrade'] = f\"Total {upgrade}\"\n",
    "                total_row['item'] = 'no'\n",
    "\n",
    "                # Populate the specified columns from the first row in the group\n",
    "                first_row = rows.iloc[0]\n",
    "                for col in columns_to_populate:\n",
    "                    if col in df.columns:\n",
    "                        total_row[col] = first_row[col]\n",
    "\n",
    "                # Sum the numeric columns\n",
    "                for col in columns_to_sum:\n",
    "                    if col in rows.columns:\n",
    "                        total_row[col] = rows[col].sum()\n",
    "                    else:\n",
    "                        total_row[col] = 0  # Default to 0 if column is missing\n",
    "\n",
    "                new_rows.append(total_row)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "if new_rows:\n",
    "    total_rows_df = pd.DataFrame(new_rows)\n",
    "    for col in df.columns:\n",
    "        if col not in total_rows_df.columns:\n",
    "            total_rows_df[col] = None\n",
    "    total_rows_df = total_rows_df[df.columns]\n",
    "    df = pd.concat([df, total_rows_df], ignore_index=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Update 'item' column based on Total in type_of_upgrade or cost_allocation_factor\n",
    "df['item'] = df.apply(\n",
    "    lambda row: 'no' if (\n",
    "        'Total' in str(row.get('type_of_upgrade', '')) or \n",
    "        'Total' in str(row.get('cost_allocation_factor', ''))\n",
    "    ) else 'yes',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Step 8: Move 'item' column next to 'type_of_upgrade'\n",
    "if 'item' in df.columns and 'type_of_upgrade' in df.columns:\n",
    "    cols = df.columns.tolist()\n",
    "    item_index = cols.index('item')\n",
    "    type_index = cols.index('type_of_upgrade')\n",
    "    if item_index < type_index:\n",
    "        cols.insert(type_index + 1, cols.pop(item_index))\n",
    "    else:\n",
    "        cols.insert(type_index + 1, cols.pop(item_index))\n",
    "    df = df[cols]\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "def clean_estimated_time(value):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub(r'(\\d+(?:-\\w+)*)\\s+\\w+.*$', r'\\1', value, flags=re.IGNORECASE).strip()\n",
    "    return value\n",
    "\n",
    "if 'estimated_time_to_construct' in df.columns:\n",
    "    df['estimated_time_to_construct'] = df['estimated_time_to_construct'].apply(clean_estimated_time)\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: re.sub(r'\\s*\\(note \\d+\\)', '', x, flags=re.IGNORECASE).strip() if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    " \n",
    "mappings = {\n",
    " \"PTO\": 'PTO_IF',\n",
    " \"PNU\": \"OPNU\",\n",
    " \"PTO's Interconnection Facilities\": \"PTO_IF\",\n",
    " \"RNUs, Estimated Costs, and Estimated Time to Construct Summary\": \"RNU\",\n",
    "'Total PTO_IF': 'PTO_IF',\n",
    "'PTO_IF Total': 'PTO_IF',\n",
    " 'Total RNU': 'RNU',\n",
    " 'RNU Total': 'RNU',\n",
    " 'Total LDNU': 'LDNU',\n",
    " 'Total OPNU' : 'OPNU',\n",
    " 'Total CANU': 'CANU',\n",
    " 'Total LOPNU': 'LOPNU',\n",
    " 'Total ADNU': 'ADNU',\n",
    " 'LDNU Total': 'LDNU',\n",
    " 'Total Distribution Upgrades': 'Distribution Upgrades',\n",
    " 'Distribution Upgrades Total': 'Distribution Upgrades',\n",
    " 'Total Potential Distribution Upgrades': 'Potential Distribution Upgrades',\n",
    "}\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "  \n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: mappings.get(x, x) if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    previous_type_of_upgrade = None\n",
    "    for i in range(len(df)):\n",
    "        if df.at[i, 'type_of_upgrade'] == 'Total':\n",
    "            if previous_type_of_upgrade is not None:\n",
    "                df.at[i, 'type_of_upgrade'] = previous_type_of_upgrade\n",
    "        else:\n",
    "            previous_type_of_upgrade = df.at[i, 'type_of_upgrade']\n",
    "\n",
    "numeric_columns = [\n",
    "    \n",
    "    'estimated_cost_x_1000',\n",
    "    'estimated_time_to_construct',\n",
    "     \n",
    "    'adnu_cost_rate_x_1000',\n",
    "    'escalated_cost_x_1000',\n",
    "     \n",
    "]\n",
    "non_numeric_columns = ['type_of_upgrade', 'upgrade', 'description']\n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: 'None' if pd.isna(x) else x)\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace('-', pd.NA)\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "if 'original_order' in df.columns and 'q_id' in df.columns:\n",
    "    df['original_order'] = df.index\n",
    "    df = df.sort_values(by=['q_id', 'original_order'], ascending=[True, True])\n",
    "    df = df.drop(columns=['original_order'])\n",
    "\n",
    "\n",
    "def reorder_columns(df):\n",
    "    \"\"\"\n",
    "    Reorders the columns of the DataFrame based on the specified order.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to reorder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The reordered DataFrame.\n",
    "    \"\"\"\n",
    "    desired_order = [\n",
    "        \"q_id\",\n",
    "        \"cluster\",\n",
    "        \"req_deliverability\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"capacity\",\n",
    "        \"point_of_interconnection\",\n",
    "        \"type_of_upgrade\",\n",
    "        \"upgrade\",\n",
    "        \"description\",\n",
    "        \"cost_allocation_factor\",\n",
    "        \"estimated_cost_x_1000\",\n",
    "        \"escalated_cost_x_1000\",\n",
    "        \"total_estimated_cost_x_1000\",\n",
    "        \"total_estimated_cost_x_1000_escalated\",\n",
    "        \"estimated_time_to_construct\",\n",
    "    ]\n",
    "\n",
    "    # Start with desired columns that exist in the DataFrame\n",
    "    existing_desired = [col for col in desired_order if col in df.columns]\n",
    "\n",
    "    # Then add the remaining columns\n",
    "    remaining = [col for col in df.columns if col not in existing_desired]\n",
    "\n",
    "    # Combine the two lists\n",
    "    new_order = existing_desired + remaining\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    df = df[new_order]\n",
    "\n",
    "    return df        \n",
    "\n",
    "\n",
    "df= reorder_columns(df)\n",
    "df = df[~df['upgrade'].astype(str).isin([\n",
    "    \"CANUIRNU\", \n",
    "    \"CANUGRNU\", \n",
    "    \"SCD\",\n",
    "    \"CANU-LDNU\",\n",
    "    \"IRNUs\",\n",
    "    \"GRNUs\",\n",
    "    \"Maximum Cost Responsibility (Network Upgrades)\",\n",
    "    \"Network Upgrade\",\n",
    "    \"Plan of Service\",\n",
    "\n",
    "\n",
    "])]\n",
    "df = remove_dollar_values_and_fill_nan(df, 'max_time_to_construct')\n",
    "# Save itemized and totals separately\n",
    "if 'item' in df.columns:\n",
    "    itemized_df = df[df['item'] == 'yes']\n",
    " \n",
    "    #itemized_df = itemized_df.drop_duplicates(subset=['q_id','type_of_upgrade','upgrade']) \n",
    "    itemized_df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_itemized.csv', index=False)\n",
    "\n",
    "    totals_columns = ['upgrade', 'description', 'cost_allocation_factor', 'estimated_time_to_construct']\n",
    "    existing_totals_columns = [col for col in totals_columns if col in df.columns]\n",
    "    totals_df = df[df['item'] == 'no'].drop(columns=existing_totals_columns, errors='ignore')\n",
    "    # Define the cost columns.\n",
    "    cost_cols = ['estimated_cost_x_1000', 'escalated_cost_x_1000']\n",
    "\n",
    "    # Build an aggregation dictionary:\n",
    "    # For columns not in grouping or cost_cols, we assume they are identical and take the first value.\n",
    "    agg_dict = {col: 'first' for col in totals_df.columns \n",
    "                if col not in ['q_id', 'type_of_upgrade'] + cost_cols}\n",
    "\n",
    "    # For the cost columns, we want to sum them.\n",
    "    agg_dict.update({col: 'sum' for col in cost_cols})\n",
    "\n",
    "    \n",
    "\n",
    "    # Group by both q_id and type_of_upgrade using the aggregation dictionary.\n",
    "    totals_df = totals_df.groupby(['q_id', 'type_of_upgrade'], as_index=False).agg(agg_dict)\n",
    "    totals_df = reorder_columns(totals_df)\n",
    "    totals_df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_total.csv', index=False)\n",
    "\n",
    "print(f\"Itemized rows saved to 'costs_phase_1_cluster_14_itemized.csv'.\")\n",
    "print(f\"Filtered Total rows saved to 'costs_phase_1_cluster_14_total.csv'.\")\n",
    "\n",
    "\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    print(df['type_of_upgrade'].unique())\n",
    "\n",
    "if 'q_id' in df.columns:\n",
    "    print(df['q_id'].unique())\n",
    "\n",
    "if 'cluster' in df.columns:\n",
    "    print(df['cluster'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addendum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: ['q_id', 'cluster', 'req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection', 'project_q1306tot792_updated_as_of_2222017', 'unnamed_8', 'none_2', 'none_3', 'none_4', 'none_5', 'none_6', 'none_7', 'adn_project_q1306tot792_updated_as_of_2222017', 'adn_none', 'adn_none_2', 'adn_none_3', 'adn_none_4', 'adn_none_5', 'adn_none_6', 'adn_none_7', 'project_q1307tot820_updated_as_of_2222017', 'adn_project_q1307tot820_updated_as_of_2222017', 'project_q1308tot808_updated_as_of_2222017', 'adn_project_q1308tot808_updated_as_of_2222017', 'project_q1309tot805_updated_as_of_2222017', 'adn_project_q1309tot805_updated_as_of_2222017', 'project_q1310tot803_updated_as_of_2222017', 'adn_project_q1310tot803_updated_as_of_2222017', 'project_q1312tot812_updated_as_of_2222017', 'adn_project_q1312tot812_updated_as_of_2222017', 'project_q1313tot811_updated_as_of_2222017', 'adn_project_q1313tot811_updated_as_of_2222017', 'project_q1314tot810_updated_as_of_2222017', 'adn_project_q1314tot810_updated_as_of_2222017', 'project_q1315tot829_updated_as_of_2222017', 'adn_project_q1315tot829_updated_as_of_2222017', 'element', 'total_estimated_costs_x_1000_constant_dollar_2017', 'total_estimated_costs_x_1000_escalated_constant_dollars_od_year', 'estimated_time_to_construct_months_note_345_9_10', 'none_8', 'od_dollar_escalation_duration_months_note_345_9_10', 'none_9', 'none_10', 'otherpotential_other_potential_network_upgrades_note_1112', 'otherpotential_none', 'otherpotential_none_2', 'otherpotential_none_3', 'otherpotential_none_4', 'adn_area_delivery_network_upgrades', 'adn_total_estimated_costs_x_1000_constant_dollar_2017', 'adn_total_estimated_costs_x_1000_escalated_constant_dollars_od_year', 'adn_estimated_time_to_construct_months_note_345_9_10', 'adn_od_dollar_escalation_duration_months_note_345_9_10']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/03_raw/rawdata_cluster9_style_J_addendums.csv', dtype={'estimated_time_to_construct': str})\n",
    "\n",
    "df['q_id'] = df['q_id'].astype('Int64')\n",
    "df['cluster'] = df['cluster'].astype('Int64')\n",
    "\n",
    "\n",
    "def clean_column_headers(headers):\n",
    "    \"\"\"Cleans column headers by normalizing and removing unwanted characters.\"\"\"\n",
    "    cleaned_headers = []  # Initialize an empty list to hold the cleaned header names.\n",
    "    for header in headers:  # Iterate over each header in the input.\n",
    "        if header is None:\n",
    "            header = \"\"  # If the header is None, set it to an empty string.\n",
    "        elif isinstance(header, str):  # Otherwise, if the header is a string:\n",
    "            #header = header.lower()  # Convert the header to lowercase.\n",
    "            header = re.sub(r'\\s+', ' ', header)  # Replace one or more whitespace characters with a single space.\n",
    "            #header = re.sub(r'\\(.*?\\)', '', header)  # Remove any text within parentheses (non-greedy).\n",
    "            header = re.sub(r'[^a-zA-Z0-9\\s()/+=_]', '', header)  # Remove any character that is not a letter, number, or whitespace.\n",
    "            header = header.strip()  # Remove any leading or trailing whitespace.\n",
    "        cleaned_headers.append(header)  # Append the cleaned header to the list.\n",
    "    return cleaned_headers  # Return the list of cleaned headers.\n",
    "\n",
    "\n",
    "\n",
    "df.columns = clean_column_headers(df.columns)\n",
    "\n",
    "def convert_to_snake_case(column_name):\n",
    "    column_name = column_name.strip().lower()\n",
    "    column_name = re.sub(r'[\\s\\-]+', '_', column_name)\n",
    "    column_name = re.sub(r'[^\\w]', '', column_name)\n",
    "    return column_name\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    if isinstance(value, str):\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "        value = value.replace('\\n', ' ').strip()\n",
    "    return value\n",
    "\n",
    "df = df.map(clean_string_cell)\n",
    "df.columns = [convert_to_snake_case(col) for col in df.columns]\n",
    "print(\"After cleaning:\", df.columns.tolist())\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: ['q_id', 'cluster', 'req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection', 'type_of_upgrade', 'upgrade', 'estimated_cost_x_1000', 'escalated_cost_x_1000', 'estimated_time_to_construct', 'item', 'max_time_to_construct']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_itemized_addendums.csv', dtype={'estimated_time_to_construct': str})\n",
    "\n",
    "df['q_id'] = df['q_id'].astype('Int64')\n",
    "df['cluster'] = df['cluster'].astype('Int64')\n",
    "\n",
    "\n",
    "def clean_column_headers(headers):\n",
    "    \"\"\"Cleans column headers by normalizing and removing unwanted characters.\"\"\"\n",
    "    cleaned_headers = []  # Initialize an empty list to hold the cleaned header names.\n",
    "    for header in headers:  # Iterate over each header in the input.\n",
    "        if header is None:\n",
    "            header = \"\"  # If the header is None, set it to an empty string.\n",
    "        elif isinstance(header, str):  # Otherwise, if the header is a string:\n",
    "            #header = header.lower()  # Convert the header to lowercase.\n",
    "            header = re.sub(r'\\s+', ' ', header)  # Replace one or more whitespace characters with a single space.\n",
    "            #header = re.sub(r'\\(.*?\\)', '', header)  # Remove any text within parentheses (non-greedy).\n",
    "            header = re.sub(r'[^a-zA-Z0-9\\s()/+=_]', '', header)  # Remove any character that is not a letter, number, or whitespace.\n",
    "            header = header.strip()  # Remove any leading or trailing whitespace.\n",
    "        cleaned_headers.append(header)  # Append the cleaned header to the list.\n",
    "    return cleaned_headers  # Return the list of cleaned headers.\n",
    "\n",
    "\n",
    "\n",
    "df.columns = clean_column_headers(df.columns)\n",
    "\n",
    "def convert_to_snake_case(column_name):\n",
    "    column_name = column_name.strip().lower()\n",
    "    column_name = re.sub(r'[\\s\\-]+', '_', column_name)\n",
    "    column_name = re.sub(r'[^\\w]', '', column_name)\n",
    "    return column_name\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    if isinstance(value, str):\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "        value = value.replace('\\n', ' ').strip()\n",
    "    return value\n",
    "\n",
    "df = df.map(clean_string_cell)\n",
    "df.columns = [convert_to_snake_case(col) for col in df.columns]\n",
    "print(\"After cleaning:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itmeized and Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itemized rows saved to 'costs_phase_1_cluster_14_itemized.csv'.\n",
      "Filtered Total rows saved to 'costs_phase_1_cluster_14_total.csv'.\n",
      "['PTO_IF' 'RNU' 'ADNU' 'LDNU' 'Distribution Upgrades']\n",
      "[1306 1307 1308 1309 1310 1312 1313 1314 1315 1344]\n",
      "[9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3440121289.py:799: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/03_raw/rawdata_cluster9_style_J_addendums.csv', dtype={'estimated_time_to_construct': str})\n",
    "\n",
    "#df['q_id'] = df['q_id'].astype('Int64')\n",
    "df['cluster'] = df['cluster'].astype('Int64')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_column_headers(headers):\n",
    "    \"\"\"Cleans column headers by normalizing and removing unwanted characters.\"\"\"\n",
    "    cleaned_headers = []  # Initialize an empty list to hold the cleaned header names.\n",
    "    for header in headers:  # Iterate over each header in the input.\n",
    "        if header is None:\n",
    "            header = \"\"  # If the header is None, set it to an empty string.\n",
    "        elif isinstance(header, str):  # Otherwise, if the header is a string:\n",
    "            #header = header.lower()  # Convert the header to lowercase.\n",
    "            header = re.sub(r'\\s+', ' ', header)  # Replace one or more whitespace characters with a single space.\n",
    "            #header = re.sub(r'\\(.*?\\)', '', header)  # Remove any text within parentheses (non-greedy).\n",
    "            header = re.sub(r'[^a-zA-Z0-9\\s()/+=_]', '', header)  # Remove any character that is not a letter, number, or whitespace.\n",
    "            header = header.strip()  # Remove any leading or trailing whitespace.\n",
    "        cleaned_headers.append(header)  # Append the cleaned header to the list.\n",
    "    return cleaned_headers  # Return the list of cleaned headers.\n",
    "\n",
    "df.columns = clean_column_headers(df.columns)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#STEP 2: NAMING CONVENTION\n",
    "def convert_to_snake_case(column_name):\n",
    "    column_name = column_name.strip().lower()\n",
    "    column_name = re.sub(r'[\\s\\-]+', '_', column_name)\n",
    "    column_name = re.sub(r'[^\\w]', '', column_name)\n",
    "    return column_name\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    if isinstance(value, str):\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "        value = value.replace('\\n', ' ').strip()\n",
    "    return value\n",
    "\n",
    "df = df.map(clean_string_cell)\n",
    "df.columns = [convert_to_snake_case(col) for col in df.columns]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def move_dollar_values(df, source_column, target_column):\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, if the value in `source_column` starts with a '$',\n",
    "    move that value to `target_column` and clear the value in the source column.\n",
    "\n",
    "    Parameters:\n",
    "      df (pd.DataFrame): The input DataFrame.\n",
    "      source_column (str): The column to check for values starting with '$'.\n",
    "      target_column (str): The column to move the values into.\n",
    "\n",
    "    Returns:\n",
    "      pd.DataFrame: The modified DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure target_column exists; if not, create it filled with empty strings.\n",
    "    if target_column not in df.columns:\n",
    "        df[target_column] = \"\"\n",
    "    \n",
    "    # Create a boolean mask for rows where the source column starts with '$'\n",
    "    mask = df[source_column].astype(str).str.startswith('$', na=False)\n",
    "    \n",
    "    # Move the values: assign the source values to the target column where the mask is True.\n",
    "    df.loc[mask, target_column] = df.loc[mask, source_column]\n",
    "    \n",
    "    # Clear the source column values for those rows (set to empty string)\n",
    "    df.loc[mask, source_column] = \"\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Move values from 'unnamed_8' to a new column 'moved_value'\n",
    "#df = move_dollar_values(df, 'none_5', 'total_estimated_costs_x_1000_escalated_constant_dollars_od_year')\n",
    "\n",
    "\n",
    "#df = move_dollar_values(df, 'none_3','total_estimated_costs_x_1000_constant_dollar_2020')\n",
    "\n",
    "def remove_dollar_values_and_fill_nan(df, column):\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, if the value in the specified column starts with '$',\n",
    "    set that value to NaN. Also, replace any empty strings in that column with NaN.\n",
    "\n",
    "    Parameters:\n",
    "      df (pd.DataFrame): The input DataFrame.\n",
    "      column (str): The column to check and clean.\n",
    "\n",
    "    Returns:\n",
    "      pd.DataFrame: The modified DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure the column is treated as string\n",
    "    df[column] = df[column].astype(str)\n",
    "    \n",
    "    # Set values starting with '$' to NaN\n",
    "    mask = df[column].str.startswith('$', na=False)\n",
    "    df.loc[mask, column] = np.nan\n",
    "    \n",
    "    # Replace any remaining empty strings with NaN\n",
    "    df[column] = df[column].replace(\"\", np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = remove_dollar_values_and_fill_nan(df, 'unnamed_8')\n",
    "\n",
    "\n",
    "\n",
    "def insert_phrase_if_missing(df, target_columns, phrase=\"Area Delivery Network Upgrades\"):\n",
    "    \"\"\"\n",
    "    For each q_id group in df, for each column in target_columns:\n",
    "      - Check the first row (by current order) that is non-empty (not NaN, not blank, not 'na').\n",
    "      - If that cell does NOT contain the given phrase (case-insensitive),\n",
    "        insert a new row above it (within that q_id group) that sets that column to phrase,\n",
    "        leaving other columns as empty strings.\n",
    "    \n",
    "    Returns a new DataFrame with the added rows.\n",
    "    \"\"\"\n",
    "    # Work on a copy and reset index; create a temporary \"order\" column for precise control.\n",
    "    df = df.copy().reset_index(drop=True)\n",
    "    df[\"order\"] = df.index.astype(float)\n",
    "    \n",
    "    new_rows = []\n",
    "    \n",
    "    # Process each q_id group\n",
    "    for qid, group in df.groupby(\"q_id\", sort=False):\n",
    "        # For each target column, find the first non-empty cell.\n",
    "        for col in target_columns:\n",
    "            # We'll iterate over the group's index in order.\n",
    "            first_idx = None\n",
    "            first_val = None\n",
    "            for idx in group.index:\n",
    "                val = group.loc[idx, col]\n",
    "                # Convert to string and strip spaces.\n",
    "                # Treat NaN, empty strings, or \"na\"/\"NA\" as empty.\n",
    "                val_str = \"\" if pd.isna(val) else str(val).strip()\n",
    "                if val_str == \"\" or val_str.lower() == \"na\":\n",
    "                    continue\n",
    "                first_idx = idx\n",
    "                first_val = val_str\n",
    "                break\n",
    "            # If we found a non-empty value and it doesn't contain our phrase, insert a row.\n",
    "            if first_idx is not None:\n",
    "                if phrase.lower() not in first_val.lower():\n",
    "                    # Create a new row with the same q_id; leave all columns blank except col.\n",
    "                    new_row = {c: \"\" for c in df.columns if c != \"order\"}\n",
    "                    new_row[\"q_id\"] = qid\n",
    "                    new_row[col] = phrase\n",
    "                    # Set its order to be a bit before the first non-empty row.\n",
    "                    new_order = group.loc[first_idx, \"order\"] - 0.1\n",
    "                    new_row[\"order\"] = new_order\n",
    "                    new_rows.append(new_row)\n",
    "    \n",
    "    # If any rows were added, append them and sort by q_id then order.\n",
    "    if new_rows:\n",
    "        new_rows_df = pd.DataFrame(new_rows)\n",
    "        df = pd.concat([df, new_rows_df], ignore_index=True)\n",
    "        df = df.sort_values(by=[\"q_id\", \"order\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Drop the temporary order column.\n",
    "    df = df.drop(columns=[\"order\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = insert_phrase_if_missing(df, ['adn_area_delivery_network_upgrades'], phrase=\"Area Delivery Network Upgrades\")  \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def merge_columns(df):\n",
    "\n",
    "    merge_columns_dict = {\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "        \"one_time_costs_b\": [\n",
    "            \"none_2\",\n",
    "             \n",
    "        ],\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "\n",
    " \n",
    "    \n",
    "        \"type_of_upgrade\": [\n",
    "            \n",
    "             'cost_category', \n",
    "           \n",
    "            \"cost_category_notes_1a_to_1f\",\n",
    "           \n",
    "            'other_potential_cost', \n",
    "            'other_potential_network_cost',\n",
    "            'area_delivery_network_upgrades', \n",
    "            'otherpotential_other_potential_network_upgrades_note_1h',\n",
    "            'adn_area_delivery_network_upgrades',\n",
    "         'project_q1306tot792_updated_as_of_2222017',\n",
    "         'project_q1307tot820_updated_as_of_2222017', 'project_q1309tot805_updated_as_of_2222017', \n",
    "         'project_q1310tot803_updated_as_of_2222017', 'project_q1312tot812_updated_as_of_2222017', \n",
    "         'project_q1313tot811_updated_as_of_2222017', 'project_q1314tot810_updated_as_of_2222017', 'project_q1315tot829_updated_as_of_2222017', \n",
    "          'element',\n",
    "          'other_potential_network_upgrades_note_1112', 'area_delivery_network_upgrades'\n",
    "          'adn_project_q1306tot792_updated_as_of_2222017',   'adn_project_q1307tot820_updated_as_of_2222017', 'project_q1308tot808_updated_as_of_2222017', \n",
    "          'adn_project_q1308tot808_updated_as_of_2222017', 'adn_project_q1309tot805_updated_as_of_2222017', 'adn_project_q1310tot803_updated_as_of_2222017', 'adn_project_q1312tot812_updated_as_of_2222017', \n",
    "          'adn_project_q1313tot811_updated_as_of_2222017',\n",
    "          'adn_project_q1314tot810_updated_as_of_2222017', 'adn_project_q1315tot829_updated_as_of_2222017', 'otherpotential_other_potential_network_upgrades_note_1112',\n",
    "          'project_q1307tot820_updated_as_of_2222017', 'adn_project_q1307tot820_updated_as_of_2222017', 'project_q1308tot808_updated_as_of_2222017', 'adn_project_q1308tot808_updated_as_of_2222017',\n",
    "            'project_q1309tot805_updated_as_of_2222017', 'adn_project_q1309tot805_updated_as_of_2222017', 'project_q1310tot803_updated_as_of_2222017', 'adn_project_q1310tot803_updated_as_of_2222017', \n",
    "            'project_q1312tot812_updated_as_of_2222017', 'adn_project_q1312tot812_updated_as_of_2222017', 'project_q1313tot811_updated_as_of_2222017', 'adn_project_q1313tot811_updated_as_of_2222017', \n",
    "            'project_q1314tot810_updated_as_of_2222017', \n",
    "          'adn_project_q1314tot810_updated_as_of_2222017', 'project_q1315tot829_updated_as_of_2222017', 'adn_project_q1315tot829_updated_as_of_2222017', 'element', \n",
    "          'otherpotential_other_potential_network_upgrades_note_1112',\n",
    "          'adn_project_q1306tot792_updated_as_of_2222017',\n",
    "          \n",
    "          'unnamed_8'\n",
    " \n",
    "            \n",
    "           \n",
    "         \n",
    "            \n",
    " \n",
    "             \n",
    "        ],\n",
    "        \"escalated_cost_x_1000\": [\n",
    "            \"total_escalated_costs_wo_itcc\",\n",
    "            \"total_estimated_costs_x_1000_escalated_constant_dollars_od_year\",\n",
    "            \"none_4\",\n",
    "            'total_escalated_costs_in_1000s',\n",
    "            'escalated_cost_in_1000s_note_8',\n",
    "            'total_estimated_costs_x',\n",
    "             'total_escalated_costs_in_1000s', \n",
    "             'total_escalated_costs_to_od_year_in_1000s',\n",
    "              'total_estimated_costs_x_1000_escalated_constant_dollars_od_year',\n",
    "              'otherpotential_none_2',\n",
    "              'adn_unnamed_5',\n",
    "              'adn_none_4',\n",
    "              'total_estimated_costs_x_1000_escalated_constant_dollars_2022', \n",
    "             \n",
    "              'total_estimated_costs_x_1000_escalated_constant_dollars_od_year',\n",
    "              'adn_none_4', \n",
    "              \n",
    "            \n",
    "\n",
    "        ],\n",
    "        \"estimated_cost_x_1000\": [\n",
    "            \"none_3\",\n",
    "            'total_costs_wo_itcc_cab',\n",
    "            'total_estimated_costs_x_1000_constant_dollar_2017',\n",
    "            'otherpotential_none',\n",
    "            'adn_unnamed_2',\n",
    "            'adn_none_3',\n",
    "            \n",
    "            'total_estimated_costs_x_1000_constant_dollar_2018',\n",
    "            'interconnection_facilities_costs_x_1000_constant_dollar_2016', 'reliability_network_upgrades_costs_x_1000_constant_dollar_2016', \n",
    "            'delivery_network_upgrades_costs_x_1000_constant_dollar_2016', 'distribution_upgrades_costs_x_1000_constant_dollar_2016', \n",
    "            'total_estimated_costs_x_1000_constant_dollar_2016', \n",
    "            'total_estimated_costs_x_1000_escalated_constant_dollars_2021', \n",
    "            'total_estimated_costs_x_1000_constant_dollar_2017', \n",
    "            'adn_none_3', \n",
    "           \n",
    " \n",
    "        ],\n",
    "        \"estimated_time_to_construct\": [\n",
    "            'estimated_time_for_licensing_permitting_construction_months',\n",
    "            'estimated_time_to_construct_months',\n",
    "            'estimated_time_to_construct_months2',\n",
    "            'estimated_time_to_construct_months',\n",
    "            'estimated_time_to_construct_months',\n",
    "            'estimated_time_to_construct_months_note_1g',\n",
    "            'estimated_time_to_construct_months_note_1g',\n",
    "            'estimated_time_to_construct_months',\n",
    "            \"none_5\",\n",
    "            'estimated_time_to_construct_months',\n",
    "            'upgrade_duration_months',\n",
    "            'estimated_time_to_construct_months_note_12', \n",
    "            'adnu_duration_months',\n",
    "            'estimated_time_to',\n",
    "      \n",
    "            'none_12',\n",
    "            'estimated_duration_months',\n",
    "            'otherpotential_none_3',\n",
    "            'adn_unnamed_8', \n",
    "            'adn_none_5',\n",
    "            'adn_estimated_time_to_construct_months', \n",
    "            'estimated_time_to_construct_months_note_345_6', \n",
    "            'estimated_time_to_construct_months_note_345_9_10',\n",
    "            'estimated_time_to_construct_months_note_1g',\n",
    "           \n",
    "             'adn_none_5', \n",
    "             \n",
    "            \n",
    "        ],\n",
    "        \"description\": [\"description\"],\n",
    "        \"capacity\": [\n",
    "            \"capacity\",\n",
    "            \"project size\",\n",
    "            \"project mw\",\n",
    "            \"mw at poi\"\n",
    "        ],\n",
    " \n",
    "        \"max_time_to_construct\": [\n",
    "            'maximum_escalation_duration_months',\n",
    "            'od_dollar_escalation_duration_months',\n",
    "            'od_dollar_escalation_duration_months',\n",
    "            'od_dollar_escalation_duration_months_note1g',\n",
    "            'od_dollar_escalation_duration_months_note1g',\n",
    "            \"none_6\",\n",
    "            'maximum_escalation_duration_months',\n",
    "            'od_dollar_escalation',\n",
    "            'maximum_project_duration_months',\n",
    "            'otherpotential_none_4',\n",
    "            'adn_unnamed_11', \n",
    "            'adn_none_6',\n",
    "            \n",
    "            'adn_od_dollar_escalation_duration_months',\n",
    "            'od_dollar_escalation_duration_months_note_345_6',\n",
    "            'od_dollar_escalation_duration_months_note_345_9_10', \n",
    "             'od_dollar_escalation_duration_months_note_1g',\n",
    "             \n",
    "             'adn_none_6', \n",
    "             \n",
    "            \n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "        # Identify unnamed columns\n",
    "    unnamed_columns = [col for col in df.columns if pd.isna(col) or col.strip() == \"\" or col.startswith(\"Unnamed\")]\n",
    "    if unnamed_columns:\n",
    "        merge_columns_dict[\"type_of_upgrade\"].extend(unnamed_columns)\n",
    "\n",
    "    for new_col, old_cols in merge_columns_dict.items():\n",
    "        existing_cols = [col for col in old_cols if col in df.columns]\n",
    "        if existing_cols:\n",
    "            df[new_col] = df[existing_cols].bfill(axis=1).iloc[:, 0]\n",
    "            cols_to_drop = [col for col in existing_cols if col != new_col]\n",
    "            if cols_to_drop:\n",
    "                df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = merge_columns(df)\n",
    "df.drop([   'adn_none', 'adn_none_2', 'adn_none_7', \n",
    "         'one_time_costs_b','none_8', 'none_9', 'none_7' ,'none_10',  'adn_total_estimated_costs_x_1000_constant_dollar_2017', 'adn_total_estimated_costs_x_1000_escalated_constant_dollars_od_year',\n",
    "         'adn_od_dollar_escalation_duration_months_note_345_9_10','adn_estimated_time_to_construct_months_note_345_9_10', \n",
    "], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def reorder_columns(df):\n",
    "    \"\"\"\n",
    "    Reorders the columns of the DataFrame based on the specified order.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to reorder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The reordered DataFrame.\n",
    "    \"\"\"\n",
    "    desired_order = [\n",
    "        \"q_id\",\n",
    "        \"cluster\",\n",
    "        \"req_deliverability\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"capacity\",\n",
    "        \"point_of_interconnection\",\n",
    "        \"type_of_upgrade\",\n",
    "        \"upgrade\",\n",
    "        \"description\",\n",
    "        \"cost_allocation_factor\",\n",
    "        \"estimated_cost_x_1000\",\n",
    "        \"escalated_cost_x_1000\",\n",
    " \n",
    "        \"estimated_time_to_construct\",\n",
    "    ]\n",
    "\n",
    "    # Start with desired columns that exist in the DataFrame\n",
    "    existing_desired = [col for col in desired_order if col in df.columns]\n",
    "\n",
    "    # Then add the remaining columns\n",
    "    remaining = [col for col in df.columns if col not in existing_desired]\n",
    "\n",
    "    # Combine the two lists\n",
    "    new_order = existing_desired + remaining\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    df = df[new_order]\n",
    "\n",
    "    return df        \n",
    "\n",
    "\n",
    "df= reorder_columns(df)\n",
    "\n",
    "\n",
    "\n",
    "df = df[~df.apply(lambda row: row.astype(str).isin([\"Total Escalated Costs w/o ITCC\", \"Constant 2017 Dollar in $1000s (Estimate)\", \"Eastern\",\"Note (h)\"]).any(), axis=1)]\n",
    "df = df[~df.apply(lambda row: any(str(cell).startswith(\"Project #:\") for cell in row), axis=1)]\n",
    "\n",
    "\n",
    "df = df[df['type_of_upgrade'].notna() & (df['type_of_upgrade'].astype(str).str.strip() != \"\")]\n",
    "\n",
    " \n",
    "def process_upgrade_columns(df):\n",
    "    \"\"\"\n",
    "    Given a DataFrame df with a column \"type_of_upgrade\" that contains both group headers and upgrade data,\n",
    "    this function:\n",
    "      1. Inserts a new column \"upgrade\" as a duplicate of \"type_of_upgrade\" (placed immediately after it).\n",
    "      2. Renames rows in \"type_of_upgrade\" that contain specific phrases as follows:\n",
    "           - If it contains \"Interconnection Facilities\", rename to \"PTO_IF\" (or \"PTO_IF Total\" if \"Total\" is present)\n",
    "           - If it contains \"Reliability Network Upgrade\", rename to \"RNU\" (or \"RNU Total\" if \"Total\" is present)\n",
    "           - If it contains \"Local Delivery Network Upgrades\", rename to \"LDNU\" (or \"LDNU Total\" if \"Total\" is present)\n",
    "           - If it contains \"Area Deliverability Network Upgrades\", rename to \"ADNU\" (or \"ADNU Total\" if \"Total\" is present)\n",
    "           - If it contains \"Distribution Upgrades\", leave it as is.\n",
    "      3. Creates a temporary column that only holds the header values (from rows that were detected as header rows) and forward-fills it downward.\n",
    "         The forward fill stops (i.e. does not fill into a row) if that row\u2019s original \"type_of_upgrade\" contains any of the \"total\" indicators.\n",
    "      4. Replaces \"type_of_upgrade\" with the forward-filled header values.\n",
    "      5. Drops the rows that originally were header rows.\n",
    "      6. This deletes any rows which are either Total or Subtotal or Total cost assigned, the reason is some proejcts have multiple pdfs thus we rather calculate the total in the end.\n",
    "      \n",
    "    Returns the updated DataFrame.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 1. Create a new column \"upgrade\" immediately after \"type_of_upgrade\"\n",
    "    loc = df.columns.get_loc(\"type_of_upgrade\")\n",
    "    df.insert(loc+1, \"upgrade\", df[\"type_of_upgrade\"])\n",
    "    \n",
    "    # 2. Define a helper to rename header rows.\n",
    "    def rename_header(val):\n",
    "        # If the cell contains any of these phrases, rename accordingly.\n",
    "        # We'll check using the substring test (case-sensitive) per your request.\n",
    "        if \"Interconnection Facilities\" in val:\n",
    "            return \"PTO_IF\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        elif \"Reliability Network Upgrade\" in val:\n",
    "            return \"RNU\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        elif \"Local Delivery Network Upgrades\" in val:\n",
    "            return \"LDNU\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        elif \"Area Deliverability Network Upgrades\" in val:\n",
    "            return \"ADNU\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        elif \"Distribution Upgrades\" in val:\n",
    "            return val  # leave unchanged\n",
    "        elif \"Conditional Assigned Network Upgrades\" in val:\n",
    "            return  (\"Total \" if \"Total\" in val else \"\") + \"CANU\" \n",
    "        elif \"Non-Allocated IRNU\" in val:\n",
    "            return  (\"Total \" if \"Total\" in val else \"\") + \"Non-Allocated IRNU\"\n",
    "        elif \"Area Delivery Network Upgrades\" in val:\n",
    "            return \"ADNU\" + (\" Total\" if \"Total\" in val else \"\")\n",
    "        else:\n",
    "            return val\n",
    "    \n",
    "    # 3. Identify header rows. We consider a row to be a header row if its \"type_of_upgrade\" cell \n",
    "    # contains any of the target phrases.\n",
    "    target_phrases = [\n",
    "        \"Interconnection Facilities\",\n",
    "        \"Reliability Network Upgrade\",\n",
    "        \"Local Delivery Network Upgrades\",\n",
    "        \"Area Deliverability Network Upgrades\",\n",
    "        \"Distribution Upgrades\",\n",
    "        \"Conditional Assigned Network Upgrades\",\n",
    "        \"Non-Allocated IRNU\",\n",
    "        \"Area Delivery Network Upgrades\",\n",
    "\n",
    "    ]\n",
    "    # Create a boolean mask for header rows.\n",
    "    header_mask = df[\"type_of_upgrade\"].apply(lambda x: any(phrase in x for phrase in target_phrases))\n",
    "    \n",
    "    # Apply renaming to the header rows.\n",
    "    df.loc[header_mask, \"type_of_upgrade\"] = df.loc[header_mask, \"type_of_upgrade\"].apply(rename_header)\n",
    "    \n",
    "    # 4. Create a temporary column 'header_temp' that holds only the header rows, then forward fill it.\n",
    "    df[\"header_temp\"] = df[\"type_of_upgrade\"].where(header_mask)\n",
    "    df[\"header_temp\"] = df[\"header_temp\"].ffill()\n",
    "    \n",
    "    # We want to stop the forward fill if we encounter a row that indicates totals.\n",
    "    # Define a simple function that returns True if a cell contains \"Total\" or \"Subtotal\" or \"Total cost assigned\".\n",
    "    def is_total_indicator(val):\n",
    "        return (\"Total\" in val) or (\"Subtotal\" in val) or (\"Total cost assigned\" in val)\n",
    "    \n",
    "    # For rows that themselves are total indicators in the \"upgrade\" column, do not forward-fill (set header_temp to NaN)\n",
    "    df.loc[df[\"upgrade\"].apply(lambda x: is_total_indicator(x)), \"header_temp\"] = None\n",
    "    \n",
    "    # Now, replace the \"type_of_upgrade\" column with the forward-filled header\n",
    "    df[\"type_of_upgrade\"] = df[\"header_temp\"]\n",
    "    df.drop(\"header_temp\", axis=1, inplace=True)\n",
    "    \n",
    "    # 5. Finally, drop the rows that were header rows (i.e. where header_mask is True)\n",
    "    df = df[~header_mask].reset_index(drop=True)\n",
    "    \n",
    "    # Also, drop any rows that have an empty \"type_of_upgrade\"\n",
    "    df = df[df[\"type_of_upgrade\"].notna() & (df[\"type_of_upgrade\"].str.strip() != \"\")]\n",
    "    \n",
    "    return df\n",
    "\n",
    " \n",
    "\n",
    "df = process_upgrade_columns(df)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "mappings = {\n",
    " \"PTO\": 'PTO_IF',\n",
    " \"PNU\": \"OPNU\",\n",
    " \"PTO's Interconnection Facilities\": \"PTO_IF\",\n",
    " \"RNUs, Estimated Costs, and Estimated Time to Construct Summary\": \"RNU\",\n",
    " \"Non-Allocated IRNU\": \"RNU\",\n",
    " \"Total Non-Allocated IRNU\": \"Total RNU\",\n",
    " }\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "  \n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: mappings.get(x, x) if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['item'] = df.apply(\n",
    "    lambda row: 'no' if (\n",
    "        (pd.notna(row.get('type_of_upgrade')) and 'Total' in str(row['type_of_upgrade'])) or\n",
    "        (pd.notna(row.get('cost_allocation_factor')) and 'Total' in str(row['cost_allocation_factor']))\n",
    "    ) else 'yes',\n",
    "    axis=1\n",
    ")\n",
    "   \n",
    "\n",
    "\n",
    " \n",
    "   \n",
    " \n",
    " \n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "# Step 7: Remove $ signs and convert to numeric\n",
    "import re\n",
    "\n",
    "def clean_currency(value):\n",
    "    \"\"\"\n",
    "    Cleans a string by explicitly removing $, *, (Note 2), and similar patterns,\n",
    "    then converts it to a numeric value.\n",
    "    \"\"\"\n",
    "    if isinstance(value, str):\n",
    "        # Explicitly remove $, *, and any \"(Note ...)\"\n",
    "        value = value.replace('$', '').replace('*', '')\n",
    "        value = re.sub(r'\\(Note \\d+\\)', '', value)  # Remove patterns like \"(Note 2)\"\n",
    "        value = value.replace(',', '').strip()  # Remove commas and extra spaces\n",
    "    try:\n",
    "        return pd.to_numeric(value)\n",
    "    except ValueError:\n",
    "        return pd.NA  # Return NaN for invalid entries\n",
    "\n",
    "\n",
    "# Clean the specific columns\n",
    "for col in ['estimated_cost_x_1000', 'escalated_cost_x_1000']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "df = df.drop_duplicates(subset=['q_id','type_of_upgrade','upgrade', 'estimated_cost_x_1000', 'escalated_cost_x_1000'])   \n",
    "df = df[~df['upgrade'].astype(str).isin([\n",
    "    \"CANUIRNU\", \n",
    "    \"CANUGRNU\", \n",
    "    \"SCD\",\n",
    "    \"CANU-LDNU\",\n",
    "    \"IRNUs\",\n",
    "    \"GRNUs\",\n",
    "    \"Maximum Cost Responsibility (Network Upgrades)\",\n",
    "    \"Network Upgrade\",\n",
    "\n",
    "\n",
    "])]\n",
    "\n",
    "df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/03_raw/rawdata_cluster9_style_J_add.csv', index=False)\n",
    "\n",
    "# Create Total rows\n",
    "new_rows = []\n",
    "columns_to_sum = ['estimated_cost_x_1000', 'escalated_cost_x_1000']\n",
    "columns_to_populate = ['cluster', 'req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection']\n",
    "\n",
    "for q_id, group in df.groupby('q_id', as_index=False):\n",
    "    unique_upgrades = group['type_of_upgrade'].dropna().unique()\n",
    "    for upgrade in unique_upgrades:\n",
    "        if pd.isna(upgrade):\n",
    "            continue\n",
    "        \n",
    "        rows = group[group['type_of_upgrade'] == upgrade]\n",
    "\n",
    "                # Check if a Total row already exists for this (q_id, upgrade)\n",
    "        total_exists = group[\n",
    "            (group['type_of_upgrade'] == upgrade) & (group['item'] == 'no')\n",
    "        ].shape[0] > 0\n",
    "        \n",
    "        if total_exists:\n",
    "             \n",
    "            continue\n",
    "\n",
    "\n",
    " \n",
    "        \n",
    "        \n",
    "        if not total_exists:\n",
    "            # If only one row exists, duplicate it as the total row\n",
    "            if len(rows) == 1:\n",
    "\n",
    "                total_row = {col: '' for col in df.columns}  # Initialize all columns as empty strings\n",
    "\n",
    "                # Populate the necessary fields\n",
    "                total_row['q_id'] = q_id\n",
    "                total_row['type_of_upgrade'] = f\"Total {upgrade}\"\n",
    "                total_row['item'] = 'no'\n",
    "\n",
    "                # Populate specified columns from the existing row\n",
    "                first_row = rows.iloc[0]\n",
    "                for col in columns_to_populate:\n",
    "                    if col in df.columns:\n",
    "                        total_row[col] = first_row[col]\n",
    "\n",
    "                # Sum the numeric columns (single row, so it remains the same)\n",
    "                for col in columns_to_sum:\n",
    "                    if col in rows.columns:\n",
    "                        total_row[col] = rows[col].sum()\n",
    "                    else:\n",
    "                        total_row[col] = 0  # Default to 0 if column is missing\n",
    "\n",
    "                new_rows.append(total_row)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "            \n",
    "            # If multiple rows exist, sum numeric columns and create a total row\n",
    "            elif len(rows) > 1:\n",
    "                total_row = {col: '' for col in df.columns}  # Initialize all columns as empty strings\n",
    "\n",
    "                # Populate the necessary fields\n",
    "                total_row['q_id'] = q_id\n",
    "                total_row['type_of_upgrade'] = f\"Total {upgrade}\"\n",
    "                total_row['item'] = 'no'\n",
    "\n",
    "                # Populate the specified columns from the first row in the group\n",
    "                first_row = rows.iloc[0]\n",
    "                for col in columns_to_populate:\n",
    "                    if col in df.columns:\n",
    "                        total_row[col] = first_row[col]\n",
    "\n",
    "                # Sum the numeric columns\n",
    "                for col in columns_to_sum:\n",
    "                    if col in rows.columns:\n",
    "                        total_row[col] = rows[col].sum()\n",
    "                    else:\n",
    "                        total_row[col] = 0  # Default to 0 if column is missing\n",
    "\n",
    "                new_rows.append(total_row)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "if new_rows:\n",
    "    total_rows_df = pd.DataFrame(new_rows)\n",
    "    for col in df.columns:\n",
    "        if col not in total_rows_df.columns:\n",
    "            total_rows_df[col] = None\n",
    "    total_rows_df = total_rows_df[df.columns]\n",
    "    df = pd.concat([df, total_rows_df], ignore_index=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Update 'item' column based on Total in type_of_upgrade or cost_allocation_factor\n",
    "df['item'] = df.apply(\n",
    "    lambda row: 'no' if (\n",
    "        'Total' in str(row.get('type_of_upgrade', '')) or \n",
    "        'Total' in str(row.get('cost_allocation_factor', ''))\n",
    "    ) else 'yes',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Step 8: Move 'item' column next to 'type_of_upgrade'\n",
    "if 'item' in df.columns and 'type_of_upgrade' in df.columns:\n",
    "    cols = df.columns.tolist()\n",
    "    item_index = cols.index('item')\n",
    "    type_index = cols.index('type_of_upgrade')\n",
    "    if item_index < type_index:\n",
    "        cols.insert(type_index + 1, cols.pop(item_index))\n",
    "    else:\n",
    "        cols.insert(type_index + 1, cols.pop(item_index))\n",
    "    df = df[cols]\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "def clean_estimated_time(value):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub(r'(\\d+(?:-\\w+)*)\\s+\\w+.*$', r'\\1', value, flags=re.IGNORECASE).strip()\n",
    "    return value\n",
    "\n",
    "if 'estimated_time_to_construct' in df.columns:\n",
    "    df['estimated_time_to_construct'] = df['estimated_time_to_construct'].apply(clean_estimated_time)\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: re.sub(r'\\s*\\(note \\d+\\)', '', x, flags=re.IGNORECASE).strip() if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    " \n",
    "mappings = {\n",
    " \"PTO\": 'PTO_IF',\n",
    " \"PNU\": \"OPNU\",\n",
    " \"PTO's Interconnection Facilities\": \"PTO_IF\",\n",
    " \"RNUs, Estimated Costs, and Estimated Time to Construct Summary\": \"RNU\",\n",
    "'Total PTO_IF': 'PTO_IF',\n",
    "'PTO_IF Total': 'PTO_IF',\n",
    " 'Total RNU': 'RNU',\n",
    " 'RNU Total': 'RNU',\n",
    " 'Total LDNU': 'LDNU',\n",
    " 'Total OPNU' : 'OPNU',\n",
    " 'Total CANU': 'CANU',\n",
    " 'Total LOPNU': 'LOPNU',\n",
    " 'Total ADNU': 'ADNU',\n",
    " 'LDNU Total': 'LDNU',\n",
    " 'Total Distribution Upgrades': 'Distribution Upgrades',\n",
    " 'Distribution Upgrades Total': 'Distribution Upgrades',\n",
    " 'Total Potential Distribution Upgrades': 'Potential Distribution Upgrades',\n",
    "}\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "  \n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: mappings.get(x, x) if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    previous_type_of_upgrade = None\n",
    "    for i in range(len(df)):\n",
    "        if df.at[i, 'type_of_upgrade'] == 'Total':\n",
    "            if previous_type_of_upgrade is not None:\n",
    "                df.at[i, 'type_of_upgrade'] = previous_type_of_upgrade\n",
    "        else:\n",
    "            previous_type_of_upgrade = df.at[i, 'type_of_upgrade']\n",
    "\n",
    "numeric_columns = [\n",
    "    \n",
    "    'estimated_cost_x_1000',\n",
    "    'estimated_time_to_construct',\n",
    "     \n",
    "    'adnu_cost_rate_x_1000',\n",
    "    'escalated_cost_x_1000',\n",
    "     \n",
    "]\n",
    "non_numeric_columns = ['type_of_upgrade', 'upgrade', 'description']\n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: 'None' if pd.isna(x) else x)\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace('-', pd.NA)\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "if 'original_order' in df.columns and 'q_id' in df.columns:\n",
    "    df['original_order'] = df.index\n",
    "    df = df.sort_values(by=['q_id', 'original_order'], ascending=[True, True])\n",
    "    df = df.drop(columns=['original_order'])\n",
    "\n",
    "\n",
    "def reorder_columns(df):\n",
    "    \"\"\"\n",
    "    Reorders the columns of the DataFrame based on the specified order.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to reorder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The reordered DataFrame.\n",
    "    \"\"\"\n",
    "    desired_order = [\n",
    "        \"q_id\",\n",
    "        \"cluster\",\n",
    "        \"req_deliverability\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"capacity\",\n",
    "        \"point_of_interconnection\",\n",
    "        \"type_of_upgrade\",\n",
    "        \"upgrade\",\n",
    "        \"description\",\n",
    "        \"cost_allocation_factor\",\n",
    "        \"estimated_cost_x_1000\",\n",
    "        \"escalated_cost_x_1000\",\n",
    "        \"total_estimated_cost_x_1000\",\n",
    "        \"total_estimated_cost_x_1000_escalated\",\n",
    "        \"estimated_time_to_construct\",\n",
    "    ]\n",
    "\n",
    "    # Start with desired columns that exist in the DataFrame\n",
    "    existing_desired = [col for col in desired_order if col in df.columns]\n",
    "\n",
    "    # Then add the remaining columns\n",
    "    remaining = [col for col in df.columns if col not in existing_desired]\n",
    "\n",
    "    # Combine the two lists\n",
    "    new_order = existing_desired + remaining\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    df = df[new_order]\n",
    "\n",
    "    return df        \n",
    "\n",
    "\n",
    "df= reorder_columns(df)\n",
    "df = df[~df['upgrade'].astype(str).isin([\n",
    "    \"CANUIRNU\", \n",
    "    \"CANUGRNU\", \n",
    "    \"SCD\",\n",
    "    \"CANU-LDNU\",\n",
    "    \"IRNUs\",\n",
    "    \"GRNUs\",\n",
    "    \"Maximum Cost Responsibility (Network Upgrades)\",\n",
    "    \"Network Upgrade\",\n",
    "    \"Plan of Service\",\n",
    "\n",
    "\n",
    "])]\n",
    "df = remove_dollar_values_and_fill_nan(df, 'max_time_to_construct')\n",
    "# Save itemized and totals separately\n",
    "if 'item' in df.columns:\n",
    "    itemized_df = df[df['item'] == 'yes']\n",
    " \n",
    "    #itemized_df = itemized_df.drop_duplicates(subset=['q_id','type_of_upgrade','upgrade']) \n",
    "    itemized_df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_itemized_addendums.csv', index=False)\n",
    "\n",
    "    totals_columns = ['upgrade', 'description', 'cost_allocation_factor', 'estimated_time_to_construct']\n",
    "    existing_totals_columns = [col for col in totals_columns if col in df.columns]\n",
    "    totals_df = df[df['item'] == 'no'].drop(columns=existing_totals_columns, errors='ignore')\n",
    "    # Define the cost columns.\n",
    "    cost_cols = ['estimated_cost_x_1000', 'escalated_cost_x_1000']\n",
    "\n",
    "    # Build an aggregation dictionary:\n",
    "    # For columns not in grouping or cost_cols, we assume they are identical and take the first value.\n",
    "    agg_dict = {col: 'first' for col in totals_df.columns \n",
    "                if col not in ['q_id', 'type_of_upgrade'] + cost_cols}\n",
    "\n",
    "    # For the cost columns, we want to sum them.\n",
    "    agg_dict.update({col: 'sum' for col in cost_cols})\n",
    "\n",
    "    \n",
    "\n",
    "    # Group by both q_id and type_of_upgrade using the aggregation dictionary.\n",
    "    totals_df = totals_df.groupby(['q_id', 'type_of_upgrade'], as_index=False).agg(agg_dict)\n",
    "    totals_df = reorder_columns(totals_df)\n",
    "    totals_df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_total_addendums.csv', index=False)\n",
    "\n",
    "print(f\"Itemized rows saved to 'costs_phase_1_cluster_14_itemized.csv'.\")\n",
    "print(f\"Filtered Total rows saved to 'costs_phase_1_cluster_14_total.csv'.\")\n",
    "\n",
    "\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    print(df['type_of_upgrade'].unique())\n",
    "\n",
    "if 'q_id' in df.columns:\n",
    "    print(df['q_id'].unique())\n",
    "\n",
    "if 'cluster' in df.columns:\n",
    "    print(df['cluster'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Original and addendum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing itemized: q_id=1306, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 13\n",
      "Length of original_rows: 14\n",
      "Processing itemized: q_id=1306, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "Processing itemized: q_id=1306, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 3\n",
      "Length of original_rows: 3\n",
      "Processing itemized: q_id=1307, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 13\n",
      "Length of original_rows: 14\n",
      "Processing itemized: q_id=1307, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 5\n",
      "Length of original_rows: 5\n",
      "Processing itemized: q_id=1307, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 3\n",
      "Processing itemized: q_id=1308, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 13\n",
      "Length of original_rows: 0\n",
      "Processing itemized: q_id=1308, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 5\n",
      "Length of original_rows: 0\n",
      "Processing itemized: q_id=1308, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 5\n",
      "Length of original_rows: 1\n",
      "Processing itemized: q_id=1309, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 13\n",
      "Length of original_rows: 14\n",
      "Processing itemized: q_id=1309, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 3\n",
      "Length of original_rows: 3\n",
      "Processing itemized: q_id=1309, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 3\n",
      "Processing itemized: q_id=1310, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 13\n",
      "Length of original_rows: 14\n",
      "Processing itemized: q_id=1310, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 3\n",
      "Length of original_rows: 3\n",
      "Processing itemized: q_id=1310, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 3\n",
      "Processing itemized: q_id=1312, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 13\n",
      "Length of original_rows: 14\n",
      "Processing itemized: q_id=1312, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 5\n",
      "Length of original_rows: 5\n",
      "Processing itemized: q_id=1312, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 2\n",
      "Length of original_rows: 0\n",
      "Processing itemized: q_id=1313, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 13\n",
      "Length of original_rows: 14\n",
      "Processing itemized: q_id=1313, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "Processing itemized: q_id=1313, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 2\n",
      "Length of original_rows: 0\n",
      "Processing itemized: q_id=1314, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 13\n",
      "Length of original_rows: 14\n",
      "Processing itemized: q_id=1314, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "Processing itemized: q_id=1314, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 2\n",
      "Length of original_rows: 0\n",
      "Processing itemized: q_id=1315, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 13\n",
      "Length of original_rows: 14\n",
      "Processing itemized: q_id=1315, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 11\n",
      "Length of original_rows: 11\n",
      "Processing itemized: q_id=1315, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 3\n",
      "Processing itemized: q_id=1344, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 11\n",
      "Processing itemized: q_id=1344, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 7\n",
      "Length of original_rows: 2\n",
      "Processing itemized: q_id=1344, type_of_upgrade=ADNU\n",
      "Length of addendum_rows: 2\n",
      "Length of original_rows: 4\n",
      "Processing itemized: q_id=1344, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 0\n",
      "Processing itemized: q_id=1344, type_of_upgrade=Distribution Upgrades\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 0\n",
      "Processing total: q_id=1306, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1306, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1306, type_of_upgrade=RNU\n",
      "Processing total: q_id=1307, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1307, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1307, type_of_upgrade=RNU\n",
      "Processing total: q_id=1308, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1308, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1308, type_of_upgrade=RNU\n",
      "Processing total: q_id=1309, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1309, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1309, type_of_upgrade=RNU\n",
      "Processing total: q_id=1310, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1310, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1310, type_of_upgrade=RNU\n",
      "Processing total: q_id=1312, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1312, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1312, type_of_upgrade=RNU\n",
      "Processing total: q_id=1313, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1313, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1313, type_of_upgrade=RNU\n",
      "Processing total: q_id=1314, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1314, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1314, type_of_upgrade=RNU\n",
      "Processing total: q_id=1315, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1315, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1315, type_of_upgrade=RNU\n",
      "Processing total: q_id=1344, type_of_upgrade=ADNU\n",
      "Processing total: q_id=1344, type_of_upgrade=PTO_IF\n",
      "Processing total: q_id=1344, type_of_upgrade=RNU\n",
      "Processing total: q_id=1344, type_of_upgrade=Distribution Upgrades\n",
      "Processing total: q_id=1344, type_of_upgrade=LDNU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  original_rows = pd.concat([original_rows, extra_rows], ignore_index=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  original_rows = pd.concat([original_rows, extra_rows], ignore_index=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  original_rows = pd.concat([original_rows, extra_rows], ignore_index=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  original_rows = pd.concat([original_rows, extra_rows], ignore_index=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  original_rows = pd.concat([original_rows, extra_rows], ignore_index=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  original_rows = pd.concat([original_rows, extra_rows], ignore_index=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:192: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  updated_itemized[col] = updated_itemized[col].replace('', np.nan)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:193: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  updated_total[col] = updated_total[col].replace('', np.nan)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:203: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .apply(lambda group: group.ffill().bfill())\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:208: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .apply(lambda group: group.ffill().bfill())\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:203: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .apply(lambda group: group.ffill().bfill())\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:208: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .apply(lambda group: group.ffill().bfill())\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:203: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .apply(lambda group: group.ffill().bfill())\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:208: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .apply(lambda group: group.ffill().bfill())\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:203: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .apply(lambda group: group.ffill().bfill())\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_4872/3158101785.py:208: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .apply(lambda group: group.ffill().bfill())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path, char_columns):\n",
    "    \"\"\"\n",
    "    Load a CSV file and ensure specific columns are treated as character, others as numeric.\n",
    "    \"\"\"\n",
    " # Get columns available in the dataset\n",
    "    available_columns = pd.read_csv(file_path, nrows=0).columns\n",
    "    \n",
    "    # Restrict to char_columns that are present in the dataset\n",
    "    char_columns_in_dataset = [col for col in char_columns if col in available_columns]\n",
    "    \n",
    "    # Load the dataset, treating char_columns_in_dataset as strings\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        dtype={col: str for col in char_columns_in_dataset},\n",
    "        na_values=[],  # Disable automatic NaN interpretation\n",
    "        keep_default_na=False  # Prevent treating \"None\" as NaN\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Convert all other columns to numeric\n",
    "    #for col in df.columns:\n",
    "    #    if col not in char_columns:\n",
    "    #        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_data(df, file_path, char_columns):\n",
    "    \"\"\"\n",
    "    Save a dataframe to a CSV file, ensuring specific columns are treated as character.\n",
    "    \"\"\"\n",
    "    for col in char_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def merge_with_addendums(itemized, itemized_addendums, total, total_addendums):\n",
    "    # Add an 'original' column to the datasets\n",
    "    itemized['original'] = \"yes\"\n",
    "    total['original'] = \"yes\"\n",
    "    \n",
    "    # Preserve the original row order\n",
    "    itemized['row_order'] = pd.to_numeric(itemized.index, errors=\"coerce\")\n",
    "    total['row_order'] = pd.to_numeric(total.index, errors=\"coerce\")\n",
    "    \n",
    "    # Ensure q_id is numeric for comparison\n",
    "    itemized['q_id'] = pd.to_numeric(itemized['q_id'], errors=\"coerce\")\n",
    "    itemized_addendums['q_id'] = pd.to_numeric(itemized_addendums['q_id'], errors=\"coerce\")\n",
    "    total['q_id'] = pd.to_numeric(total['q_id'], errors=\"coerce\")\n",
    "    total_addendums['q_id'] = pd.to_numeric(total_addendums['q_id'], errors=\"coerce\")\n",
    "    \n",
    "    # Columns for conditional replacement\n",
    "    conditional_columns = [\"req_deliverability\", \"latitude\", \"longitude\", \"capacity\", \"point_of_interconnection\"]\n",
    "    \n",
    "    # --- Process itemized data (unchanged) ---\n",
    "    updated_itemized_rows = []\n",
    "    for q_id in itemized_addendums['q_id'].unique():\n",
    "        for upgrade_type in itemized_addendums['type_of_upgrade'].unique():\n",
    "            addendum_rows = itemized_addendums[\n",
    "                (itemized_addendums['q_id'] == q_id) &\n",
    "                (itemized_addendums['type_of_upgrade'] == upgrade_type)\n",
    "            ]\n",
    "            if not addendum_rows.empty:\n",
    "                mask = (itemized['q_id'] == q_id) & (itemized['type_of_upgrade'] == upgrade_type)\n",
    "                original_rows = itemized[mask]\n",
    "                print(f\"Processing itemized: q_id={q_id}, type_of_upgrade={upgrade_type}\")\n",
    "                print(f\"Length of addendum_rows: {len(addendum_rows)}\")\n",
    "                print(f\"Length of original_rows: {len(original_rows)}\")\n",
    "                # For specified columns, replace if addendum values are non-empty\n",
    "                for col in conditional_columns:\n",
    "                    if col in addendum_rows.columns and col in original_rows.columns:\n",
    "                        addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
    "                        addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
    "                        addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
    "                # Align lengths\n",
    "                original_rows = original_rows.reset_index(drop=True)\n",
    "                addendum_rows = addendum_rows.reset_index(drop=True)\n",
    "                if len(addendum_rows) > len(original_rows):\n",
    "                    extra_rows = pd.DataFrame({col: pd.NA for col in original_rows.columns},\n",
    "                                              index=range(len(addendum_rows) - len(original_rows)))\n",
    "                    original_rows = pd.concat([original_rows, extra_rows], ignore_index=True)\n",
    "                elif len(addendum_rows) < len(original_rows):\n",
    "                    original_rows = original_rows.iloc[:len(addendum_rows)].reset_index(drop=True)\n",
    "                itemized.loc[mask, 'original'] = \"no\"\n",
    "                updated_itemized_rows.append(\n",
    "                    addendum_rows.assign(original=\"no\", row_order=original_rows['row_order'].values[:len(addendum_rows)])\n",
    "                )\n",
    "                itemized = itemized[~mask]\n",
    "    if updated_itemized_rows:\n",
    "        updated_itemized = pd.concat([itemized] + updated_itemized_rows, ignore_index=True)\n",
    "    else:\n",
    "        updated_itemized = itemized.copy()\n",
    "    updated_itemized[\"row_order\"] = pd.to_numeric(updated_itemized[\"row_order\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    updated_itemized = updated_itemized.sort_values(by=\"row_order\").drop(columns=[\"row_order\"]).reset_index(drop=True)\n",
    "    \n",
    "    # --- Process total data ---\n",
    "    updated_total_rows = []\n",
    "    for q_id in total_addendums['q_id'].unique():\n",
    "        for upgrade_type in total_addendums['type_of_upgrade'].unique():\n",
    "            addendum_row = total_addendums[\n",
    "                (total_addendums['q_id'] == q_id) &\n",
    "                (total_addendums['type_of_upgrade'] == upgrade_type)\n",
    "            ]\n",
    "            if not addendum_row.empty:\n",
    "                mask = (total['q_id'] == q_id) & (total['type_of_upgrade'] == upgrade_type)\n",
    "                original_row = total[mask]\n",
    "                print(f\"Processing total: q_id={q_id}, type_of_upgrade={upgrade_type}\")\n",
    "                # If no matching original row exists, create a default row_order column\n",
    "                if original_row.empty:\n",
    "                    original_row = pd.DataFrame({'row_order': [pd.NA] * len(addendum_row)}, index=addendum_row.index)\n",
    "                else:\n",
    "                    original_row = original_row.reset_index(drop=True)\n",
    "                addendum_row = addendum_row.reset_index(drop=True)\n",
    "                if len(addendum_row) > len(original_row):\n",
    "                    extra_rows = pd.DataFrame({col: pd.NA for col in original_row.columns},\n",
    "                                              index=range(len(addendum_row) - len(original_row)))\n",
    "                    original_row = pd.concat([original_row, extra_rows], ignore_index=True)\n",
    "                elif len(addendum_row) < len(original_row):\n",
    "                    original_row = original_row.iloc[:len(addendum_row)].reset_index(drop=True)\n",
    "                for col in conditional_columns:\n",
    "                    if col in addendum_row.columns and col in original_row.columns:\n",
    "                        addendum_row[col] = addendum_row[col].replace(\"\", pd.NA)\n",
    "                        addendum_row[col] = addendum_row[col].combine_first(original_row[col].reset_index(drop=True))\n",
    "                        addendum_row[col] = addendum_row[col].fillna(\"\")\n",
    "                total.loc[mask, 'original'] = \"no\"\n",
    "                updated_total_rows.append(\n",
    "                    addendum_row.assign(original=\"no\", row_order=original_row['row_order'].values[:len(addendum_row)])\n",
    "                )\n",
    "                total = total[~mask]\n",
    "    if updated_total_rows:\n",
    "        updated_total = pd.concat([total] + updated_total_rows, ignore_index=True)\n",
    "    else:\n",
    "        updated_total = total.copy()\n",
    "    updated_total[\"row_order\"] = pd.to_numeric(updated_total[\"row_order\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    updated_total = updated_total.sort_values(by=\"row_order\").drop(columns=[\"row_order\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Fill missing columns with zeros in the updated datasets\n",
    "    for col in set(itemized.columns) - set(updated_itemized.columns):\n",
    "        updated_itemized[col] = 0\n",
    "    for col in set(total.columns) - set(updated_total.columns):\n",
    "        updated_total[col] = 0\n",
    "\n",
    "    # Move the 'original' column to the last position\n",
    "    updated_itemized = updated_itemized[[col for col in updated_itemized.columns if col != 'original'] + ['original']]\n",
    "    updated_total = updated_total[[col for col in updated_total.columns if col != 'original'] + ['original']]\n",
    "    \n",
    "    if \"row_order\" in updated_itemized.columns:\n",
    "        updated_itemized = updated_itemized.drop(columns=[\"row_order\"]).reset_index(drop=True)\n",
    "    if \"row_order\" in updated_total.columns:\n",
    "        updated_total = updated_total.drop(columns=[\"row_order\"]).reset_index(drop=True)\n",
    "    \n",
    "    return updated_itemized, updated_total\n",
    "\n",
    "\n",
    "# Define the character columns\n",
    "char_columns = [\n",
    "    \"req_deliverability\", \"point_of_interconnection\", \"type_of_upgrade\",\n",
    "    \"upgrade\", \"description\", \"estimated_time_to_construct\", \"original\", \"item\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "itemized = load_data(\"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_itemized.csv\", char_columns)\n",
    "itemized_addendums = load_data(\"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_itemized_addendums.csv\", char_columns)\n",
    "total = load_data(\"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_total.csv\", char_columns)\n",
    "total_addendums = load_data(\"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/02_intermediate/costs_phase_1_cluster_9_style_J_total_addendums.csv\", char_columns)\n",
    "\n",
    "\n",
    "updated_itemized, updated_total = merge_with_addendums(itemized, itemized_addendums, total, total_addendums)\n",
    "\n",
    "# Drop the specified columns from the updated datasets\n",
    "columns_to_drop = [ \"upgrade_classification\",\"estimated\", \"caiso_queue\", \"project_type\", \"dependent_system_upgrade\"]\n",
    "\n",
    "# For the itemized dataset\n",
    "updated_itemized = updated_itemized.drop(columns=[col for col in columns_to_drop if col in updated_itemized.columns], errors='ignore')\n",
    "\n",
    "# For the total dataset\n",
    "updated_total = updated_total.drop(columns=[col for col in columns_to_drop if col in updated_total.columns], errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "# List of columns to process with ffill and bfill\n",
    "columns_to_fill = [\"point_of_interconnection\", \"latitude\", \"longitude\", \"req_deliverability\", \"capacity\"]\n",
    "\n",
    "# Replace empty strings with NaN for the specified columns\n",
    "for col in columns_to_fill:\n",
    "    updated_itemized[col] = updated_itemized[col].replace('', np.nan)\n",
    "    updated_total[col] = updated_total[col].replace('', np.nan)\n",
    "\n",
    "# Sort by q_id while maintaining other column order (stable sorting)\n",
    "updated_itemized = updated_itemized.sort_values(by=[\"q_id\"], kind=\"stable\").reset_index(drop=True)\n",
    "updated_total = updated_total.sort_values(by=[\"q_id\"], kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "# Apply forward-fill and backward-fill for the specified columns within each q_id group\n",
    "for col in columns_to_fill:\n",
    "    updated_itemized[col] = (\n",
    "        updated_itemized.groupby(\"q_id\")[col]\n",
    "        .apply(lambda group: group.ffill().bfill())\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    updated_total[col] = (\n",
    "        updated_total.groupby(\"q_id\")[col]\n",
    "        .apply(lambda group: group.ffill().bfill())\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# Replace NaN back with empty strings for consistency\n",
    "for col in columns_to_fill:\n",
    "    updated_itemized[col] = updated_itemized[col].replace(np.nan, '')\n",
    "    updated_total[col] = updated_total[col].replace(np.nan, '')\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the updated datasets\n",
    "save_data(updated_itemized, \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/01_clean/costs_phase_1_cluster_9_style_J_itemized_updated.csv\", char_columns)\n",
    "save_data(updated_total, \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_1_cost_data/Cluster 9/01_clean/costs_phase_1_cluster_9_style_J_total_updated.csv\", char_columns)\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}