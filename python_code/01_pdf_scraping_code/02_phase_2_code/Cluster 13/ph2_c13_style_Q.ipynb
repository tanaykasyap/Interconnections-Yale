{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 8 Cluster 13- Style Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped PDF: Q1683-Buena Vista Storage-Appendix_A-C13PhII.pdf from Project 1683\n",
      "Scraped PDF: Q1687-Conaway Hybrid Power Plant-Appendix_A-C13PhII.pdf from Project 1687\n",
      "Scraped PDF: Q1688-Crossroads-Appendix_A-C13PhII.pdf from Project 1688\n",
      "Scraped Addendum PDF: Q1688CrossroadsAppendix_AC13PhIIRevision1.pdf from Project 1688\n",
      "Scraped PDF: Q1690-Denali Energy Storage-Appendix_A-C13PhII.pdf from Project 1690\n",
      "Scraped PDF: Q1691-Fortis-Appendix_A-C13PhII.pdf from Project 1691\n",
      "Scraped Addendum PDF: Q1691FortisAppendix_AC13PhIIRevision1.pdf from Project 1691\n",
      "Scraped PDF: Q1695-Meadows Energy Storage-Appendix_A-C13PhII.pdf from Project 1695\n",
      "Scraped PDF: Q1700-North Bay Energy Storage-Appendix_A-C13PhII.pdf from Project 1700\n",
      "Scraped PDF: Q1702-Potentia-Viridi-Appendix_A-C13PhII.pdf from Project 1702\n",
      "Scraped PDF: Q1705-Steel City Battery Storage-Appendix_A-C13PhII.pdf from Project 1705\n",
      "Skipped PDF: C13Ph2 - Attachment 1 - Allocation of NU Cost Estimates - Q1709.pdf from Project 1709 (No Table 7)\n",
      "Scraped PDF: Q1709-Rosemary-Appendix_A-C13PhII.pdf from Project 1709\n",
      "Skipped Addendum PDF: P2RPT-Q1709RosemaryAppendix_AC13PhIIAddendum1.pdf from Project 1709 (No Table 7)\n",
      "Scraped PDF: Q1713-Bia BESS 1-Appendix_A-C13PhII.pdf from Project 1713\n",
      "Scraped Addendum PDF: Q1713Lead_Appendix_AAddendum1.pdf from Project 1713\n",
      "Skipped Addendum PDF: P2RPT-Q1713BiaBESS1Appendix_AC13PhIIAddendum1.pdf from Project 1713 (No Table 7)\n",
      "Scraped Addendum PDF: P2RPT-Q1718GonzagaHybridAppendix_AC13PhIIAddendum1.pdf from Project 1718\n",
      "Scraped PDF: Q1728-Zeta-Appendix_A-C13PhII.pdf from Project 1728\n",
      "Scraped Addendum PDF: P2RPT-Q1728ZetaAppendix_AC13PhIIAddendum1.pdf from Project 1728\n",
      "Scraped Addendum PDF: P2RPT-Q1728ZetaAppendix_AC13PhIIAddendum2_.pdf from Project 1728\n",
      "Scraped Addendum PDF: Q1736Hawkins_Solar_HybridAppendix_AC13PhIIRevision1.pdf from Project 1736\n",
      "Scraped PDF: Q1739-Pecho Energy Storage-Appendix_A-C13PhII.pdf from Project 1739\n",
      "Skipped Addendum PDF: Q1739Pecho_Energy_Storage_Appendix_A_Addendum2.pdf from Project 1739 (No Table 7)\n",
      "Skipped Addendum PDF: Q1739Pecho_Energy_Storage_Appendix_A_Addendum3.pdf from Project 1739 (No Table 7)\n",
      "Scraped Addendum PDF: Q1739Pecho_Energy_StorageAppendix_AC13PhIIRevision1.pdf from Project 1739\n",
      "Scraped Addendum PDF: P2RPT-Q1740Puff_Hybrid_SolarAppendix_AC13PhIIRevision1.pdf from Project 1740\n",
      "Scraped PDF: Q1744-Second Fiddle-Appendix_A-C13PhII.pdf from Project 1744\n",
      "Skipped Addendum PDF: P2RPT-Q1744Second_FiddleAppendix_AC13PhIIAddendum1.pdf from Project 1744 (No Table 7)\n",
      "Scraped PDF: Q1745-Sunrise Power Improvement-Appendix_A-C13PhII.pdf from Project 1745\n",
      "Scraped PDF: Q1750-Windwalker Offshore-Appendix_A-C13PhII.pdf from Project 1750\n",
      "Skipped Addendum PDF: Q1750Windwalker_OffshoreAppendix_AC13PhIIAddendum1.pdf from Project 1750 (No Table 7)\n",
      "Scraped PDF: Q1751-Winston Hybrid PV and BESS-Appendix_A-C13PhII.pdf from Project 1751\n",
      "Skipped Addendum PDF: P2RPT-Q1751Winston_Hybrid_PV_and_BESSAppendix_AC13PhIIAddendum1.pdf from Project 1751 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-Attachment 3-revised.pdf from Project 1757 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-Attachment 1.pdf from Project 1757 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A.pdf from Project 1757 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-Attachment 3.pdf from Project 1757 (No Table 7)\n",
      "Skipped PDF: Revision2-QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Attachment 2.pdf from Project 1757 (No Table 7)\n",
      "Skipped Addendum PDF: QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-revised.pdf from Project 1757 (No Table 7 and original does not have Table 7)\n",
      "Skipped Addendum PDF: Revision2-QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Attachment 3.pdf from Project 1757 (No Table 7 and original does not have Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1758 TOT1005-DesertSands-Appendix A-Attachment 1.pdf from Project 1758 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1758 TOT1005-DesertSands-Appendix A.pdf from Project 1758 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1758 TOT1005-DesertSands-Appendix A-Attachment 2.pdf from Project 1758 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1759 TOT1016-Eternal-Appendix A-Attachment 2.pdf from Project 1759 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1759 TOT1016-Eternal-Appendix A-Attachment 1.pdf from Project 1759 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1759 TOT1016-Eternal-Appendix A.pdf from Project 1759 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-Attachment 3-revised.pdf from Project 1761 (No Table 7)\n",
      "Skipped PDF: Revision2-QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Attachment 2.pdf from Project 1761 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A.pdf from Project 1761 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-Attachment 1.pdf from Project 1761 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-Attachment 3.pdf from Project 1761 (No Table 7)\n",
      "Skipped Addendum PDF: QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-revised.pdf from Project 1761 (No Table 7 and original does not have Table 7)\n",
      "Skipped Addendum PDF: Revision2-QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Attachment 3.pdf from Project 1761 (No Table 7 and original does not have Table 7)\n",
      "Skipped Addendum PDF: Revision2-QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Attachment 1.pdf from Project 1761 (No Table 7 and original does not have Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1763 TOT988-Porta-Appendix A-Attachment 2.pdf from Project 1763 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1763 TOT988-Porta-Appendix A-Attachment 1.pdf from Project 1763 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1763 TOT988-Porta-Appendix A.pdf from Project 1763 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1764 TOT976-Sapphire-Appendix A.pdf from Project 1764 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1764 TOT976-Sapphire-Appendix A-Attachment 1.pdf from Project 1764 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Eastern-Q1764 TOT976-Sapphire-Appendix A-Attachment 2.pdf from Project 1764 (No Table 7)\n",
      "Skipped PDF: C13.2-Metro-Q1766-TOT996-Commerce2-AppendixA.pdf from Project 1766 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1766 TOT996.pdf from Project 1766 (No Table 7)\n",
      "Skipped PDF: C13PII- Metro-Area Report_rev2_rs.pdf from Project 1768 (No Table 7)\n",
      "Skipped PDF: C13PII-Metro-Attachment1-TOT1008 Q1768.pdf from Project 1768 (No Table 7)\n",
      "Skipped PDF: C13.2-Metro-Q1768-TOT1008-Roadhouse-AppendixA.pdf from Project 1768 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1768 TOT1008.pdf from Project 1768 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 3 Q1768 TOT1008.pdf from Project 1768 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1774 TOT981.pdf from Project 1774 (No Table 7)\n",
      "Skipped PDF: C13.2-NOL-Q1774-TOT981-Overnight-ApndxA.pdf from Project 1774 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 3 Q1774 TOT981.pdf from Project 1774 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2-Attachment 1 Q1774 TOT981-Overnight.pdf from Project 1774 (No Table 7)\n",
      "Skipped PDF: C13.2-NOL-Q1775-TOT989-SEGSEx2-ApndxA.pdf from Project 1775 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 3 Q1775 TOT989.pdf from Project 1775 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1775 TOT989.pdf from Project 1775 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 1 Q1776 TOT993-Ventoso.pdf from Project 1776 (No Table 7)\n",
      "Skipped PDF: C13.2-NOL-Q1776-TOT993-Ventoso-ApndxA.pdf from Project 1776 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 3 Q1776 TOT993.pdf from Project 1776 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1776 TOT993.pdf from Project 1776 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Northern-Q1779&TOT966-Bellefield3-Appendix A-Attachment 1.pdf from Project 1779 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1779 TOT966.pdf from Project 1779 (No Table 7)\n",
      "Skipped PDF: C13.2-North-Q1779-TOT966-Bellefiled3-AppendixA.pdf from Project 1779 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Northern-Q1782&TOT1002-Gem-Appendix A-Attachment 1.pdf from Project 1782 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1782 TOT1002.pdf from Project 1782 (No Table 7)\n",
      "Skipped PDF: C13.2-North-Q1782-TOT1002-Gem-AppendixA.pdf from Project 1782 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Northern-Q1784&TOT983-Keyhole-Appendix A-Attachment 1.pdf from Project 1784 (No Table 7)\n",
      "Skipped PDF: C13.2-North-Q1784-TOT983-Keyhole-AppendixA.pdf from Project 1784 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1784 TOT983.pdf from Project 1784 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1789 TOT965.pdf from Project 1789 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Northern-Q1789&TOT965-Rexford2-Appendix A-Attachment 1.pdf from Project 1789 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 3 Q1789 TOT965.pdf from Project 1789 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Northern-Q1789&TOT965-Rexford2-Appendix A-Attachment 1_v2.pdf from Project 1789 (No Table 7)\n",
      "Skipped PDF: C13.2-North-Q1789-TOT965-Rexford2-AppendixA.pdf from Project 1789 (No Table 7)\n",
      "Skipped Addendum PDF: QC13 Ph2 Attachment 2 Q1789 TOT965 addendum.pdf from Project 1789 (No Table 7 and original does not have Table 7)\n",
      "Skipped PDF: C13.2-North-Q1790-TOT987-Sanborn4-AppendixA.pdf from Project 1790 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Northern-Q1790&TOT987-Sanborn4-Appendix A-Attachment 1.pdf from Project 1790 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1790 TOT987.pdf from Project 1790 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 3 Q1791 TOT985.pdf from Project 1791 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Northern-Q1791&TOT985-Sanborn5-Appendix A-Attachment 1.pdf from Project 1791 (No Table 7)\n",
      "Skipped PDF: C13.2-North-Q1791-TOT985-Sanborn5-ApndxA-01.04.22.pdf from Project 1791 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1791 TOT985.pdf from Project 1791 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Northern-Q1792&TOT969-Sequoia-Appendix A-Attachment 1.pdf from Project 1792 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1792 TOT969.pdf from Project 1792 (No Table 7)\n",
      "Skipped PDF: C13.2-North-Q1792-TOT969-Sequoia-AppendixA.pdf from Project 1792 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 3 Q1792 TOT969.pdf from Project 1792 (No Table 7)\n",
      "Skipped PDF: QC13PII-SCE-Northern-Q1792&TOT969-Sequoia-Appendix A-Attachment 1_v2.pdf from Project 1792 (No Table 7)\n",
      "Skipped Addendum PDF: QC13 Ph2 Attachment 2 Q1792 TOT969 addendum.pdf from Project 1792 (No Table 7 and original does not have Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1795 TOT967.pdf from Project 1795 (No Table 7)\n",
      "Skipped PDF: C13.2-EOP-Q1795-TOT967-Arida3-ApndxA.pdf from Project 1795 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 3 Q1795 TOT967.pdf from Project 1795 (No Table 7)\n",
      "Skipped PDF: QC13PII EOP Attch1 TOT967-Q1795 Arida Solar Farm 3.pdf from Project 1795 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1796 TOT995.pdf from Project 1796 (No Table 7)\n",
      "Skipped PDF: QC13PII EOP Attch1 TOT995-Q1796 Delamar Energy Storage.pdf from Project 1796 (No Table 7)\n",
      "Skipped PDF: C13.2-EOP-Q1796-TOT995-Delamar-ApndxA.pdf from Project 1796 (No Table 7)\n",
      "Skipped Addendum PDF: QC13 Ph2 Attachment 2 Q1796 TOT995_CRAS Removal Addendum.pdf from Project 1796 (No Table 7 and original does not have Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1798 TOT972 AFS.pdf from Project 1798 (No Table 7)\n",
      "Skipped PDF: QC13PII-EOP-GLW-Q1798&TOT972-CalvadaSprings-Appendix A.pdf from Project 1798 (No Table 7)\n",
      "Skipped PDF: C13P2-GLW-Q1798-Appendix A-GLW-Attachment 2.pdf from Project 1798 (No Table 7)\n",
      "Skipped PDF: C13.2-EOP-Q1798-TOT972-Calvada-AFS_ApndxA.pdf from Project 1798 (No Table 7)\n",
      "Skipped Addendum PDF: QC13 Ph2 Attachment 2 Q1798 TOT972 AFS_CRAS Removal Addendum.pdf from Project 1798 (No Table 7 and original does not have Table 7)\n",
      "Skipped PDF: C13P2-GLW-Q1799-Appendix A-GLW-Attachment 2.pdf from Project 1799 (No Table 7)\n",
      "Skipped PDF: QC13PII-EOP-GLW-Q1799&TOT979-RoughHat2-AppendixA.pdf from Project 1799 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1799 TOT979 AFS.pdf from Project 1799 (No Table 7)\n",
      "Skipped PDF: C13.2-EOP-Q1799-TOT979-RoughHat2-AFS_ApndxA.pdf from Project 1799 (No Table 7)\n",
      "Skipped PDF: QC13PII-EOP-GLW-Q1800&TOT984-Sagittarius-AppendixA.pdf from Project 1800 (No Table 7)\n",
      "Skipped PDF: C13P2-GLW-Q1800-Appendix A-GLW-Attachment 2.pdf from Project 1800 (No Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1800 TOT984 AFS.pdf from Project 1800 (No Table 7)\n",
      "Skipped PDF: C13.2-EOP-Q1800-TOT984-Sagittarius-AFS_ApndxA.pdf from Project 1800 (No Table 7)\n",
      "Skipped Addendum PDF: QC13 Ph2 Attachment 2 Q1800 TOT984 AFS_CRAS Removal Addendum.pdf from Project 1800 (No Table 7 and original does not have Table 7)\n",
      "Skipped PDF: QC13 Ph2 Attachment 2 Q1801 TOT971 AFS.pdf from Project 1801 (No Table 7)\n",
      "Skipped PDF: QC13PII-EOP-GLW-Q1801&TOT971-WaterRock-AppendixA.pdf from Project 1801 (No Table 7)\n",
      "Skipped PDF: C13.2-EOP-Q1801-TOT971-WaterRock-AFS_ApndxA.pdf from Project 1801 (No Table 7)\n",
      "Skipped PDF: C13P2-GLW-Q1801-Appendix A-GLW-Attachment 2.pdf from Project 1801 (No Table 7)\n",
      "Skipped Addendum PDF: QC13 Ph2 Attachment 2 Q1801 TOT971 AFS_CRAS Removal Addendum.pdf from Project 1801 (No Table 7 and original does not have Table 7)\n",
      "Skipped PDF: QC13PhII_Q1818_Saddle Mountain_Solar_Appendix_A_11-22-21.pdf from Project 1818 (No Table 7)\n",
      "Skipped PDF: QC13PhII_Q1822_Sun_Streams_4_Appendix_A_11-22-21.pdf from Project 1822 (No Table 7)\n",
      "Skipped Addendum PDF: QC13PhII_Q1822_Sun_Streams_4_Appendix_A_Addendum1_12122.pdf from Project 1822 (No Table 7 and original does not have Table 7)\n",
      "Skipped PDF: QC13PhII_Q1823_Sun_Streams_5_Appendix_A_11-22-21.pdf from Project 1823 (No Table 7)\n",
      "Skipped Addendum PDF: QC13PhII_Q1823_Sun_Streams_5_Appendix_A_Addendum1_12122.pdf from Project 1823 (No Table 7 and original does not have Table 7)\n",
      "\n",
      "Columns reordered for originals as per specification.\n",
      "\n",
      "Data successfully saved to /Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/03_raw/ph2_rawdata_cluster13_style_Q_originals.csv\n",
      "\n",
      "Columns reordered for addendums as per specification.\n",
      "\n",
      "Data successfully saved to /Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/03_raw/ph2_rawdata_cluster13_style_Q_addendums.csv\n",
      "\n",
      "=== Scraping Summary ===\n",
      "Total Projects Processed: 110\n",
      "Total Projects Scraped: 20\n",
      "Total Projects Skipped: 90\n",
      "Total Projects Missing: 40\n",
      "Total PDFs Accessed: 163\n",
      "Total PDFs Scraped: 26\n",
      "Total PDFs Skipped: 113\n",
      "\n",
      "List of Scraped Projects:\n",
      "[1683, 1687, 1688, 1690, 1691, 1695, 1700, 1702, 1705, 1709, 1713, 1718, 1728, 1736, 1739, 1740, 1744, 1745, 1750, 1751]\n",
      "\n",
      "List of Skipped Projects:\n",
      "[1682, 1684, 1685, 1686, 1689, 1692, 1694, 1696, 1699, 1703, 1710, 1712, 1714, 1715, 1719, 1721, 1722, 1723, 1724, 1726, 1729, 1731, 1732, 1733, 1735, 1737, 1738, 1741, 1742, 1743, 1747, 1748, 1749, 1752, 1754, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1766, 1768, 1770, 1774, 1775, 1776, 1778, 1779, 1780, 1782, 1783, 1784, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1805, 1806, 1810, 1811, 1812, 1814, 1815, 1817, 1818, 1820, 1821, 1822, 1823, 1824, 1825, 1827]\n",
      "\n",
      "List of Missing Projects:\n",
      "[1679, 1680, 1681, 1693, 1697, 1698, 1701, 1704, 1706, 1707, 1708, 1711, 1716, 1717, 1720, 1725, 1727, 1730, 1734, 1746, 1753, 1755, 1765, 1767, 1769, 1771, 1772, 1773, 1777, 1781, 1785, 1804, 1807, 1808, 1809, 1813, 1816, 1819, 1826, 1828]\n",
      "\n",
      "List of Scraped PDFs:\n",
      "['Q1683-Buena Vista Storage-Appendix_A-C13PhII.pdf', 'Q1687-Conaway Hybrid Power Plant-Appendix_A-C13PhII.pdf', 'Q1688-Crossroads-Appendix_A-C13PhII.pdf', 'Q1688CrossroadsAppendix_AC13PhIIRevision1.pdf', 'Q1690-Denali Energy Storage-Appendix_A-C13PhII.pdf', 'Q1691-Fortis-Appendix_A-C13PhII.pdf', 'Q1691FortisAppendix_AC13PhIIRevision1.pdf', 'Q1695-Meadows Energy Storage-Appendix_A-C13PhII.pdf', 'Q1700-North Bay Energy Storage-Appendix_A-C13PhII.pdf', 'Q1702-Potentia-Viridi-Appendix_A-C13PhII.pdf', 'Q1705-Steel City Battery Storage-Appendix_A-C13PhII.pdf', 'Q1709-Rosemary-Appendix_A-C13PhII.pdf', 'Q1713-Bia BESS 1-Appendix_A-C13PhII.pdf', 'Q1713Lead_Appendix_AAddendum1.pdf', 'P2RPT-Q1718GonzagaHybridAppendix_AC13PhIIAddendum1.pdf', 'Q1728-Zeta-Appendix_A-C13PhII.pdf', 'P2RPT-Q1728ZetaAppendix_AC13PhIIAddendum1.pdf', 'P2RPT-Q1728ZetaAppendix_AC13PhIIAddendum2_.pdf', 'Q1736Hawkins_Solar_HybridAppendix_AC13PhIIRevision1.pdf', 'Q1739-Pecho Energy Storage-Appendix_A-C13PhII.pdf', 'Q1739Pecho_Energy_StorageAppendix_AC13PhIIRevision1.pdf', 'P2RPT-Q1740Puff_Hybrid_SolarAppendix_AC13PhIIRevision1.pdf', 'Q1744-Second Fiddle-Appendix_A-C13PhII.pdf', 'Q1745-Sunrise Power Improvement-Appendix_A-C13PhII.pdf', 'Q1750-Windwalker Offshore-Appendix_A-C13PhII.pdf', 'Q1751-Winston Hybrid PV and BESS-Appendix_A-C13PhII.pdf']\n",
      "\n",
      "List of Skipped PDFs:\n",
      "['C13Ph2 - Attachment 1 - Allocation of NU Cost Estimates - Q1709.pdf', 'P2RPT-Q1709RosemaryAppendix_AC13PhIIAddendum1.pdf', 'P2RPT-Q1713BiaBESS1Appendix_AC13PhIIAddendum1.pdf', 'Q1739Pecho_Energy_Storage_Appendix_A_Addendum2.pdf', 'Q1739Pecho_Energy_Storage_Appendix_A_Addendum3.pdf', 'P2RPT-Q1744Second_FiddleAppendix_AC13PhIIAddendum1.pdf', 'Q1750Windwalker_OffshoreAppendix_AC13PhIIAddendum1.pdf', 'P2RPT-Q1751Winston_Hybrid_PV_and_BESSAppendix_AC13PhIIAddendum1.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-Attachment 3-revised.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-Attachment 3.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-revised.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Attachment 3.pdf', 'QC13PII-SCE-Eastern-Q1758 TOT1005-DesertSands-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1758 TOT1005-DesertSands-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1758 TOT1005-DesertSands-Appendix A-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1759 TOT1016-Eternal-Appendix A-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1759 TOT1016-Eternal-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1759 TOT1016-Eternal-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-Attachment 3-revised.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-Attachment 3.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-revised.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Attachment 3.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1763 TOT988-Porta-Appendix A-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1763 TOT988-Porta-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1763 TOT988-Porta-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1764 TOT976-Sapphire-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1764 TOT976-Sapphire-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1764 TOT976-Sapphire-Appendix A-Attachment 2.pdf', 'C13.2-Metro-Q1766-TOT996-Commerce2-AppendixA.pdf', 'QC13 Ph2 Attachment 2 Q1766 TOT996.pdf', 'C13PII- Metro-Area Report_rev2_rs.pdf', 'C13PII-Metro-Attachment1-TOT1008 Q1768.pdf', 'C13.2-Metro-Q1768-TOT1008-Roadhouse-AppendixA.pdf', 'QC13 Ph2 Attachment 2 Q1768 TOT1008.pdf', 'QC13 Ph2 Attachment 3 Q1768 TOT1008.pdf', 'QC13 Ph2 Attachment 2 Q1774 TOT981.pdf', 'C13.2-NOL-Q1774-TOT981-Overnight-ApndxA.pdf', 'QC13 Ph2 Attachment 3 Q1774 TOT981.pdf', 'QC13 Ph2-Attachment 1 Q1774 TOT981-Overnight.pdf', 'C13.2-NOL-Q1775-TOT989-SEGSEx2-ApndxA.pdf', 'QC13 Ph2 Attachment 3 Q1775 TOT989.pdf', 'QC13 Ph2 Attachment 2 Q1775 TOT989.pdf', 'QC13 Ph2 Attachment 1 Q1776 TOT993-Ventoso.pdf', 'C13.2-NOL-Q1776-TOT993-Ventoso-ApndxA.pdf', 'QC13 Ph2 Attachment 3 Q1776 TOT993.pdf', 'QC13 Ph2 Attachment 2 Q1776 TOT993.pdf', 'QC13PII-SCE-Northern-Q1779&TOT966-Bellefield3-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 2 Q1779 TOT966.pdf', 'C13.2-North-Q1779-TOT966-Bellefiled3-AppendixA.pdf', 'QC13PII-SCE-Northern-Q1782&TOT1002-Gem-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 2 Q1782 TOT1002.pdf', 'C13.2-North-Q1782-TOT1002-Gem-AppendixA.pdf', 'QC13PII-SCE-Northern-Q1784&TOT983-Keyhole-Appendix A-Attachment 1.pdf', 'C13.2-North-Q1784-TOT983-Keyhole-AppendixA.pdf', 'QC13 Ph2 Attachment 2 Q1784 TOT983.pdf', 'QC13 Ph2 Attachment 2 Q1789 TOT965.pdf', 'QC13PII-SCE-Northern-Q1789&TOT965-Rexford2-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 3 Q1789 TOT965.pdf', 'QC13PII-SCE-Northern-Q1789&TOT965-Rexford2-Appendix A-Attachment 1_v2.pdf', 'C13.2-North-Q1789-TOT965-Rexford2-AppendixA.pdf', 'QC13 Ph2 Attachment 2 Q1789 TOT965 addendum.pdf', 'C13.2-North-Q1790-TOT987-Sanborn4-AppendixA.pdf', 'QC13PII-SCE-Northern-Q1790&TOT987-Sanborn4-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 2 Q1790 TOT987.pdf', 'QC13 Ph2 Attachment 3 Q1791 TOT985.pdf', 'QC13PII-SCE-Northern-Q1791&TOT985-Sanborn5-Appendix A-Attachment 1.pdf', 'C13.2-North-Q1791-TOT985-Sanborn5-ApndxA-01.04.22.pdf', 'QC13 Ph2 Attachment 2 Q1791 TOT985.pdf', 'QC13PII-SCE-Northern-Q1792&TOT969-Sequoia-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 2 Q1792 TOT969.pdf', 'C13.2-North-Q1792-TOT969-Sequoia-AppendixA.pdf', 'QC13 Ph2 Attachment 3 Q1792 TOT969.pdf', 'QC13PII-SCE-Northern-Q1792&TOT969-Sequoia-Appendix A-Attachment 1_v2.pdf', 'QC13 Ph2 Attachment 2 Q1792 TOT969 addendum.pdf', 'QC13 Ph2 Attachment 2 Q1795 TOT967.pdf', 'C13.2-EOP-Q1795-TOT967-Arida3-ApndxA.pdf', 'QC13 Ph2 Attachment 3 Q1795 TOT967.pdf', 'QC13PII EOP Attch1 TOT967-Q1795 Arida Solar Farm 3.pdf', 'QC13 Ph2 Attachment 2 Q1796 TOT995.pdf', 'QC13PII EOP Attch1 TOT995-Q1796 Delamar Energy Storage.pdf', 'C13.2-EOP-Q1796-TOT995-Delamar-ApndxA.pdf', 'QC13 Ph2 Attachment 2 Q1796 TOT995_CRAS Removal Addendum.pdf', 'QC13 Ph2 Attachment 2 Q1798 TOT972 AFS.pdf', 'QC13PII-EOP-GLW-Q1798&TOT972-CalvadaSprings-Appendix A.pdf', 'C13P2-GLW-Q1798-Appendix A-GLW-Attachment 2.pdf', 'C13.2-EOP-Q1798-TOT972-Calvada-AFS_ApndxA.pdf', 'QC13 Ph2 Attachment 2 Q1798 TOT972 AFS_CRAS Removal Addendum.pdf', 'C13P2-GLW-Q1799-Appendix A-GLW-Attachment 2.pdf', 'QC13PII-EOP-GLW-Q1799&TOT979-RoughHat2-AppendixA.pdf', 'QC13 Ph2 Attachment 2 Q1799 TOT979 AFS.pdf', 'C13.2-EOP-Q1799-TOT979-RoughHat2-AFS_ApndxA.pdf', 'QC13PII-EOP-GLW-Q1800&TOT984-Sagittarius-AppendixA.pdf', 'C13P2-GLW-Q1800-Appendix A-GLW-Attachment 2.pdf', 'QC13 Ph2 Attachment 2 Q1800 TOT984 AFS.pdf', 'C13.2-EOP-Q1800-TOT984-Sagittarius-AFS_ApndxA.pdf', 'QC13 Ph2 Attachment 2 Q1800 TOT984 AFS_CRAS Removal Addendum.pdf', 'QC13 Ph2 Attachment 2 Q1801 TOT971 AFS.pdf', 'QC13PII-EOP-GLW-Q1801&TOT971-WaterRock-AppendixA.pdf', 'C13.2-EOP-Q1801-TOT971-WaterRock-AFS_ApndxA.pdf', 'C13P2-GLW-Q1801-Appendix A-GLW-Attachment 2.pdf', 'QC13 Ph2 Attachment 2 Q1801 TOT971 AFS_CRAS Removal Addendum.pdf', 'QC13PhII_Q1818_Saddle Mountain_Solar_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1822_Sun_Streams_4_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1822_Sun_Streams_4_Appendix_A_Addendum1_12122.pdf', 'QC13PhII_Q1823_Sun_Streams_5_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1823_Sun_Streams_5_Appendix_A_Addendum1_12122.pdf']\n",
      "\n",
      "List of Addendum PDFs:\n",
      "['Q1688CrossroadsAppendix_AC13PhIIRevision1.pdf', 'Q1691FortisAppendix_AC13PhIIRevision1.pdf', 'P2RPT-Q1709RosemaryAppendix_AC13PhIIAddendum1.pdf', 'Q1713Lead_Appendix_AAddendum1.pdf', 'P2RPT-Q1713BiaBESS1Appendix_AC13PhIIAddendum1.pdf', 'P2RPT-Q1718GonzagaHybridAppendix_AC13PhIIAddendum1.pdf', 'P2RPT-Q1728ZetaAppendix_AC13PhIIAddendum1.pdf', 'P2RPT-Q1728ZetaAppendix_AC13PhIIAddendum2_.pdf', 'Q1736Hawkins_Solar_HybridAppendix_AC13PhIIRevision1.pdf', 'Q1739Pecho_Energy_Storage_Appendix_A_Addendum2.pdf', 'Q1739Pecho_Energy_Storage_Appendix_A_Addendum3.pdf', 'Q1739Pecho_Energy_StorageAppendix_AC13PhIIRevision1.pdf', 'P2RPT-Q1740Puff_Hybrid_SolarAppendix_AC13PhIIRevision1.pdf', 'P2RPT-Q1744Second_FiddleAppendix_AC13PhIIAddendum1.pdf', 'Q1750Windwalker_OffshoreAppendix_AC13PhIIAddendum1.pdf', 'P2RPT-Q1751Winston_Hybrid_PV_and_BESSAppendix_AC13PhIIAddendum1.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-revised.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Attachment 3.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-revised.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Attachment 3.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Attachment 1.pdf', 'QC13 Ph2 Attachment 2 Q1789 TOT965 addendum.pdf', 'QC13 Ph2 Attachment 2 Q1792 TOT969 addendum.pdf', 'QC13 Ph2 Attachment 2 Q1796 TOT995_CRAS Removal Addendum.pdf', 'QC13 Ph2 Attachment 2 Q1798 TOT972 AFS_CRAS Removal Addendum.pdf', 'QC13 Ph2 Attachment 2 Q1800 TOT984 AFS_CRAS Removal Addendum.pdf', 'QC13 Ph2 Attachment 2 Q1801 TOT971 AFS_CRAS Removal Addendum.pdf', 'QC13PhII_Q1822_Sun_Streams_4_Appendix_A_Addendum1_12122.pdf', 'QC13PhII_Q1823_Sun_Streams_5_Appendix_A_Addendum1_12122.pdf']\n",
      "\n",
      "List of Original PDFs:\n",
      "['Q1683-Buena Vista Storage-Appendix_A-C13PhII.pdf', 'Q1687-Conaway Hybrid Power Plant-Appendix_A-C13PhII.pdf', 'Q1688-Crossroads-Appendix_A-C13PhII.pdf', 'Q1690-Denali Energy Storage-Appendix_A-C13PhII.pdf', 'Q1691-Fortis-Appendix_A-C13PhII.pdf', 'Q1695-Meadows Energy Storage-Appendix_A-C13PhII.pdf', 'Q1700-North Bay Energy Storage-Appendix_A-C13PhII.pdf', 'Q1702-Potentia-Viridi-Appendix_A-C13PhII.pdf', 'Q1705-Steel City Battery Storage-Appendix_A-C13PhII.pdf', 'C13Ph2 - Attachment 1 - Allocation of NU Cost Estimates - Q1709.pdf', 'Q1709-Rosemary-Appendix_A-C13PhII.pdf', 'Q1713-Bia BESS 1-Appendix_A-C13PhII.pdf', 'Q1728-Zeta-Appendix_A-C13PhII.pdf', 'Q1739-Pecho Energy Storage-Appendix_A-C13PhII.pdf', 'Q1744-Second Fiddle-Appendix_A-C13PhII.pdf', 'Q1745-Sunrise Power Improvement-Appendix_A-C13PhII.pdf', 'Q1750-Windwalker Offshore-Appendix_A-C13PhII.pdf', 'Q1751-Winston Hybrid PV and BESS-Appendix_A-C13PhII.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-Attachment 3-revised.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Appendix A-Attachment 3.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1757 TOT1013-Cobalt-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1758 TOT1005-DesertSands-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1758 TOT1005-DesertSands-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1758 TOT1005-DesertSands-Appendix A-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1759 TOT1016-Eternal-Appendix A-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1759 TOT1016-Eternal-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1759 TOT1016-Eternal-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-Attachment 3-revised.pdf', 'Revision2-QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1761 TOT1006-Grace-Appendix A-Attachment 3.pdf', 'QC13PII-SCE-Eastern-Q1763 TOT988-Porta-Appendix A-Attachment 2.pdf', 'QC13PII-SCE-Eastern-Q1763 TOT988-Porta-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1763 TOT988-Porta-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1764 TOT976-Sapphire-Appendix A.pdf', 'QC13PII-SCE-Eastern-Q1764 TOT976-Sapphire-Appendix A-Attachment 1.pdf', 'QC13PII-SCE-Eastern-Q1764 TOT976-Sapphire-Appendix A-Attachment 2.pdf', 'C13.2-Metro-Q1766-TOT996-Commerce2-AppendixA.pdf', 'QC13 Ph2 Attachment 2 Q1766 TOT996.pdf', 'C13PII- Metro-Area Report_rev2_rs.pdf', 'C13PII-Metro-Attachment1-TOT1008 Q1768.pdf', 'C13.2-Metro-Q1768-TOT1008-Roadhouse-AppendixA.pdf', 'QC13 Ph2 Attachment 2 Q1768 TOT1008.pdf', 'QC13 Ph2 Attachment 3 Q1768 TOT1008.pdf', 'QC13 Ph2 Attachment 2 Q1774 TOT981.pdf', 'C13.2-NOL-Q1774-TOT981-Overnight-ApndxA.pdf', 'QC13 Ph2 Attachment 3 Q1774 TOT981.pdf', 'QC13 Ph2-Attachment 1 Q1774 TOT981-Overnight.pdf', 'C13.2-NOL-Q1775-TOT989-SEGSEx2-ApndxA.pdf', 'QC13 Ph2 Attachment 3 Q1775 TOT989.pdf', 'QC13 Ph2 Attachment 2 Q1775 TOT989.pdf', 'QC13 Ph2 Attachment 1 Q1776 TOT993-Ventoso.pdf', 'C13.2-NOL-Q1776-TOT993-Ventoso-ApndxA.pdf', 'QC13 Ph2 Attachment 3 Q1776 TOT993.pdf', 'QC13 Ph2 Attachment 2 Q1776 TOT993.pdf', 'QC13PII-SCE-Northern-Q1779&TOT966-Bellefield3-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 2 Q1779 TOT966.pdf', 'C13.2-North-Q1779-TOT966-Bellefiled3-AppendixA.pdf', 'QC13PII-SCE-Northern-Q1782&TOT1002-Gem-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 2 Q1782 TOT1002.pdf', 'C13.2-North-Q1782-TOT1002-Gem-AppendixA.pdf', 'QC13PII-SCE-Northern-Q1784&TOT983-Keyhole-Appendix A-Attachment 1.pdf', 'C13.2-North-Q1784-TOT983-Keyhole-AppendixA.pdf', 'QC13 Ph2 Attachment 2 Q1784 TOT983.pdf', 'QC13 Ph2 Attachment 2 Q1789 TOT965.pdf', 'QC13PII-SCE-Northern-Q1789&TOT965-Rexford2-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 3 Q1789 TOT965.pdf', 'QC13PII-SCE-Northern-Q1789&TOT965-Rexford2-Appendix A-Attachment 1_v2.pdf', 'C13.2-North-Q1789-TOT965-Rexford2-AppendixA.pdf', 'C13.2-North-Q1790-TOT987-Sanborn4-AppendixA.pdf', 'QC13PII-SCE-Northern-Q1790&TOT987-Sanborn4-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 2 Q1790 TOT987.pdf', 'QC13 Ph2 Attachment 3 Q1791 TOT985.pdf', 'QC13PII-SCE-Northern-Q1791&TOT985-Sanborn5-Appendix A-Attachment 1.pdf', 'C13.2-North-Q1791-TOT985-Sanborn5-ApndxA-01.04.22.pdf', 'QC13 Ph2 Attachment 2 Q1791 TOT985.pdf', 'QC13PII-SCE-Northern-Q1792&TOT969-Sequoia-Appendix A-Attachment 1.pdf', 'QC13 Ph2 Attachment 2 Q1792 TOT969.pdf', 'C13.2-North-Q1792-TOT969-Sequoia-AppendixA.pdf', 'QC13 Ph2 Attachment 3 Q1792 TOT969.pdf', 'QC13PII-SCE-Northern-Q1792&TOT969-Sequoia-Appendix A-Attachment 1_v2.pdf', 'QC13 Ph2 Attachment 2 Q1795 TOT967.pdf', 'C13.2-EOP-Q1795-TOT967-Arida3-ApndxA.pdf', 'QC13 Ph2 Attachment 3 Q1795 TOT967.pdf', 'QC13PII EOP Attch1 TOT967-Q1795 Arida Solar Farm 3.pdf', 'QC13 Ph2 Attachment 2 Q1796 TOT995.pdf', 'QC13PII EOP Attch1 TOT995-Q1796 Delamar Energy Storage.pdf', 'C13.2-EOP-Q1796-TOT995-Delamar-ApndxA.pdf', 'QC13 Ph2 Attachment 2 Q1798 TOT972 AFS.pdf', 'QC13PII-EOP-GLW-Q1798&TOT972-CalvadaSprings-Appendix A.pdf', 'C13P2-GLW-Q1798-Appendix A-GLW-Attachment 2.pdf', 'C13.2-EOP-Q1798-TOT972-Calvada-AFS_ApndxA.pdf', 'C13P2-GLW-Q1799-Appendix A-GLW-Attachment 2.pdf', 'QC13PII-EOP-GLW-Q1799&TOT979-RoughHat2-AppendixA.pdf', 'QC13 Ph2 Attachment 2 Q1799 TOT979 AFS.pdf', 'C13.2-EOP-Q1799-TOT979-RoughHat2-AFS_ApndxA.pdf', 'QC13PII-EOP-GLW-Q1800&TOT984-Sagittarius-AppendixA.pdf', 'C13P2-GLW-Q1800-Appendix A-GLW-Attachment 2.pdf', 'QC13 Ph2 Attachment 2 Q1800 TOT984 AFS.pdf', 'C13.2-EOP-Q1800-TOT984-Sagittarius-AFS_ApndxA.pdf', 'QC13 Ph2 Attachment 2 Q1801 TOT971 AFS.pdf', 'QC13PII-EOP-GLW-Q1801&TOT971-WaterRock-AppendixA.pdf', 'C13.2-EOP-Q1801-TOT971-WaterRock-AFS_ApndxA.pdf', 'C13P2-GLW-Q1801-Appendix A-GLW-Attachment 2.pdf', 'QC13PhII_Q1818_Saddle Mountain_Solar_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1822_Sun_Streams_4_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1823_Sun_Streams_5_Appendix_A_11-22-21.pdf']\n",
      "\n",
      "List of Style N PDFs (Skipped due to 'Network Upgrade Type'):\n",
      "['QC13PhII_Q1802_AmpChamp_Storage_Appendix_A_11-22-21.pdf', 'P2RPT-QC13PhII_Q1802_AmpChamp_Storage_Appendix_A_Addendum_1_121721.pdf', 'QC13PhII_Q1802_AmpChamp_Storage_Appendix_A_Addendum_2_12122.pdf', 'QC13PhII_Q1806_Captiva_Energy_Storage_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1806_Captiva_Energy_Storage_Appendix_A_Addendum2_32822.pdf', 'QC13PhII_Q1806_Captiva_Energy_Storage_Appendix_A_Addendum1_012422.pdf', 'QC13PhII_Q1810_Drop_Zone_Storage_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1811_Duck_Pilot_Storage_Appendix_A_11-22-21.pdf', 'P2RPT-QC13PhII_Q1811_Duck_Pilot_Storage_Appendix_A_Addendum1_121721.pdf', 'QC13PhII_Q1812_Elisabeth_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1812_Elisabeth_Appendix_A_112221_v2.pdf', 'QC13PhII_Q1812_Elisabeth_Appendix_A_v2_Addendum1_12122.pdf', 'QC13PhII_Q1814_Hedionda_Energy_Storage_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1815_Hinton_Energy_Storage_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1815_Hinton_Energy_Storage_Appendix_A_Rev1_12122.pdf', 'QC13PhII_Q1820_Scafell_Storage_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1820_Scafell_Storage_Appendix_A_Rev1_12122.pdf', 'QC13PhII_Q1821_Seguro_Storage_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1821_Seguro_Storage_Appendix_A_Addendum1_12122.pdf', 'QC13PhII_Q1824_Viento_Fronterizo_Appendix_A_11-22-21.pdf', 'QC13PhII_Q1824_Viento_Fronterizo_Appendix_A_Rev1_Addendum1_12122.pdf', 'P2RPT-QC13PhII_Q1824_Viento_Fronterizo_Appendix_A_Rev1_121721.pdf', 'P2RPT-QC13PhII_Q1824_Viento_Fronterizo_Appendix_A_Rev2_22924.pdf', 'QC13PhII_Q1825_Viking_Energy_Storage_Appendix_A_11-22-21.pdf']\n",
      "\n",
      "Total Number of Style N PDFs: 24\n",
      "\n",
      "Number of Original PDFs Scraped: 17\n",
      "Number of Addendum PDFs Scraped: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/454131560.py:1104: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(clean_string_cell)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/454131560.py:1104: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(clean_string_cell)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import PyPDF2\n",
    "import traceback\n",
    "\n",
    "# Define paths and project range\n",
    "BASE_DIRECTORY = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/03_data\"\n",
    "OUTPUT_CSV_PATH_ORIGINAL = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/03_raw/ph2_rawdata_cluster13_style_Q_originals.csv\"\n",
    "OUTPUT_CSV_PATH_ADDENDUM = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/03_raw/ph2_rawdata_cluster13_style_Q_addendums.csv\"\n",
    "LOG_FILE_PATH = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/03_raw/ph2_scraping_cluster13_style_Q_log.txt\"\n",
    "# List of Style N PDFs\n",
    "style_Q_Q_IDS = [\n",
    "     \n",
    "1859,1871, 1875, 1881, 1932, 1954, 1956, 1958, 1959, 1963, 1968, 1973, 1992, 2096\n",
    "\n",
    "]\n",
    "\n",
    "PROJECT_RANGE = range(1679, 1829)   \n",
    "\n",
    "# Set PROJECT_LIST to the list of Style N q_ids\n",
    "PROJECT_LIST = style_Q_Q_IDS\n",
    "\n",
    "\n",
    "# Initialize DataFrames\n",
    "core_originals = pd.DataFrame()\n",
    "core_addendums = pd.DataFrame()\n",
    "\n",
    "# Initialize tracking variables\n",
    "scraped_projects = set()\n",
    "skipped_projects = set()\n",
    "missing_projects = set()\n",
    "scraped_pdfs = []\n",
    "skipped_pdfs = []\n",
    "addendum_pdfs = []\n",
    "original_pdfs = []\n",
    "style_n_pdfs = []  # List to track style N PDFs\n",
    "total_pdfs_accessed = 0\n",
    "total_pdfs_scraped = 0\n",
    "total_pdfs_skipped = 0\n",
    "original_has_table7 = {}  # Dictionary to track if original PDFs have table7\n",
    "\n",
    "def clean_column_headers(headers):\n",
    "    \"\"\"Cleans column headers by normalizing and removing unwanted characters.\"\"\"\n",
    "    cleaned_headers = []\n",
    "    for header in headers:\n",
    "        if header is None:\n",
    "            header = \"\"\n",
    "        elif isinstance(header, str):\n",
    "            header = header.lower()\n",
    "            header = re.sub(r'\\s+', ' ', header)\n",
    "            header = re.sub(r'\\(.*?\\)', '', header)\n",
    "            header = re.sub(r'[^a-zA-Z0-9\\s]', '', header)\n",
    "            header = header.strip()\n",
    "        cleaned_headers.append(header)\n",
    "    return cleaned_headers\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    \"\"\"Cleans string cells by removing newlines and trimming spaces.\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        return value.replace('\\n', ' ').strip()\n",
    "    elif value is None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return str(value).replace('\\n', ' ').strip()\n",
    "     \n",
    "\n",
    "def contains_phrase(row, phrase):\n",
    "    \"\"\"Checks if any cell in a row contains a specific phrase.\"\"\"\n",
    "    regex_pattern = re.sub(r\"\\s+\", r\"\\\\s*\", phrase)\n",
    "    pattern = re.compile(regex_pattern, flags=re.IGNORECASE)\n",
    "    return row.astype(str).apply(lambda cell: bool(pattern.search(cell))).any()\n",
    "\n",
    "def extract_specific_phrase(title):\n",
    "    \"\"\"\n",
    "    Extracts a specific phrase from the table title based on predefined keywords.\n",
    "\n",
    "    Args:\n",
    "        title (str): The table title string.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted specific phrase if found, else the original title.\n",
    "    \"\"\"\n",
    "    phrases = [\n",
    "        \"PTO\",\n",
    "        \"Reliability Network Upgrade\",\n",
    "        \"Reliability Network Upgrades\",\n",
    "        \"Area Delivery Network Upgrade\",\n",
    "        \"Local Delivery Network\",\n",
    "        \"Other Potential Network Upgrade\",\n",
    "        \"Area Delivery Network Upgrades\",\n",
    "        \"Conditionally Assigned Network Upgrades\",\n",
    "        \"Local Off-Peak Network Upgrade\",\n",
    "        \"ADNU\",\n",
    "        \"LDNU\",\n",
    "        \"RNU\"\n",
    "    ]\n",
    "\n",
    "    for phrase in phrases:\n",
    "        if  re.search(rf\"\\b{re.escape(phrase)}\\b(?=\\d|\\W|$)\", title, re.IGNORECASE):\n",
    "        \n",
    "         #re.search(rf\"\\b{re.escape(phrase)}\\b\", title, re.IGNORECASE):\n",
    "            return phrase\n",
    "    return title  # Fallback to the entire title if no specific phrase is found\n",
    "\n",
    "def reorder_columns(df):\n",
    "    \"\"\"\n",
    "    Reorders the columns of the DataFrame based on the specified order.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to reorder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The reordered DataFrame.\n",
    "    \"\"\"\n",
    "    desired_order = [\n",
    "        \"q_id\",\n",
    "        \"cluster\",\n",
    "        \"req_deliverability\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"capacity\",\n",
    "        \"point_of_interconnection\",\n",
    "        \"type of upgrade\",\n",
    "        \"upgrade\",\n",
    "        \"description\",\n",
    "        \"cost allocation factor\"\n",
    "    ]\n",
    "\n",
    "    # Start with desired columns that exist in the DataFrame\n",
    "    existing_desired = [col for col in desired_order if col in df.columns]\n",
    "\n",
    "    # Then add the remaining columns\n",
    "    remaining = [col for col in df.columns if col not in existing_desired]\n",
    "\n",
    "    # Combine the two lists\n",
    "    new_order = existing_desired + remaining\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    df = df[new_order]\n",
    "\n",
    "    return df\n",
    "\n",
    "def search_gps_coordinates(text, log_file):\n",
    "    \"\"\"Search for GPS coordinates using multiple patterns.\"\"\"\n",
    "    gps_coords = re.search(r\"gps coordinates:\\s*([\\d\\.\\-]+),\\s*([\\d\\.\\-]+)\", text, re.IGNORECASE)\n",
    "    if gps_coords:\n",
    "        print(f\"Found GPS coordinates: {gps_coords.groups()}\", file=log_file)\n",
    "        return gps_coords.groups()\n",
    "\n",
    "    project_coords = re.search(r\"latitude[:\\s]*([\\d\\.\\-]+)[^\\d]+longitude[:\\s]*([\\d\\.\\-]+)\", text, re.IGNORECASE)\n",
    "    if project_coords:\n",
    "        print(f\"Found project coordinates: {project_coords.groups()}\", file=log_file)\n",
    "        return project_coords.groups()\n",
    "\n",
    "    gps_coords_directional = re.search(\n",
    "        r\"gps coordinates:\\s*([\\d\\.\\-]+)\\s*[nNsS],\\s*([\\d\\.\\-]+)\\s*[eEwW]\", text, re.IGNORECASE)\n",
    "    if gps_coords_directional:\n",
    "        lat, lon = gps_coords_directional.groups()\n",
    "        latitude = lat if \"N\" in text.upper() else f\"-{lat}\"  # Adjust latitude sign\n",
    "        longitude = lon if \"E\" in text.upper() else f\"-{lon}\"  # Adjust longitude sign\n",
    "        print(f\"Found directional GPS coordinates: {(latitude, longitude)}\", file=log_file)\n",
    "        return (latitude, longitude)\n",
    "\n",
    "    print(\"GPS coordinates not found.\", file=log_file)\n",
    "    return (None, None)\n",
    "\n",
    "def extract_table1(pdf_path, log_file):\n",
    "    \"\"\"\n",
    "    Extracts the Point of Interconnection from Table 1 in the provided PDF.\n",
    "    Implements a retry mechanism with different table extraction settings if initial attempts fail.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        log_file (file object): Log file to write print statements.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted Point of Interconnection value,\n",
    "             \"Value Missing\" if label found but no value,\n",
    "             or None if not found.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing {pdf_path} for Table 1 extraction...\", file=log_file)\n",
    "    point_of_interconnection = None\n",
    "\n",
    "    # Define the regex pattern for 'Point of Interconnection' (case-insensitive)\n",
    "    poi_pattern = re.compile(r\"Point\\s+of\\s+Interconnection\", re.IGNORECASE)\n",
    "\n",
    "    # Define different table extraction settings to try\n",
    "    table_settings_list = [\n",
    "        {\n",
    "            \"horizontal_strategy\": \"text\",\n",
    "            \"vertical_strategy\": \"lines\",\n",
    "            \"snap_tolerance\": 1,\n",
    "        },\n",
    "        {\n",
    "            \"horizontal_strategy\": \"lines\",\n",
    "            \"vertical_strategy\": \"lines\",\n",
    "            \"snap_tolerance\": 2,  # Increased tolerance for retry\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # Identify all pages that contain \"Table 1\"\n",
    "            table1_pages = []\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                text = page.extract_text() or \"\"\n",
    "                if re.search(r\"Table\\s*1\\b\", text, re.IGNORECASE):\n",
    "                    table1_pages.append(i)\n",
    "\n",
    "            if not table1_pages:\n",
    "                print(\"No Table 1 found in the PDF.\", file=log_file)\n",
    "                return None  # Return None if no Table 1 found\n",
    "\n",
    "            first_page = table1_pages[0]\n",
    "            last_page = table1_pages[-1]\n",
    "            scrape_start = first_page\n",
    "            scrape_end = last_page + 2  # Plus one to include the next page if needed\n",
    "\n",
    "            print(f\"Table 1 starts on page {scrape_start + 1} and ends on page {scrape_end + 1}\", file=log_file)\n",
    "\n",
    "            # Flag to indicate if extraction was successful\n",
    "            extraction_successful = False\n",
    "\n",
    "            # Iterate through the specified page range\n",
    "            for page_number in range(scrape_start, min(scrape_end + 1, len(pdf.pages))):\n",
    "                page = pdf.pages[page_number]\n",
    "                print(f\"\\nScraping tables on page {page_number + 1} for Table 1...\", file=log_file)\n",
    "\n",
    "                for attempt, table_settings in enumerate(table_settings_list, start=1):\n",
    "                    print(f\"\\nAttempt {attempt} with table settings: {table_settings}\", file=log_file)\n",
    "                    tables = page.find_tables(table_settings=table_settings)\n",
    "                    print(f\"Found {len(tables)} table(s) on page {page_number + 1} with current settings.\", file=log_file)\n",
    "\n",
    "                    for table_index, table in enumerate(tables, start=1):\n",
    "                        tab = table.extract()\n",
    "                        if not tab:\n",
    "                            print(f\"Table {table_index} on page {page_number + 1} is empty. Skipping.\", file=log_file)\n",
    "                            continue  # Skip empty tables\n",
    "\n",
    "                        print(f\"\\n--- Table {table_index} on Page {page_number + 1} ---\", file=log_file)\n",
    "                        for row_num, row in enumerate(tab, start=1):\n",
    "                            print(f\"Row {row_num}: {row}\", file=log_file)\n",
    "\n",
    "                        # Iterate through each row in the table\n",
    "                        for row_index, row in enumerate(tab, start=1):\n",
    "                            # Iterate through each cell in the row\n",
    "                            for cell_index, cell in enumerate(row, start=1):\n",
    "                                if cell and poi_pattern.search(cell):\n",
    "                                    # Assuming the next column contains the value\n",
    "                                    poi_col_index = cell_index  # 1-based index\n",
    "                                    adjacent_col_index = poi_col_index + 1  # Next column\n",
    "\n",
    "                                    if adjacent_col_index <= len(row):\n",
    "                                        poi_value = clean_string_cell(row[adjacent_col_index - 1])\n",
    "                                        if poi_value:  # Check if the value is not empty\n",
    "                                            point_of_interconnection = poi_value\n",
    "                                            print(f\"\\nFound Point of Interconnection: '{point_of_interconnection}' \"\n",
    "                                                  f\"(Page {page_number + 1}, Table {table_index}, Row {row_index})\", file=log_file)\n",
    "                                            extraction_successful = True\n",
    "                                            break  # Exit the cell loop\n",
    "                                        else:\n",
    "                                            print(f\"\\nPoint of Interconnection label found but adjacent value is empty \"\n",
    "                                                  f\"(Page {page_number + 1}, Table {table_index}, Row {row_index}).\", file=log_file)\n",
    "                                            # Proceed to scan surrounding rows for the value\n",
    "                                            poi_value_parts = []\n",
    "\n",
    "                                            # Define the range to scan: two rows above and two rows below\n",
    "                                            # Convert to 0-based index\n",
    "                                            current_row_idx = row_index - 1\n",
    "                                            start_scan = max(0, current_row_idx - 2)\n",
    "                                            end_scan = min(len(tab), current_row_idx + 3)  # Exclusive\n",
    "\n",
    "                                            print(f\"Scanning rows {start_scan + 1} to {end_scan} for POI value parts.\", file=log_file)\n",
    "\n",
    "                                            for scan_row_index in range(start_scan, end_scan):\n",
    "                                                # Skip the current row where the label was found\n",
    "                                                if scan_row_index == current_row_idx:\n",
    "                                                    continue\n",
    "\n",
    "                                                scan_row = tab[scan_row_index]\n",
    "                                                # Ensure the adjacent column exists in the scan row\n",
    "                                                if adjacent_col_index - 1 < len(scan_row):\n",
    "                                                    scan_cell = clean_string_cell(scan_row[adjacent_col_index - 1])\n",
    "                                                    if scan_cell and not poi_pattern.search(scan_cell):\n",
    "                                                        poi_value_parts.append(scan_cell)\n",
    "                                                        print(f\"Found POI part in row {scan_row_index + 1}: '{scan_cell}'\", file=log_file)\n",
    "                                                    elif poi_pattern.search(scan_cell):\n",
    "                                                        # If another POI label is found, skip it\n",
    "                                                        print(f\"Encountered another POI label in row {scan_row_index + 1}. Skipping this row.\", file=log_file)\n",
    "                                                        continue\n",
    "\n",
    "                                            if poi_value_parts:\n",
    "                                                # Concatenate the parts to form the complete POI value\n",
    "                                                point_of_interconnection = \" \".join(poi_value_parts)\n",
    "                                                print(f\"\\nConcatenated Point of Interconnection: '{point_of_interconnection}' \"\n",
    "                                                      f\"(Page {page_number + 1}, Table {table_index})\", file=log_file)\n",
    "                                                extraction_successful = True\n",
    "                                                break  # Exit the cell loop\n",
    "                                            else:\n",
    "                                                print(f\"\\nNo POI value found in the surrounding rows \"\n",
    "                                                      f\"(Page {page_number + 1}, Table {table_index}, Row {row_index}).\", file=log_file)\n",
    "                                                # Do not return immediately; proceed to retry\n",
    "                                    else:\n",
    "                                        print(f\"\\nPoint of Interconnection label found but no adjacent column \"\n",
    "                                              f\"(Page {page_number + 1}, Table {table_index}, Row {row_index}).\", file=log_file)\n",
    "                                        # Do not return immediately; proceed to retry\n",
    "                            if extraction_successful:\n",
    "                                break  # Exit the row loop\n",
    "                        if extraction_successful:\n",
    "                            break  # Exit the table loop\n",
    "                    if extraction_successful:\n",
    "                        break  # Exit the attempt loop\n",
    "                if extraction_successful:\n",
    "                    break  # Exit the page loop\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Table 1 in {pdf_path}: {e}\", file=log_file)\n",
    "        print(traceback.format_exc(), file=log_file)\n",
    "        return None\n",
    "\n",
    "    if not extraction_successful:\n",
    "        # After all attempts, determine the appropriate return value\n",
    "        if point_of_interconnection is not None and point_of_interconnection != \"\":\n",
    "            # Label was found but no value\n",
    "            print(\"Point of Interconnection label found but no adjacent value.\", file=log_file)\n",
    "            return \"Value Missing\"\n",
    "        else:\n",
    "            # Label not found\n",
    "            print(\"Point of Interconnection not found in Table 1.\", file=log_file)\n",
    "            return None\n",
    "\n",
    "    return point_of_interconnection\n",
    "\n",
    "def extract_base_data(pdf_path, project_id, log_file):\n",
    "    \"\"\"Extract base data from the PDF and return as a DataFrame.\"\"\"\n",
    "    print(\"Extracting base data from PDF...\", file=log_file)\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as pdf_file:\n",
    "            reader = PyPDF2.PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "\n",
    "        text = clean_string_cell(text)\n",
    "\n",
    "        queue_id = re.search(r\"q[\\s_-]*(\\d+)\", text, re.IGNORECASE)\n",
    "        queue_id = queue_id.group(1) if queue_id else str(project_id)  # Use project_id if queue_id is not found\n",
    "        print(f\"Extracted Queue ID: {queue_id}\", file=log_file)\n",
    "\n",
    "        # Updated Cluster Extraction\n",
    "        clusters = re.findall(r\"queue[\\s_-]*cluster[\\s_-]*(\\d+)\", text, re.IGNORECASE)\n",
    "        if '13' in clusters:\n",
    "            cluster_number = '13'\n",
    "        elif clusters:\n",
    "            cluster_number = max(clusters, key=lambda x: int(x))  # Choose the highest cluster number found\n",
    "        else:\n",
    "            cluster_number = '13'  # Default to 13 if not found\n",
    "        print(f\"Extracted Cluster Number: {cluster_number}\", file=log_file)\n",
    "\n",
    "        deliverability_status = re.search(r\"(\\w+)\\s*capacity deliverability status\", text, re.IGNORECASE)\n",
    "        deliverability_status = deliverability_status.group(1) if deliverability_status else None\n",
    "        print(f\"Extracted Deliverability Status: {deliverability_status}\", file=log_file)\n",
    "\n",
    "        # Extract Capacity\n",
    "        capacity = re.search(r\"total rated output of (\\d+)\\s*mw\", text, re.IGNORECASE)\n",
    "        if capacity:\n",
    "            capacity = int(capacity.group(1))\n",
    "        else:\n",
    "            capacity2 = re.search(r\"(\\d+)\\s*mw\", text)\n",
    "            capacity = int(capacity2.group(1)) if capacity2 else None\n",
    "        print(f\"Extracted Capacity: {capacity}\", file=log_file)\n",
    "\n",
    "        # Extract Point of Interconnection\n",
    "        point_of_interconnection = extract_table1(pdf_path, log_file)\n",
    "\n",
    "        latitude, longitude = search_gps_coordinates(text, log_file)\n",
    "\n",
    "        # Initialize base data dictionary\n",
    "        base_data = {\n",
    "            \"q_id\": [queue_id],\n",
    "            \"cluster\": [cluster_number],\n",
    "            \"req_deliverability\": [deliverability_status],\n",
    "            \"latitude\": [latitude],\n",
    "            \"longitude\": [longitude],\n",
    "            \"capacity\": [capacity],\n",
    "            \"point_of_interconnection\": [point_of_interconnection]\n",
    "        }\n",
    "\n",
    "        print(\"Base data extracted:\", file=log_file)\n",
    "        print(base_data, file=log_file)\n",
    "        return pd.DataFrame(base_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting base data from {pdf_path}: {e}\", file=log_file)\n",
    "        print(traceback.format_exc(), file=log_file)\n",
    "        return pd.DataFrame()  # Return empty DataFrame on error\n",
    "\n",
    "def adjust_rows_length(data_rows, headers):\n",
    "    \"\"\"Ensure each row in data_rows matches the length of headers by truncating or padding.\"\"\"\n",
    "    col_count = len(headers)\n",
    "    for i in range(len(data_rows)):\n",
    "        row = data_rows[i]\n",
    "        if len(row) > col_count:\n",
    "            data_rows[i] = row[:col_count]\n",
    "        elif len(row) < col_count:\n",
    "            data_rows[i].extend([\"\"]*(col_count - len(row)))\n",
    "\n",
    "def extract_table7(pdf_path, log_file, is_addendum=False):\n",
    "    \"\"\"\n",
    "    Extracts Table 7 data from the provided PDF.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        log_file (file object): Log file to write print statements.\n",
    "        is_addendum (bool): Whether the PDF is an addendum.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Extracted Table 7 data.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing {pdf_path} for Table 7 extraction...\", file=log_file)\n",
    "    extracted_tables = []\n",
    "    specific_phrase = None\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # Identify pages that contain \"Table 7-1\" to \"Table 7-5\" with hyphen or dot\n",
    "            table7_pages = []\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                text = page.extract_text() or \"\"\n",
    "                if re.search(r\"Table\\s*8[-.]([2-6])\\b\", text, re.IGNORECASE):\n",
    "                    table7_pages.append(i)\n",
    "\n",
    "            if not table7_pages:\n",
    "                print(\"No Table 7-1 to 7-6 found in the PDF.\", file=log_file)\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            first_page = table7_pages[0]\n",
    "            last_page = table7_pages[-1]\n",
    "            scrape_start = first_page\n",
    "            scrape_end = last_page + 1  # Plus two to include possible continuation\n",
    "\n",
    "            print(f\"Table 7 starts on page {scrape_start + 1} and ends on page {scrape_end}\", file=log_file)\n",
    "\n",
    "            for page_number in range(scrape_start, min(scrape_end, len(pdf.pages))):\n",
    "                page = pdf.pages[page_number]\n",
    "                print(f\"\\nScraping tables on page {page_number + 1}...\", file=log_file)\n",
    "                tables = page.find_tables(table_settings={\n",
    "                    \"horizontal_strategy\": \"lines\",\n",
    "                    \"vertical_strategy\": \"lines\",\n",
    "                })\n",
    "\n",
    "                for table_index, table in enumerate(tables):\n",
    "                    tab = table.extract()\n",
    "                    if not tab:\n",
    "                        print(f\"Table {table_index + 1} on page {page_number + 1} is empty. Skipping.\", file=log_file)\n",
    "                        continue\n",
    "\n",
    "                    table_bbox = table.bbox\n",
    "                    title_bbox = (0, 0, page.width, table_bbox[1])\n",
    "                    title_text = page.within_bbox(title_bbox).extract_text() or \"\"\n",
    "                    table_title = None\n",
    "\n",
    "                    if title_text:\n",
    "                        title_lines = title_text.split('\\n')[::-1]\n",
    "                        for line in title_lines:\n",
    "                            line = line.strip()\n",
    "                            match = re.search(r\"(Modification\\s+of\\s+)?Table\\s*8[-.]([2-6])[:\\-\\s]*(.*)\", line, re.IGNORECASE)\n",
    "                            if match:\n",
    "                                table_title = match.group(3).strip()\n",
    "                                break\n",
    "\n",
    "                    if table_title:\n",
    "                        if re.search(r\"\\b8-7\\b\", table_title, re.IGNORECASE):\n",
    "                            print(f\"Skipping Table 7-7 on page {page_number + 1}, table {table_index + 1}.\", file=log_file)\n",
    "                            continue  # Skip Table 7-7\n",
    "\n",
    "                        # New Table 7 detected\n",
    "                        specific_phrase = extract_specific_phrase(table_title)\n",
    "                        print(f\"New Table 7 detected: '{specific_phrase}' on page {page_number + 1}, table {table_index + 1}\", file=log_file)\n",
    "\n",
    "                        headers = clean_column_headers(tab[0])\n",
    "                        data_rows = tab[1:]\n",
    "\n",
    "                        # Create DataFrame for new table\n",
    "                        try:\n",
    "                            df_new = pd.DataFrame(data_rows, columns=headers)\n",
    "                        except ValueError as ve:\n",
    "                            print(f\"Error creating DataFrame for new table on page {page_number + 1}, table {table_index + 1}: {ve}\", file=log_file)\n",
    "                            continue\n",
    "\n",
    "                        # Handle ADNU-specific grouping\n",
    "                        if re.search(r\"Area\\s*Delivery\\s*Network\\s*Upgrade\", specific_phrase, re.IGNORECASE):\n",
    "                            print(\"Detected 'Area Delivery Network Upgrade' table (new).\", file=log_file)\n",
    "                            if \"adnu\" in df_new.columns:\n",
    "                                if \"type of upgrade\" not in df_new.columns:\n",
    "                                    # Group all adnu rows into one 'upgrade' row\n",
    "                                    adnu_values = df_new[\"adnu\"].dropna().astype(str).tolist()\n",
    "                                    grouped_adnu = \" \".join(adnu_values)\n",
    "                                    other_columns = df_new.drop(columns=[\"adnu\"]).iloc[0].to_dict()\n",
    "\n",
    "                                    df_grouped = pd.DataFrame({\n",
    "                                        \"upgrade\": [grouped_adnu],\n",
    "                                        \"type of upgrade\": [specific_phrase]\n",
    "                                    })\n",
    "\n",
    "                                    for col, value in other_columns.items():\n",
    "                                        df_grouped[col] = value\n",
    "\n",
    "                                    print(\"Grouped all 'adnu' rows into a single 'upgrade' row for new ADNU table.\", file=log_file)\n",
    "                                    df_new = df_grouped\n",
    "                                else:\n",
    "                                    # If 'type of upgrade' exists, just rename adnu if needed\n",
    "                                    if \"upgrade\" in df_new.columns:\n",
    "                                        df_new.drop(columns=['adnu'], inplace=True)\n",
    "                                        print(\"Dropped 'adnu' column to avoid duplicate 'upgrade'.\", file=log_file)\n",
    "                                    else:\n",
    "                                        df_new.rename(columns={'adnu': 'upgrade'}, inplace=True)\n",
    "                                        print(\"Renamed 'adnu' to 'upgrade' in new ADNU table.\", file=log_file)\n",
    "                            if \"type of upgrade\" not in df_new.columns:\n",
    "                                df_new[\"type of upgrade\"] = specific_phrase\n",
    "                                print(\"Added 'type of upgrade' to all rows in new ADNU table.\", file=log_file)\n",
    "                            else:\n",
    "                                # If 'type of upgrade' exists and first row is none, replace only first row if needed\n",
    "                                first_row = df_new.iloc[0]\n",
    "                                if pd.isna(first_row[\"type of upgrade\"]) or first_row[\"type of upgrade\"] == \"\":\n",
    "                                    df_new.at[0, \"type of upgrade\"] = specific_phrase\n",
    "                                    print(\"Replaced None in 'type of upgrade' first row for new ADNU table.\", file=log_file)\n",
    "                        else:\n",
    "                            # Non-ADNU new tables\n",
    "                            if \"type of upgrade\" not in df_new.columns:\n",
    "                                df_new[\"type of upgrade\"] = specific_phrase\n",
    "                                print(\"Added 'type of upgrade' to all rows in new non-ADNU table.\", file=log_file)\n",
    "                            else:\n",
    "                                # If 'type of upgrade' exists and first row is none, replace only first row if needed\n",
    "                                first_row = df_new.iloc[0]\n",
    "                                if pd.isna(first_row[\"type of upgrade\"]) or first_row[\"type of upgrade\"] == \"\":\n",
    "                                    print(\"Replacing None in 'type of upgrade' for the first row in new non-ADNU table.\", file=log_file)\n",
    "                                    df_new.at[0, \"type of upgrade\"] = specific_phrase\n",
    "\n",
    "                        # Ensure no duplicate columns\n",
    "                        if df_new.columns.duplicated().any():\n",
    "                            print(\"Duplicate columns detected in new table. Dropping duplicates.\", file=log_file)\n",
    "                            df_new = df_new.loc[:, ~df_new.columns.duplicated()]\n",
    "\n",
    "                        extracted_tables.append(df_new)\n",
    "                    else:\n",
    "                        # Continuation Table\n",
    "                        if not extracted_tables:\n",
    "                            print(f\"No previous Table 7 detected to continue with on page {page_number + 1}, table {table_index + 1}. Skipping.\", file=log_file)\n",
    "                            continue\n",
    "\n",
    "                        last_table = extracted_tables[-1]\n",
    "                        expected_columns = last_table.columns.tolist()\n",
    "\n",
    "                        print(f\"Continuation Table detected on page {page_number + 1}, table {table_index + 1}\", file=log_file)\n",
    "                        data_rows = tab\n",
    "\n",
    "                        # Check if the first row is a header row\n",
    "                        # As per your latest instruction, we will treat all continuation table rows as data points\n",
    "                        # without any header detection\n",
    "                        # However, you mentioned checking if there is a header row first, so we'll implement that\n",
    "\n",
    "                        # Detect if first row is a header\n",
    "                        header_keywords = [\"type of upgrade\", \"adnu\", \"MW at POI\"]\n",
    "                        first_row = data_rows[0] if data_rows else []\n",
    "                        is_header_row = any(\n",
    "                            any(re.search(rf\"\\b{kw}\\b\", clean_string_cell(cell).lower()) for kw in header_keywords)\n",
    "                            for cell in first_row\n",
    "                        )\n",
    "\n",
    "                        if is_header_row:\n",
    "                            # Handle header row in continuation table\n",
    "                            headers = clean_column_headers(first_row)\n",
    "                            data_rows = data_rows[1:]  # Exclude header row\n",
    "\n",
    "                            # Update expected_columns by adding new columns if any\n",
    "                            new_columns = [col for col in headers if col not in expected_columns]\n",
    "                            if new_columns:\n",
    "                                expected_columns.extend(new_columns)\n",
    "                                print(f\"Added new columns from continuation table: {new_columns}\", file=log_file)\n",
    "\n",
    "                            # Create a mapping of new columns to add with default NaN\n",
    "                            for new_col in new_columns:\n",
    "                                last_table[new_col] = pd.NA\n",
    "\n",
    "                            # Reindex last_table to include new columns\n",
    "                            last_table = last_table.reindex(columns=expected_columns)\n",
    "                            extracted_tables[-1] = last_table\n",
    "\n",
    "                            # Update 'type of upgrade' column in the first row if needed\n",
    "                            if \"type of upgrade\" in headers:\n",
    "                                type_upgrade_idx = headers.index(\"type of upgrade\")\n",
    "                                if pd.isna(data_rows[0][type_upgrade_idx]) or data_rows[0][type_upgrade_idx] == \"\":\n",
    "                                    data_rows[0][type_upgrade_idx] = specific_phrase\n",
    "                                    print(f\"Replaced None in 'type of upgrade' first row for continuation table on page {page_number + 1}, table {table_index + 1}.\", file=log_file)\n",
    "                            elif \"upgrade\" in headers:\n",
    "                                upgrade_idx = headers.index(\"upgrade\")\n",
    "                                if pd.isna(data_rows[0][upgrade_idx]) or data_rows[0][upgrade_idx] == \"\":\n",
    "                                    data_rows[0][upgrade_idx] = specific_phrase\n",
    "                                    print(f\"Replaced None in 'upgrade' first row for continuation table on page {page_number + 1}, table {table_index + 1}.\", file=log_file)\n",
    "                            else:\n",
    "                                # If 'type of upgrade' or 'upgrade' does not exist, add it\n",
    "                                headers.append(\"type of upgrade\")\n",
    "                                expected_columns.append(\"type of upgrade\")\n",
    "                                for idx, row in enumerate(data_rows):\n",
    "                                    data_rows[idx].append(specific_phrase)\n",
    "                                print(f\"Added 'type of upgrade' column and filled with '{specific_phrase}' for continuation table on page {page_number + 1}, table {table_index + 1}.\", file=log_file)\n",
    "\n",
    "                            # Handle ADNU-specific logic if applicable\n",
    "                            if re.search(r\"Area\\s*Delivery\\s*Network\\s*Upgrade\", specific_phrase, re.IGNORECASE):\n",
    "                                if \"adnu\" in headers:\n",
    "                                    if \"upgrade\" not in headers:\n",
    "                                        # Rename 'adnu' to 'upgrade'\n",
    "                                        adnu_idx = headers.index(\"adnu\")\n",
    "                                        headers[adnu_idx] = \"upgrade\"\n",
    "                                        for row in data_rows:\n",
    "                                            row[adnu_idx] = \" \".join([str(cell) for cell in row[adnu_idx] if pd.notna(cell)])\n",
    "                                        print(\"Renamed 'adnu' to 'upgrade' in continuation ADNU table.\", file=log_file)\n",
    "                                # Ensure 'type of upgrade' column is filled\n",
    "                                if \"type of upgrade\" not in headers:\n",
    "                                    headers.append(\"type of upgrade\")\n",
    "                                    expected_columns.append(\"type of upgrade\")\n",
    "                                    for row in data_rows:\n",
    "                                        row.append(specific_phrase)\n",
    "                                    print(\"Added 'type of upgrade' column with specific phrase for continuation ADNU table.\", file=log_file)\n",
    "\n",
    "                        else:\n",
    "                            # No header row detected, treat all rows as data points\n",
    "                            print(f\"No header row detected in continuation table on page {page_number + 1}, table {table_index + 1}. Treating all rows as data.\", file=log_file)\n",
    "\n",
    "                        # Create DataFrame for continuation table\n",
    "                        if is_header_row:\n",
    "                            try:\n",
    "                                df_continuation = pd.DataFrame(data_rows, columns=headers)\n",
    "                            except ValueError as ve:\n",
    "                                print(f\"Error creating DataFrame for continuation table on page {page_number + 1}, table {table_index + 1}: {ve}\", file=log_file)\n",
    "                                continue\n",
    "                        else:\n",
    "                            # Create DataFrame with expected_columns\n",
    "                            # Handle cases where continuation table has more columns\n",
    "                            standardized_data = []\n",
    "                            for row in data_rows:\n",
    "                                if len(row) < len(expected_columns):\n",
    "                                    # Insert 'type of upgrade' or 'upgrade' with specific_phrase\n",
    "                                    if re.search(r\"Area\\s*Delivery\\s*Network\\s*Upgrade\", specific_phrase, re.IGNORECASE):\n",
    "                                        # For ADNU tables, assume missing \"upgrade\" column\n",
    "                                        missing_cols = len(expected_columns) - len(row)\n",
    "                                        #row += [specific_phrase] * missing_cols\n",
    "                                        data_rows = [row[:7] + [specific_phrase] + row[7:] for row in data_rows]\n",
    "                                        print(f\"Inserted '{specific_phrase}' for missing columns in ADNU continuation table on page {page_number + 1}, table {table_index + 1}.\", file=log_file)\n",
    "                                    else:\n",
    "                                        # For non-ADNU tables, assume missing \"type of upgrade\" column\n",
    "                                        missing_cols = len(expected_columns) - len(row)\n",
    "                                        #row += [specific_phrase] * missing_cols\n",
    "                                        #data_rows = [ [specific_phrase]  for row in data_rows]\n",
    "                                        data_rows = [row[:7] + [specific_phrase] + row[7:] for row in data_rows]\n",
    "                                        print(f\"Inserted '{specific_phrase}' for missing columns in non-ADNU continuation table on page {page_number + 1}, table {table_index + 1}.\", file=log_file)\n",
    "                                elif len(row) > len(expected_columns):\n",
    "                                    # Add new columns with default names\n",
    "                                    extra_cols = len(row) - len(expected_columns)\n",
    "                                    for i in range(extra_cols):\n",
    "                                        new_col_name = f\"column{len(expected_columns) + 1 + i}\"\n",
    "                                        expected_columns.append(new_col_name)\n",
    "                                        last_table[new_col_name] = pd.NA\n",
    "                                        print(f\"Added new column '{new_col_name}' for extra data in continuation table on page {page_number + 1}, table {table_index + 1}.\", file=log_file)\n",
    "                                    row = row[:len(expected_columns)]\n",
    "\n",
    "                                row_dict = dict(zip(expected_columns, [clean_string_cell(cell) for cell in row]))\n",
    "\n",
    "                                # Handle 'type of upgrade' column\n",
    "                                if \"type of upgrade\" in row_dict and (pd.isna(row_dict[\"type of upgrade\"]) or row_dict[\"type of upgrade\"] == \"\"):\n",
    "                                    row_dict[\"type of upgrade\"] = specific_phrase\n",
    "                                    print(f\"Replaced None in 'type of upgrade' for a row in continuation table on page {page_number + 1}, table {table_index + 1}.\", file=log_file)\n",
    "\n",
    "                                standardized_data.append(row_dict)\n",
    "\n",
    "                            try:\n",
    "                                df_continuation = pd.DataFrame(standardized_data, columns=expected_columns)\n",
    "                            except ValueError as ve:\n",
    "                                print(f\"Error creating DataFrame for continuation table on page {page_number + 1}, table {table_index + 1}: {ve}\", file=log_file)\n",
    "                                continue\n",
    "\n",
    "\n",
    "\n",
    "                            # Special Handling for \"Area Delivery Network Upgrade\" Tables in Continuation\n",
    "                            if re.search(r\"Area\\s*Delivery\\s*Network\\s*Upgrade\", specific_phrase, re.IGNORECASE):\n",
    "                                if \"type of upgrade\" in df_continuation.columns:\n",
    "                                    first_row = df_continuation.iloc[0]\n",
    "                                    if pd.isna(first_row[\"type of upgrade\"]) or first_row[\"type of upgrade\"] == \"\":\n",
    "                                        print(f\"Replacing 'None' in 'type of upgrade' for the first data row of continuation on page {page_number + 1}, table {table_index + 1}\",file=log_file)\n",
    "                                        df_continuation.at[0, \"type of upgrade\"] = specific_phrase\n",
    "                                else:\n",
    "                                    # If \"type of upgrade\" column does not exist, add it\n",
    "                                    df_continuation[\"type of upgrade\"] = specific_phrase\n",
    "                                    print(f\"'type of upgrade' column added with value '{specific_phrase}' for continuation on page {page_number + 1}, table {table_index + 1}\",file=log_file)\n",
    "                            else:\n",
    "                                # General Handling for other tables\n",
    "                                if \"type of upgrade\" in df_continuation.columns:\n",
    "                                    first_row = df_continuation.iloc[0]\n",
    "                                    if pd.isna(first_row[\"type of upgrade\"]) or first_row[\"type of upgrade\"] == \"\":\n",
    "                                        print(f\"Replacing 'None' in 'Type of Upgrade' for the first data row of continuation on page {page_number + 1}, table {table_index + 1}\",file=log_file)\n",
    "                                        df_continuation.at[0, \"type of upgrade\"] = specific_phrase\n",
    "                                else:\n",
    "                                    # If \"Type of Upgrade\" column does not exist, add it\n",
    "                                    df_continuation[\"type of upgrade\"] = specific_phrase\n",
    "                                    print(f\"'Type of Upgrade' column added with value '{specific_phrase}' for continuation on page {page_number + 1}, table {table_index + 1}\",file=log_file)\n",
    "\n",
    "\n",
    "                        # Handle ADNU-specific logic in continuation tables\n",
    "                        #if re.search(r\"Area\\s*Delivery\\s*Network\\s*Upgrade\", specific_phrase, re.IGNORECASE):\n",
    "                        #    print(\"Handling ADNU-specific logic in continuation table.\", file=log_file)\n",
    "                        #    if \"upgrade\" in df_continuation.columns and \"adnu\" not in df_continuation.columns:\n",
    "                        #        # Ensure 'upgrade' column is present\n",
    "                        #        if \"upgrade\" not in df_continuation.columns:\n",
    "                        #            df_continuation[\"upgrade\"] = specific_phrase\n",
    "                        #            print(\"Added 'upgrade' column to continuation ADNU table.\", file=log_file)\n",
    "\n",
    "                        # Ensure no duplicate columns\n",
    "                        if df_continuation.columns.duplicated().any():\n",
    "                            print(f\"Duplicate columns detected in continuation table on page {page_number + 1}, table {table_index + 1}. Dropping duplicates.\", file=log_file)\n",
    "                            df_continuation = df_continuation.loc[:, ~df_continuation.columns.duplicated()]\n",
    "\n",
    "                        # Merge with the last extracted table\n",
    "                        extracted_tables[-1] = pd.concat([extracted_tables[-1], df_continuation], ignore_index=True, sort=False)\n",
    "                        print(f\"Appended continuation table data to the last extracted table on page {page_number + 1}, table {table_index + 1}.\", file=log_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Table 7 in {pdf_path}: {e}\", file=log_file)\n",
    "        print(traceback.format_exc(), file=log_file)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # After processing all tables, concatenate them\n",
    "    if extracted_tables:\n",
    "        all_columns = set()\n",
    "        for df in extracted_tables:\n",
    "            all_columns.update(df.columns.tolist())\n",
    "\n",
    "        standardized_tables = []\n",
    "        for df in extracted_tables:\n",
    "            standardized_df = df.reindex(columns=all_columns)\n",
    "            standardized_tables.append(standardized_df)\n",
    "\n",
    "        print(\"\\nConcatenating all extracted Table 7 data...\", file=log_file)\n",
    "        try:\n",
    "            table7_data = pd.concat(standardized_tables, ignore_index=True, sort=False)\n",
    "            print(f\"Successfully concatenated {len(standardized_tables)} tables.\", file=log_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error concatenating tables: {e}\", file=log_file)\n",
    "            print(traceback.format_exc(), file=log_file)\n",
    "            table7_data = pd.DataFrame()\n",
    "    else:\n",
    "        print(\"No Table 7 data extracted.\", file=log_file)\n",
    "        table7_data = pd.DataFrame()\n",
    "\n",
    "    return table7_data\n",
    "\n",
    "\n",
    "\n",
    "def extract_table7_and_replace_none(pdf_path, project_id, log_file, is_addendum=False):\n",
    "    \"\"\"Extracts Table 7 data and merges with base data.\"\"\"\n",
    "    base_data = extract_base_data(pdf_path, project_id, log_file)\n",
    "    table7_data = extract_table7(pdf_path, log_file, is_addendum)\n",
    "\n",
    "    if table7_data.empty:\n",
    "        return base_data\n",
    "    else:\n",
    "        # Identify overlapping columns excluding 'point_of_interconnection'\n",
    "        overlapping_columns = base_data.columns.intersection(table7_data.columns).difference(['point_of_interconnection'])\n",
    "        table7_data = table7_data.drop(columns=overlapping_columns, errors='ignore')\n",
    "        \n",
    "        # Repeat base data for each row in table7_data\n",
    "        base_data_repeated = pd.concat([base_data] * len(table7_data), ignore_index=True)\n",
    "        \n",
    "        try:\n",
    "            # Concatenate base data with Table 7 data along columns\n",
    "            merged_df = pd.concat([base_data_repeated, table7_data], axis=1, sort=False)\n",
    "            \n",
    "            # Ensure 'point_of_interconnection' is present and correctly populated\n",
    "            if 'point_of_interconnection' not in merged_df.columns:\n",
    "                merged_df['point_of_interconnection'] = base_data['point_of_interconnection'].iloc[0]\n",
    "                print(f\"Added 'point_of_interconnection' to merged data for {pdf_path}.\", file=log_file)\n",
    "            \n",
    "            print(f\"Merged base data with Table 7 data for {pdf_path}.\", file=log_file)\n",
    "            return merged_df\n",
    "        except Exception as e:\n",
    "            print(f\"Error merging base data with Table 7 data for {pdf_path}: {e}\", file=log_file)\n",
    "            print(traceback.format_exc(), file=log_file)\n",
    "            return base_data  # Fallback to base data only\n",
    "\n",
    "def check_has_table7(pdf_path):\n",
    "    \"\"\"Checks if the PDF contains Table 7-1 to 7-5.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text() or \"\"\n",
    "                if re.search(r\"Table\\s*8[-.]([1-5])\\b\", text, re.IGNORECASE):\n",
    "                    return True\n",
    "    except Exception as e:\n",
    "        # Handle potential errors when opening PDF\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def has_network_upgrade_type_column(pdf_path, log_file):\n",
    "    \"\"\"Checks if any table in the PDF has a column header 'Network Upgrade Type'.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page_number, page in enumerate(pdf.pages, start=1):\n",
    "                tables = page.find_tables()\n",
    "                for table_index, table in enumerate(tables, start=1):\n",
    "                    tab = table.extract()\n",
    "                    if not tab:\n",
    "                        continue\n",
    "                    headers = clean_column_headers(tab[0])\n",
    "                    if \"network upgrade type\" in headers:\n",
    "                        print(f\"Found 'Network Upgrade Type' in PDF {pdf_path} on page {page_number}, table {table_index}.\", file=log_file)\n",
    "                        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking 'Network Upgrade Type' in {pdf_path}: {e}\", file=log_file)\n",
    "        print(traceback.format_exc(), file=log_file)\n",
    "    return False\n",
    "\n",
    "def is_addendum(pdf_path, log_file):\n",
    "    \"\"\"Checks if the PDF is an addendum by searching 'Addendum' or 'Revision' on the first page.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            if len(pdf.pages) == 0:\n",
    "                return False\n",
    "            first_page = pdf.pages[0]\n",
    "            text = first_page.extract_text() or \"\"\n",
    "            print(f\"Extracted Text: {text}\", file= log_file)  # Debugging step\n",
    "            # Case-insensitive check for 'Addendum' or 'Revision'\n",
    "            text_lower = text.lower()\n",
    "            return \"addendum\" in text_lower or \"revision\" in text_lower\n",
    "    except Exception as e:\n",
    "        # Handle potential errors when opening PDF\n",
    "        return False\n",
    "\n",
    "def make_unique_headers(headers):\n",
    "    \"\"\"\n",
    "    Appends a suffix to duplicate headers to make them unique.\n",
    "\n",
    "    Args:\n",
    "        headers (list): List of column headers.\n",
    "\n",
    "    Returns:\n",
    "        list: List of unique column headers.\n",
    "    \"\"\"\n",
    "    seen = {}\n",
    "    unique_headers = []\n",
    "    for header in headers:\n",
    "        if header in seen:\n",
    "            seen[header] += 1\n",
    "            unique_headers.append(f\"{header}_{seen[header]}\")\n",
    "        else:\n",
    "            seen[header] = 1\n",
    "            unique_headers.append(header)\n",
    "    return unique_headers\n",
    "\n",
    "def process_pdfs_in_folder():\n",
    "    \"\"\"Processes all PDFs in the specified project range and directory.\"\"\"\n",
    "    global core_originals, core_addendums, total_pdfs_accessed, total_pdfs_scraped, total_pdfs_skipped\n",
    "\n",
    "    # Ensure the log file directory exists\n",
    "    os.makedirs(os.path.dirname(LOG_FILE_PATH), exist_ok=True)\n",
    "\n",
    "    with open(LOG_FILE_PATH, 'w') as log_file:\n",
    "        for project_id in PROJECT_RANGE:\n",
    "            project_path = os.path.join(BASE_DIRECTORY, str(project_id), \"03_phase_2_study\")\n",
    "            if not os.path.exists(project_path):\n",
    "                missing_projects.add(project_id)\n",
    "                print(f\"Project path does not exist: {project_path}\", file=log_file)\n",
    "                continue\n",
    "\n",
    "            project_scraped = False  # Flag to track if any PDF in the project was scraped\n",
    "            base_data_extracted = False\n",
    "            base_data = pd.DataFrame()\n",
    "\n",
    "            # **START OF CHANGES**\n",
    "            # Separate PDFs into originals and addendums\n",
    "            list_pdfs = [pdf for pdf in os.listdir(project_path) if pdf.endswith(\".pdf\")]\n",
    "            originals = []\n",
    "            addendums = []\n",
    "            for pdf_name in list_pdfs:\n",
    "                pdf_path = os.path.join(project_path, pdf_name)\n",
    "                if is_addendum(pdf_path, log_file):\n",
    "                    addendums.append(pdf_name)\n",
    "                else:\n",
    "                    originals.append(pdf_name)\n",
    "            # **END OF CHANGES**\n",
    "\n",
    "            # ─── NEW BLOCK ───\n",
    "            # If there are no originals at all, treat every addendum as an original\n",
    "            #if not originals and addendums:\n",
    "            #    print(f\"No originals found for project {project_id}; will process addendums as originals\", file=log_file)\n",
    "            #    originals = addendums.copy()\n",
    "            #    addendums =  []\n",
    "            # ──────────────────\n",
    "\n",
    "\n",
    "            # **START OF CHANGES**\n",
    "            # Process original PDFs first\n",
    "            for pdf_name in originals:\n",
    "                \n",
    "                pdf_path = os.path.join(project_path, pdf_name)\n",
    "                total_pdfs_accessed += 1\n",
    "\n",
    "                is_add = is_addendum(pdf_path, log_file)\n",
    "\n",
    "                # Check if PDF has 'Network Upgrade Type' column\n",
    "                if has_network_upgrade_type_column(pdf_path, log_file):\n",
    "                    style_n_pdfs.append(pdf_name)\n",
    "                    print(f\"Skipping PDF: {pdf_name} from Project {project_id} (Style N)\", file=log_file)\n",
    "                    # Still check if original has table7\n",
    "                    has_table7 = check_has_table7(pdf_path)\n",
    "                    original_has_table7[project_id] = has_table7\n",
    "                    continue  # Skip processing this PDF\n",
    "\n",
    "                print(f\"Accessing Original PDF: {pdf_name} from Project {project_id}\", file=log_file)\n",
    "                original_pdfs.append(pdf_name)\n",
    "\n",
    "                try:\n",
    "                    has_table7 = check_has_table7(pdf_path)\n",
    "                    original_has_table7[project_id] = has_table7\n",
    "\n",
    "                    if not has_table7:\n",
    "                        skipped_pdfs.append(pdf_name)\n",
    "                        print(f\"Skipped PDF: {pdf_name} from Project {project_id} (No Table 7)\", file=log_file)\n",
    "                        print(f\"Skipped PDF: {pdf_name} from Project {project_id} (No Table 7)\")\n",
    "                        total_pdfs_skipped += 1\n",
    "                        continue\n",
    "\n",
    "                    if not base_data_extracted:\n",
    "                        # Extract base data from original PDF\n",
    "                        base_data = extract_base_data(pdf_path, project_id, log_file)\n",
    "                        base_data_extracted = True\n",
    "                        print(f\"Extracted base data from original PDF: {pdf_name}\", file=log_file)\n",
    "\n",
    "                    # Extract Table 7 and merge\n",
    "                    df = extract_table7_and_replace_none(pdf_path, project_id, log_file, is_addendum=False)\n",
    "                    if not df.empty:\n",
    "                        core_originals = pd.concat([core_originals, df], ignore_index=True)\n",
    "                        scraped_pdfs.append(pdf_name)\n",
    "                        scraped_projects.add(project_id)\n",
    "                        project_scraped = True\n",
    "                        total_pdfs_scraped += 1\n",
    "                        print(f\"Scraped PDF: {pdf_name} from Project {project_id}\")\n",
    "                    else:\n",
    "                        skipped_pdfs.append(pdf_name)\n",
    "                        print(f\"Skipped PDF: {pdf_name} from Project {project_id} (Empty Data)\", file=log_file)\n",
    "                        print(f\"Skipped PDF: {pdf_name} from Project {project_id} (Empty Data)\")\n",
    "                        total_pdfs_skipped += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    skipped_pdfs.append(pdf_name)\n",
    "                    print(f\"Skipped PDF: {pdf_name} from Project {project_id} due to an error: {e}\", file=log_file)\n",
    "                    print(traceback.format_exc(), file=log_file)\n",
    "                    print(f\"Skipped PDF: {pdf_name} from Project {project_id} due to an error: {e}\")\n",
    "                    total_pdfs_skipped += 1\n",
    "            # **END OF CHANGES**\n",
    "\n",
    "            # **START OF CHANGES**\n",
    "            # Then process addendum PDFs\n",
    "            for pdf_name in addendums:\n",
    "                pdf_path = os.path.join(project_path, pdf_name)\n",
    "                total_pdfs_accessed += 1\n",
    "                is_add = is_addendum(pdf_path, log_file)\n",
    "\n",
    "                # If we never extracted base_data from an original, do it now from this addendum  <<< NEW\n",
    "                if not base_data_extracted:                                            \n",
    "                    print(f\"No original base data for project {project_id}; extracting from addendum {pdf_name}\", file=log_file)   \n",
    "                    base_data = extract_base_data(pdf_path, project_id, log_file)      \n",
    "                    base_data_extracted = True  \n",
    "\n",
    "                # Check if PDF has 'Network Upgrade Type' column\n",
    "                if has_network_upgrade_type_column(pdf_path, log_file):\n",
    "                    style_n_pdfs.append(pdf_name)\n",
    "                    print(f\"Skipping PDF: {pdf_name} from Project {project_id} (Style N)\", file=log_file)\n",
    "                    continue  # Skip processing this PDF\n",
    "\n",
    "                print(f\"Accessing Addendum PDF: {pdf_name} from Project {project_id}\", file=log_file)\n",
    "                addendum_pdfs.append(pdf_name)\n",
    "\n",
    "                try:\n",
    "                    has_table7 = check_has_table7(pdf_path)\n",
    "\n",
    "                    if not has_table7:\n",
    "                        if original_has_table7.get(project_id, False):\n",
    "                            # Attempt to scrape alternative tables is no longer needed\n",
    "                            # According to the latest request, alternative table scraping is removed\n",
    "                            # Therefore, we skip addendum PDFs that do not have Table 7\n",
    "                            skipped_pdfs.append(pdf_name)\n",
    "                            print(f\"Skipped Addendum PDF: {pdf_name} from Project {project_id} (No Table 7)\", file=log_file)\n",
    "                            print(f\"Skipped Addendum PDF: {pdf_name} from Project {project_id} (No Table 7)\")\n",
    "                            total_pdfs_skipped += 1\n",
    "                        else:\n",
    "                            skipped_pdfs.append(pdf_name)\n",
    "                            print(f\"Skipped Addendum PDF: {pdf_name} from Project {project_id} (No Table 7 and original does not have Table 7)\", file=log_file)\n",
    "                            print(f\"Skipped Addendum PDF: {pdf_name} from Project {project_id} (No Table 7 and original does not have Table 7)\")\n",
    "                            total_pdfs_skipped += 1\n",
    "                        continue\n",
    "\n",
    "                    if not is_add and not base_data_extracted:\n",
    "                        # Extract base data from original PDF\n",
    "                        base_data = extract_base_data(pdf_path, project_id, log_file)\n",
    "                        base_data_extracted = True\n",
    "                        print(f\"Extracted base data from original PDF: {pdf_name}\", file=log_file)\n",
    "\n",
    "                    if is_add and base_data_extracted:\n",
    "                        # For addendums, use the extracted base data\n",
    "                        table7_data = extract_table7(pdf_path, log_file, is_addendum=is_add)\n",
    "                        if table7_data.empty and original_has_table7.get(project_id, False):\n",
    "                            # Scrape alternative tables is removed, so skip if no data\n",
    "                            skipped_pdfs.append(pdf_name)\n",
    "                            print(f\"Skipped Addendum PDF: {pdf_name} from Project {project_id} (No relevant tables found)\", file=log_file)\n",
    "                            print(f\"Skipped Addendum PDF: {pdf_name} from Project {project_id} (No relevant tables found)\")\n",
    "                            total_pdfs_skipped += 1\n",
    "                        if not table7_data.empty:\n",
    "                            # Merge base data with Table 7 data\n",
    "                            merged_df = pd.concat([base_data] * len(table7_data), ignore_index=True)\n",
    "                            merged_df = pd.concat([merged_df, table7_data], axis=1, sort=False)\n",
    "                            core_addendums = pd.concat([core_addendums, merged_df], ignore_index=True)\n",
    "                            scraped_pdfs.append(pdf_name)\n",
    "                            scraped_projects.add(project_id)\n",
    "                            project_scraped = True\n",
    "                            total_pdfs_scraped += 1\n",
    "                            print(f\"Scraped Addendum PDF: {pdf_name} from Project {project_id}\")\n",
    "                        else:\n",
    "                            skipped_pdfs.append(pdf_name)\n",
    "                            print(f\"Skipped Addendum PDF: {pdf_name} from Project {project_id} (Empty Data)\", file=log_file)\n",
    "                            print(f\"Skipped Addendum PDF: {pdf_name} from Project {project_id} (Empty Data)\")\n",
    "                            total_pdfs_skipped += 1\n",
    "                except Exception as e:\n",
    "                    skipped_pdfs.append(pdf_name)\n",
    "                    print(f\"Skipped PDF: {pdf_name} from Project {project_id} due to an error: {e}\", file=log_file)\n",
    "                    print(traceback.format_exc(), file=log_file)\n",
    "                    # Optionally, print to ipynb\n",
    "                    print(f\"Skipped PDF: {pdf_name} from Project {project_id} due to an error: {e}\")\n",
    "                    total_pdfs_skipped += 1\n",
    "            # **END OF CHANGES**\n",
    "\n",
    "            # After processing all PDFs for this project, check if any PDF was scraped\n",
    "            if not project_scraped and os.path.exists(project_path):\n",
    "                skipped_projects.add(project_id)\n",
    "\n",
    "    # Rest of the code remains unchanged...\n",
    "\n",
    "    # After processing all PDFs, save to CSV\n",
    "    save_to_csv(core_originals, OUTPUT_CSV_PATH_ORIGINAL, \"originals\")\n",
    "    save_to_csv(core_addendums, OUTPUT_CSV_PATH_ADDENDUM, \"addendums\")\n",
    "\n",
    "    # Calculate total projects processed\n",
    "    total_projects_processed = len(scraped_projects) + len(skipped_projects)\n",
    "\n",
    "    # Print summary to ipynb\n",
    "    print(\"\\n=== Scraping Summary ===\")\n",
    "    print(f\"Total Projects Processed: {total_projects_processed}\")\n",
    "    print(f\"Total Projects Scraped: {len(scraped_projects)}\")\n",
    "    print(f\"Total Projects Skipped: {len(skipped_projects)}\")\n",
    "    print(f\"Total Projects Missing: {len(missing_projects)}\")\n",
    "    print(f\"Total PDFs Accessed: {total_pdfs_accessed}\")\n",
    "    print(f\"Total PDFs Scraped: {total_pdfs_scraped}\")\n",
    "    print(f\"Total PDFs Skipped: {total_pdfs_skipped}\")\n",
    "\n",
    "    print(\"\\nList of Scraped Projects:\")\n",
    "    print(sorted(scraped_projects))\n",
    "\n",
    "    print(\"\\nList of Skipped Projects:\")\n",
    "    print(sorted(skipped_projects))\n",
    "\n",
    "    print(\"\\nList of Missing Projects:\")\n",
    "    print(sorted(missing_projects))\n",
    "\n",
    "    print(\"\\nList of Scraped PDFs:\")\n",
    "    print(scraped_pdfs)\n",
    "\n",
    "    print(\"\\nList of Skipped PDFs:\")\n",
    "    print(skipped_pdfs)\n",
    "\n",
    "    print(\"\\nList of Addendum PDFs:\")\n",
    "    print(addendum_pdfs)\n",
    "\n",
    "    print(\"\\nList of Original PDFs:\")\n",
    "    print(original_pdfs)\n",
    "\n",
    "    print(\"\\nList of Style N PDFs (Skipped due to 'Network Upgrade Type'):\")\n",
    "    print(style_n_pdfs)\n",
    "\n",
    "    print(\"\\nTotal Number of Style N PDFs:\", len(style_n_pdfs))\n",
    "\n",
    "    print(\"\\nNumber of Original PDFs Scraped:\", len([pdf for pdf in scraped_pdfs if pdf in original_pdfs]))\n",
    "    print(\"Number of Addendum PDFs Scraped:\", len([pdf for pdf in scraped_pdfs if pdf in addendum_pdfs]))\n",
    "\n",
    "def save_to_csv(df, output_csv_path, data_type):\n",
    "    \"\"\"Cleans the DataFrame and saves it to a CSV file.\"\"\"\n",
    "    if df.empty:\n",
    "        print(f\"No data to save for {data_type}.\")\n",
    "        return\n",
    "\n",
    "    # Clean up the entire DataFrame by cleaning string cells\n",
    "    df = df.applymap(clean_string_cell)\n",
    "\n",
    "    # Drop rows that contain specific phrases (e.g., \"Type of Upgrade\")\n",
    "    df = df[~df.apply(lambda row: contains_phrase(row, \"Type of Upgrade\"), axis=1)]\n",
    "\n",
    "    # Reorder columns as specified\n",
    "    df = reorder_columns(df)\n",
    "    print(f\"\\nColumns reordered for {data_type} as per specification.\")\n",
    "\n",
    "    # Ensure q_id is numeric for sorting, replace missing values with None\n",
    "    if 'q_id' in df.columns:\n",
    "        df['q_id'] = pd.to_numeric(df['q_id'], errors='coerce')\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    try:\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"\\nData successfully saved to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {data_type} data to CSV: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the PDF scraping process.\"\"\"\n",
    "    process_pdfs_in_folder()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itemized and Updated datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itemized rows saved to 'costs_phase_2_cluster_12_style_Q_itemized.csv'.\n",
      "Filtered Total rows saved to 'costs_phase_2_cluster_12_style_Q_total.csv'.\n",
      "['PTO_IF' 'RNU' 'LDNU' 'LOPNU' 'CANU']\n",
      "[1683 1687 1688 1690 1691 1695 1700 1702 1705 1709 1713 1728 1739 1744\n",
      " 1745 1750 1751]\n",
      "[13]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/03_raw/ph2_rawdata_cluster13_style_Q_originals.csv', dtype={'estimated_time_to_construct': str})\n",
    "\n",
    "df['q_id'] = df['q_id'].astype('Int64')\n",
    "df['cluster'] = df['cluster'].astype('Int64')\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "########################################\n",
    "#STEP 1 MERGE COLUMNS\n",
    "\n",
    "def merge_columns(df):\n",
    "    merge_columns_dict = {\n",
    "        \"escalated_cost_x_1000\": [\n",
    "            \"escalated costs x 1000\",\n",
    "            \"estimated cost x 1000 escalated\",\n",
    "            \"estimated cost x 1000 escalated without itcca\",\n",
    "            \"escalated cost x 1000\",\n",
    "            \"sum of allocated escalated cost\"\n",
    "        ],\n",
    "        \"estimated_cost_x_1000\": [\n",
    "            \"estimated cost x 1000\",\n",
    "            \"allocated_cost\",\n",
    "            \"sum of allocated constant cost\"\n",
    "        ],\n",
    "        \"estimated_time_to_construct\": [\n",
    "            \"estimated time to construct\",\n",
    "            \"estimated time  to construct\"\n",
    "        ],\n",
    "        \"total_estimated_cost_x_1000_escalated\": [\n",
    "            \"total estimated cost x 1000 escalalted\",\n",
    "            \"total estimated cost x 1000 escalated\"\n",
    "        ],\n",
    "        \"total_estimated_cost_x_1000\": [\n",
    "            \"total nu cost\",\n",
    "            \"total cost constant\"\n",
    "        ],\n",
    "        \"adnu_cost_rate_x_1000\": [\n",
    "            \"adnu cost rate x 1000\",\n",
    "            \"cost rate x 1000\",\n",
    "            \"cost rate\",\n",
    "            \"cost rate constant\"\n",
    "        ],\n",
    "        \"description\": [\"description\"],\n",
    "        \"capacity\": [\n",
    "            \"capacity\",\n",
    "            \"project size\",\n",
    "            \"project mw\",\n",
    "            \"mw at poi\"\n",
    "        ],\n",
    "        \"cost_allocation_factor\": [\n",
    "            \"cost allocation factor\",\n",
    "            \"cost allocatio n factor\",\n",
    "            \"cost allocati on factor\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Identify unnamed columns\n",
    "    unnamed_columns = [col for col in df.columns if pd.isna(col) or col.strip() == \"\" or col.startswith(\"Unnamed\")]\n",
    "    if unnamed_columns:\n",
    "        merge_columns_dict[\"description\"].extend(unnamed_columns)\n",
    "\n",
    "    for new_col, old_cols in merge_columns_dict.items():\n",
    "        existing_cols = [col for col in old_cols if col in df.columns]\n",
    "        if existing_cols:\n",
    "            df[new_col] = df[existing_cols].bfill(axis=1).iloc[:, 0]\n",
    "            cols_to_drop = [col for col in existing_cols if col != new_col]\n",
    "            if cols_to_drop:\n",
    "                df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = merge_columns(df)\n",
    "#df.drop('incremental deliverability', axis=1, inplace=True)\n",
    "#df.drop('dependent system upgrade', axis=1, inplace=True)\n",
    "#df.drop('upgrade_classification', axis=1, inplace=True)\n",
    "\n",
    "#STEP 2: NAMING CONVENTION\n",
    "def convert_to_snake_case(column_name):\n",
    "    column_name = column_name.strip().lower()\n",
    "    column_name = re.sub(r'[\\s\\-]+', '_', column_name)\n",
    "    column_name = re.sub(r'[^\\w]', '', column_name)\n",
    "    return column_name\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    if isinstance(value, str):\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "        value = value.replace('\\n', ' ').strip()\n",
    "    return value\n",
    "\n",
    "df = df.map(clean_string_cell)\n",
    "df.columns = [convert_to_snake_case(col) for col in df.columns]\n",
    "\n",
    "required_columns = ['type_of_upgrade', 'cost_allocation_factor']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "\n",
    "df = df[\n",
    "    ~df['type_of_upgrade'].str.contains(r'Precursor Network Upgrades \\(PNU\\)|Estimated in Service Date', na=False)\n",
    "]\n",
    " \n",
    " \n",
    "# Step 3: Rename 'Grand Total' to 'Total' in total_estimated_cost_x_1000\n",
    "if 'total_estimated_cost_x_1000' in df.columns:\n",
    "    df['total_estimated_cost_x_1000'] = df['total_estimated_cost_x_1000'].replace('Grand Total', 'Total')\n",
    "\n",
    "# Step 4: Move 'Total' from total_estimated_cost_x_1000 to cost_allocation_factor\n",
    "if 'total_estimated_cost_x_1000' in df.columns and 'cost_allocation_factor' in df.columns:\n",
    "    df['cost_allocation_factor'] = df.apply(\n",
    "        lambda row: 'Total' if str(row['total_estimated_cost_x_1000']) == 'Total' else row['cost_allocation_factor'],\n",
    "        axis=1\n",
    "    )\n",
    "    df['total_estimated_cost_x_1000'] = df['total_estimated_cost_x_1000'].replace('Total', None)\n",
    "\n",
    "df = df[df[\"description\"] != \"Total Allocated\"]    \n",
    "\n",
    "if 'description' in df.columns and 'cost_allocation_factor' in df.columns:\n",
    "    df['cost_allocation_factor'] = df.apply(\n",
    "        lambda row: 'Total' if str(row['description']) == 'Total' else row['cost_allocation_factor'],\n",
    "        axis=1\n",
    "    )\n",
    "    df['description'] = df['description'].replace('Total', None)\n",
    "\n",
    "\n",
    "df['item'] = df.apply(\n",
    "    lambda row: 'no' if (\n",
    "        (pd.notna(row.get('type_of_upgrade')) and 'Total' in str(row['type_of_upgrade'])) or\n",
    "        (pd.notna(row.get('cost_allocation_factor')) and 'Total' in str(row['cost_allocation_factor']))\n",
    "    ) else 'yes',\n",
    "    axis=1\n",
    ")\n",
    "   \n",
    "df.drop('upgrade_classification', axis=1, inplace=True)\n",
    "\n",
    "# Step 5: Clean the type of upgrade column\n",
    "   \n",
    " \n",
    "df['type_of_upgrade'] = (\n",
    "    df['type_of_upgrade']\n",
    "    .fillna('')  # Temporarily replace NaN with an empty string\n",
    "    .str.replace(r'\\(Note \\d+\\)', '', regex=True)  # Remove (Note digit)\n",
    "    .str.strip()  # Strip leading/trailing whitespace\n",
    "    .str.title()  # Capitalize the first letter of each word\n",
    "    .str.replace(r'Upgrades$', 'Upgrade', regex=True)  # Fix plural endings\n",
    "    .replace('', pd.NA)  # Convert empty strings back to NaN\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mappings = {\n",
    "    'Reliability Network Upgrade': 'RNU',\n",
    "    'Reliability Network Upgrades': 'RNU',\n",
    "    'Local Delivery Network Upgrade': 'LDNU',\n",
    "    'Local Delivery Network': 'LDNU',\n",
    "    'Potential Local Delivery Network Upgrade': 'LDNU',\n",
    "    \"Ptos Interconnection Facilities\": 'PTO_IF',\n",
    "    'Area Delivery Network Upgrade': 'ADNU',\n",
    "    'Reliability Network Upgrade To Physically Interconnect': 'RNU',\n",
    "    \"Reliability Network upgrade To Physically Interconnect\": \"RNU\",\n",
    "     'Pto': 'PTO_IF',\n",
    "    \"Other Potential Network Upgrade\": \"OPNU\",\n",
    "    \"Conditionally Assigned Network Upgrade\": \"CANU\",\n",
    "    \"Canus\": \"CANU\",\n",
    "        \"Escalated Cost And Time To Construct For Reliability Network Upgrade4\": \"RNU\",\n",
    "    \"Escalated Cost And Time To Construct For Reliability Network Upgrade3\": \"RNU\",\n",
    "    \"Local Off-Peak Network Upgrade\": \"LOPNU\",\n",
    "    'Total PTO_IF': 'PTO_IF',\n",
    " 'Total RNU': 'RNU',\n",
    " 'Total LDNU': 'LDNU',\n",
    " 'Total OPNU' : 'OPNU',\n",
    " 'Total CANU': 'CANU',\n",
    " 'Total LOPNU': 'LOPNU',\n",
    "  \n",
    " 'Total ADNU': 'ADNU',\n",
    "  'Ptos Interconnect Ion Facilities' : 'PTO_IF',\n",
    "  'Local Off- Peak Network Upgrade': 'LOPNU',\n",
    " 'P Os Interconnection Facilities': 'PTO_IF',\n",
    "  \n",
    "\n",
    " \n",
    "}\n",
    "\n",
    "\n",
    "#Step 6: Apply mapping and ffill type of upgrade column\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: re.sub(r'\\bupgrades\\b', 'upgrade', x, flags=re.IGNORECASE).strip() if isinstance(x, str) else x\n",
    "    )\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: mappings.get(x, x) if isinstance(x, str) else x\n",
    "    )\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].ffill()  \n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def drop_rows_with_star_in_costs(df, cost_cols):\n",
    "    \"\"\"\n",
    "    Remove any row where any of the cost_cols contains a '*' character.\n",
    "    \"\"\"\n",
    "    mask = pd.Series(False, index=df.index)\n",
    "    for col in cost_cols:\n",
    "        if col in df.columns:\n",
    "            # star anywhere in the string\n",
    "            mask = mask | df[col].astype(str).str.contains(r\"\\*\", regex=True)\n",
    "    # keep only rows without a star\n",
    "    return df.loc[~mask].reset_index(drop=True)\n",
    "\n",
    "def drop_rows_with_dash_in_time(df, time_col):\n",
    "    \"\"\"\n",
    "    Remove any row where the time_col contains a dash '-' (e.g. '-').\n",
    "    \"\"\"\n",
    "    if time_col in df.columns:\n",
    "        mask = df[time_col].astype(str).str.contains(r\"^-+$\", regex=True)\n",
    "        return df.loc[~mask].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def keep_second_entry_in_cells(df, columns):\n",
    "    \"\"\"\n",
    "    For each column in columns, if the cell contains multiple space‑separated entries,\n",
    "    keep only the second one.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        def pick_second(cell):\n",
    "            parts = re.findall(r\"[\\d\\.\\$%,]+\", str(cell))\n",
    "            return parts[1] if len(parts) > 1 else (parts[0] if parts else cell)\n",
    "        df[col] = df[col].apply(pick_second)\n",
    "    return df\n",
    "\n",
    "# ── Integration ──\n",
    "# Place this just before your Step 7 clean_currency block:\n",
    "\n",
    "# 1) drop any row where estimated or escalated cost has '*'\n",
    "df = drop_rows_with_star_in_costs(\n",
    "    df,\n",
    "    cost_cols=[\n",
    "        'estimated_cost_x_1000',\n",
    "        'escalated_cost_x_1000',\n",
    "        'total_estimated_cost_x_1000',\n",
    "        'total_estimated_cost_x_1000_escalated'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 2) drop any row where estimated_time_to_construct is just a dash\n",
    "df = drop_rows_with_dash_in_time(df, 'estimated_time_to_construct')\n",
    "\n",
    "# 3) if multiple entries exist in a cell, keep only the second\n",
    "df = keep_second_entry_in_cells(\n",
    "    df,\n",
    "    columns=[\n",
    "        'cost_allocation_factor',\n",
    "        'estimated_cost_x_1000',\n",
    "        'escalated_cost_x_1000',\n",
    "        'total_estimated_cost_x_1000',\n",
    "        'total_estimated_cost_x_1000_escalated'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Now proceed with your clean_currency step…\n",
    "\n",
    "\n",
    "    \n",
    "# Step 7: Remove $ signs and convert to numeric\n",
    "import re\n",
    "\n",
    "def clean_currency(value):\n",
    "    \"\"\"\n",
    "    Cleans a string by explicitly removing $, *, (Note 2), and similar patterns,\n",
    "    then converts it to a numeric value.\n",
    "    \"\"\"\n",
    "    if isinstance(value, str):\n",
    "        # Explicitly remove $, *, and any \"(Note ...)\"\n",
    "        value = value.replace('$', '').replace('*', '')\n",
    "        value = re.sub(r'\\(Note \\d+\\)', '', value)  # Remove patterns like \"(Note 2)\"\n",
    "        value = value.replace(',', '').strip()  # Remove commas and extra spaces\n",
    "    try:\n",
    "        return pd.to_numeric(value)\n",
    "    except ValueError:\n",
    "        return pd.NA  # Return NaN for invalid entries\n",
    "\n",
    "\n",
    "# Clean the specific columns\n",
    "for col in ['estimated_cost_x_1000', 'escalated_cost_x_1000', 'total_estimated_cost_x_1000_escalated', 'total_estimated_cost_x_1000', 'adnu_cost_rate_x_1000', 'adnu_cost_rate_x_1000_escalated']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "# Create Total rows\n",
    "new_rows = []\n",
    "columns_to_sum = ['estimated_cost_x_1000', 'escalated_cost_x_1000', 'total_estimated_cost_x_1000_escalated',   'adnu_cost_rate_x_1000_escalated']\n",
    "columns_to_populate = ['cluster', 'req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection']\n",
    "\n",
    "for q_id, group in df.groupby('q_id', as_index=False):\n",
    "    unique_upgrades = group['type_of_upgrade'].dropna().unique()\n",
    "    for upgrade in unique_upgrades:\n",
    "        if pd.isna(upgrade):\n",
    "            continue\n",
    "        \n",
    "        rows = group[group['type_of_upgrade'] == upgrade]\n",
    "\n",
    "                # Check if a Total row already exists for this (q_id, upgrade)\n",
    "        total_exists = group[\n",
    "            (group['type_of_upgrade'] == upgrade) & (group['item'] == 'no')\n",
    "        ].shape[0] > 0\n",
    "        \n",
    "        if total_exists:\n",
    "             \n",
    "            continue\n",
    "\n",
    "\n",
    " \n",
    "        \n",
    "        \n",
    "        if not total_exists:\n",
    "            # If only one row exists, duplicate it as the total row\n",
    "            if len(rows) == 1:\n",
    "\n",
    "                total_row = {col: '' for col in df.columns}  # Initialize all columns as empty strings\n",
    "\n",
    "                # Populate the necessary fields\n",
    "                total_row['q_id'] = q_id\n",
    "                total_row['type_of_upgrade'] = f\"Total {upgrade}\"\n",
    "                total_row['item'] = 'no'\n",
    "\n",
    "                # Populate specified columns from the existing row\n",
    "                first_row = rows.iloc[0]\n",
    "                for col in columns_to_populate:\n",
    "                    if col in df.columns:\n",
    "                        total_row[col] = first_row[col]\n",
    "\n",
    "                # Sum the numeric columns (single row, so it remains the same)\n",
    "                for col in columns_to_sum:\n",
    "                    if col in rows.columns:\n",
    "                        total_row[col] = rows[col].sum()\n",
    "                    else:\n",
    "                        total_row[col] = 0  # Default to 0 if column is missing\n",
    "\n",
    "                new_rows.append(total_row)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "            \n",
    "            # If multiple rows exist, sum numeric columns and create a total row\n",
    "            elif len(rows) > 1:\n",
    "                total_row = {col: '' for col in df.columns}  # Initialize all columns as empty strings\n",
    "\n",
    "                # Populate the necessary fields\n",
    "                total_row['q_id'] = q_id\n",
    "                total_row['type_of_upgrade'] = f\"Total {upgrade}\"\n",
    "                total_row['item'] = 'no'\n",
    "\n",
    "                # Populate the specified columns from the first row in the group\n",
    "                first_row = rows.iloc[0]\n",
    "                for col in columns_to_populate:\n",
    "                    if col in df.columns:\n",
    "                        total_row[col] = first_row[col]\n",
    "\n",
    "                # Sum the numeric columns\n",
    "                for col in columns_to_sum:\n",
    "                    if col in rows.columns:\n",
    "                        total_row[col] = rows[col].sum()\n",
    "                    else:\n",
    "                        total_row[col] = 0  # Default to 0 if column is missing\n",
    "\n",
    "                new_rows.append(total_row)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "if new_rows:\n",
    "    total_rows_df = pd.DataFrame(new_rows)\n",
    "    for col in df.columns:\n",
    "        if col not in total_rows_df.columns:\n",
    "            total_rows_df[col] = None\n",
    "    total_rows_df = total_rows_df[df.columns]\n",
    "    df = pd.concat([df, total_rows_df], ignore_index=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Update 'item' column based on Total in type_of_upgrade or cost_allocation_factor\n",
    "df['item'] = df.apply(\n",
    "    lambda row: 'no' if (\n",
    "        'Total' in str(row.get('type_of_upgrade', '')) or \n",
    "        'Total' in str(row.get('cost_allocation_factor', ''))\n",
    "    ) else 'yes',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Step 8: Move 'item' column next to 'type_of_upgrade'\n",
    "if 'item' in df.columns and 'type_of_upgrade' in df.columns:\n",
    "    cols = df.columns.tolist()\n",
    "    item_index = cols.index('item')\n",
    "    type_index = cols.index('type_of_upgrade')\n",
    "    if item_index < type_index:\n",
    "        cols.insert(type_index + 1, cols.pop(item_index))\n",
    "    else:\n",
    "        cols.insert(type_index + 1, cols.pop(item_index))\n",
    "    df = df[cols]\n",
    "\n",
    "# Step 9: Remove \"Total\" values from cost_allocation_factor if they appear in type_of_upgrade\n",
    "if 'cost_allocation_factor' in df.columns and 'type_of_upgrade' in df.columns:\n",
    "    df['cost_allocation_factor'] = df.apply(\n",
    "        lambda row: None if (\n",
    "            pd.notna(row['type_of_upgrade']) and 'Total' in str(row['type_of_upgrade'])\n",
    "        ) else row.get('cost_allocation_factor'),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "\n",
    "if 'cost_allocation_factor' in df.columns and 'type_of_upgrade' in df.columns:\n",
    "    df['cost_allocation_factor'] = df.apply(\n",
    "        lambda row: None if 'Total' in str(row.get('cost_allocation_factor', '')) else row.get('cost_allocation_factor'),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def clean_estimated_time(value):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub(r'(\\d+(?:-\\w+)*)\\s+\\w+.*$', r'\\1', value, flags=re.IGNORECASE).strip()\n",
    "    return value\n",
    "\n",
    "if 'estimated_time_to_construct' in df.columns:\n",
    "    df['estimated_time_to_construct'] = df['estimated_time_to_construct'].apply(clean_estimated_time)\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: re.sub(r'\\s*\\(note \\d+\\)', '', x, flags=re.IGNORECASE).strip() if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: re.sub(r'\\bupgrades\\b', 'upgrade', x, flags=re.IGNORECASE).strip() if isinstance(x, str) else x\n",
    "    )\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: mappings.get(x, x) if isinstance(x, str) else x\n",
    "    )\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].ffill()\n",
    "\n",
    "if 'upgrade' in df.columns and 'type_of_upgrade' in df.columns and 'q_id' in df.columns:\n",
    "    df['upgrade'] = df.groupby(['q_id', 'type_of_upgrade'])['upgrade'].ffill()\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    previous_type_of_upgrade = None\n",
    "    for i in range(len(df)):\n",
    "        if df.at[i, 'type_of_upgrade'] == 'Total':\n",
    "            if previous_type_of_upgrade is not None:\n",
    "                df.at[i, 'type_of_upgrade'] = previous_type_of_upgrade\n",
    "        else:\n",
    "            previous_type_of_upgrade = df.at[i, 'type_of_upgrade']\n",
    "\n",
    "numeric_columns = [\n",
    "    'cost_allocation_factor',\n",
    "    'estimated_cost_x_1000',\n",
    "    'estimated_time_to_construct',\n",
    "    'total_estimated_cost_x_1000_escalated',\n",
    "    'adnu_cost_rate_x_1000',\n",
    "    'escalated_cost_x_1000',\n",
    "    'estimated_cost_x_1000_escalated_without_itcca',\n",
    "    'adnu_cost_rate_x_1000_escalated'\n",
    "]\n",
    "non_numeric_columns = ['type_of_upgrade', 'upgrade', 'description']\n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: 'None' if pd.isna(x) else x)\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace('-', pd.NA)\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "if 'original_order' in df.columns and 'q_id' in df.columns:\n",
    "    df['original_order'] = df.index\n",
    "    df = df.sort_values(by=['q_id', 'original_order'], ascending=[True, True])\n",
    "    df = df.drop(columns=['original_order'])\n",
    "\n",
    "\n",
    "def reorder_columns(df):\n",
    "    \"\"\"\n",
    "    Reorders the columns of the DataFrame based on the specified order.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to reorder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The reordered DataFrame.\n",
    "    \"\"\"\n",
    "    desired_order = [\n",
    "        \"q_id\",\n",
    "        \"cluster\",\n",
    "        \"req_deliverability\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"capacity\",\n",
    "        \"point_of_interconnection\",\n",
    "        \"type_of_upgrade\",\n",
    "        \"upgrade\",\n",
    "        \"description\",\n",
    "        \"cost_allocation_factor\",\n",
    "        \"estimated_cost_x_1000\",\n",
    "        \"escalated_cost_x_1000\",\n",
    "        \"total_estimated_cost_x_1000\",\n",
    "        \"total_estimated_cost_x_1000_escalated\",\n",
    "        \"estimated_time_to_construct\",\n",
    "    ]\n",
    "\n",
    "    # Start with desired columns that exist in the DataFrame\n",
    "    existing_desired = [col for col in desired_order if col in df.columns]\n",
    "\n",
    "    # Then add the remaining columns\n",
    "    remaining = [col for col in df.columns if col not in existing_desired]\n",
    "\n",
    "    # Combine the two lists\n",
    "    new_order = existing_desired + remaining\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    df = df[new_order]\n",
    "\n",
    "    return df        \n",
    "\n",
    "\n",
    "df= reorder_columns(df)\n",
    "\n",
    "\n",
    "# Save itemized and totals separately\n",
    "if 'item' in df.columns:\n",
    "    itemized_df = df[df['item'] == 'yes']\n",
    "    itemized_df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_itemized.csv', index=False)\n",
    "\n",
    "    totals_columns = ['upgrade', 'description', 'cost_allocation_factor', 'estimated_time_to_construct']\n",
    "    totals_df = df[df['item'] == 'no'].drop(columns=totals_columns, errors='ignore')\n",
    "    totals_df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_total.csv', index=False)\n",
    "\n",
    "print(f\"Itemized rows saved to 'costs_phase_2_cluster_12_style_Q_itemized.csv'.\")\n",
    "print(f\"Filtered Total rows saved to 'costs_phase_2_cluster_12_style_Q_total.csv'.\")\n",
    "\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    print(df['type_of_upgrade'].unique())\n",
    "\n",
    "if 'q_id' in df.columns:\n",
    "    print(df['q_id'].unique())\n",
    "\n",
    "if 'cluster' in df.columns:\n",
    "    print(df['cluster'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addendums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itemized rows saved to 'costs_phase_2_cluster_12_style_Q_itemized.csv'.\n",
      "Filtered Total rows saved to 'costs_phase_2_cluster_12_style_Q_total.csv'.\n",
      "['PTO_IF' 'RNU' 'LDNU' 'LOPNU' 'CANU']\n",
      "[1688 1691 1713 1718 1728 1736 1739 1740]\n",
      "[13]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/03_raw/ph2_rawdata_cluster13_style_Q_addendums.csv', dtype={'estimated_time_to_construct': str})\n",
    "\n",
    "df['q_id'] = df['q_id'].astype('Int64')\n",
    "df['cluster'] = df['cluster'].astype('Int64')\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "########################################\n",
    "#STEP 1 MERGE COLUMNS\n",
    "\n",
    "def merge_columns(df):\n",
    "    merge_columns_dict = {\n",
    "        \"escalated_cost_x_1000\": [\n",
    "            \"escalated costs x 1000\",\n",
    "            \"estimated cost x 1000 escalated\",\n",
    "            \"estimated cost x 1000 escalated without itcca\",\n",
    "            \"escalated cost x 1000\",\n",
    "            \"sum of allocated escalated cost\"\n",
    "        ],\n",
    "        \"estimated_cost_x_1000\": [\n",
    "            \"estimated cost x 1000\",\n",
    "            \"allocated_cost\",\n",
    "            \"sum of allocated constant cost\"\n",
    "        ],\n",
    "        \"estimated_time_to_construct\": [\n",
    "            \"estimated time to construct\",\n",
    "            \"estimated time  to construct\"\n",
    "        ],\n",
    "        \"total_estimated_cost_x_1000_escalated\": [\n",
    "            \"total estimated cost x 1000 escalalted\",\n",
    "            \"total estimated cost x 1000 escalated\"\n",
    "        ],\n",
    "        \"total_estimated_cost_x_1000\": [\n",
    "            \"total nu cost\",\n",
    "            \"total cost constant\"\n",
    "        ],\n",
    "        \"adnu_cost_rate_x_1000\": [\n",
    "            \"adnu cost rate x 1000\",\n",
    "            \"cost rate x 1000\",\n",
    "            \"cost rate\",\n",
    "            \"cost rate constant\"\n",
    "        ],\n",
    "        \"description\": [\"description\"],\n",
    "        \"capacity\": [\n",
    "            \"capacity\",\n",
    "            \"project size\",\n",
    "            \"project mw\",\n",
    "            \"mw at poi\"\n",
    "        ],\n",
    "        \"cost_allocation_factor\": [\n",
    "            \"cost allocation factor\",\n",
    "            \"cost allocatio n factor\",\n",
    "            \"cost allocati on factor\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Identify unnamed columns\n",
    "    unnamed_columns = [col for col in df.columns if pd.isna(col) or col.strip() == \"\" or col.startswith(\"Unnamed\")]\n",
    "    if unnamed_columns:\n",
    "        merge_columns_dict[\"description\"].extend(unnamed_columns)\n",
    "\n",
    "    for new_col, old_cols in merge_columns_dict.items():\n",
    "        existing_cols = [col for col in old_cols if col in df.columns]\n",
    "        if existing_cols:\n",
    "            df[new_col] = df[existing_cols].bfill(axis=1).iloc[:, 0]\n",
    "            cols_to_drop = [col for col in existing_cols if col != new_col]\n",
    "            if cols_to_drop:\n",
    "                df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = merge_columns(df)\n",
    "#df.drop('incremental deliverability', axis=1, inplace=True)\n",
    "#df.drop('dependent system upgrade', axis=1, inplace=True)\n",
    "#df.drop('upgrade_classification', axis=1, inplace=True)\n",
    "\n",
    "#STEP 2: NAMING CONVENTION\n",
    "def convert_to_snake_case(column_name):\n",
    "    column_name = column_name.strip().lower()\n",
    "    column_name = re.sub(r'[\\s\\-]+', '_', column_name)\n",
    "    column_name = re.sub(r'[^\\w]', '', column_name)\n",
    "    return column_name\n",
    "\n",
    "def clean_string_cell(value):\n",
    "    if isinstance(value, str):\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "        value = value.replace('\\n', ' ').strip()\n",
    "    return value\n",
    "\n",
    "df = df.map(clean_string_cell)\n",
    "df.columns = [convert_to_snake_case(col) for col in df.columns]\n",
    "\n",
    "required_columns = ['type_of_upgrade', 'cost_allocation_factor']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "\n",
    "df = df[\n",
    "    ~df['type_of_upgrade'].str.contains(r'Precursor Network Upgrades \\(PNU\\)|Estimated in Service Date', na=False)\n",
    "]\n",
    " \n",
    " \n",
    "# Step 3: Rename 'Grand Total' to 'Total' in total_estimated_cost_x_1000\n",
    "if 'total_estimated_cost_x_1000' in df.columns:\n",
    "    df['total_estimated_cost_x_1000'] = df['total_estimated_cost_x_1000'].replace('Grand Total', 'Total')\n",
    "\n",
    "# Step 4: Move 'Total' from total_estimated_cost_x_1000 to cost_allocation_factor\n",
    "if 'total_estimated_cost_x_1000' in df.columns and 'cost_allocation_factor' in df.columns:\n",
    "    df['cost_allocation_factor'] = df.apply(\n",
    "        lambda row: 'Total' if str(row['total_estimated_cost_x_1000']) == 'Total' else row['cost_allocation_factor'],\n",
    "        axis=1\n",
    "    )\n",
    "    df['total_estimated_cost_x_1000'] = df['total_estimated_cost_x_1000'].replace('Total', None)\n",
    "\n",
    "df = df[df[\"description\"] != \"Total Allocated\"]    \n",
    "\n",
    "if 'description' in df.columns and 'cost_allocation_factor' in df.columns:\n",
    "    df['cost_allocation_factor'] = df.apply(\n",
    "        lambda row: 'Total' if str(row['description']) == 'Total' else row['cost_allocation_factor'],\n",
    "        axis=1\n",
    "    )\n",
    "    df['description'] = df['description'].replace('Total', None)\n",
    "\n",
    "\n",
    "df['item'] = df.apply(\n",
    "    lambda row: 'no' if (\n",
    "        (pd.notna(row.get('type_of_upgrade')) and 'Total' in str(row['type_of_upgrade'])) or\n",
    "        (pd.notna(row.get('cost_allocation_factor')) and 'Total' in str(row['cost_allocation_factor']))\n",
    "    ) else 'yes',\n",
    "    axis=1\n",
    ")\n",
    "   \n",
    "df.drop('upgrade_classification', axis=1, inplace=True)\n",
    "\n",
    "# Step 5: Clean the type of upgrade column\n",
    "   \n",
    " \n",
    "df['type_of_upgrade'] = (\n",
    "    df['type_of_upgrade']\n",
    "    .fillna('')  # Temporarily replace NaN with an empty string\n",
    "    .str.replace(r'\\(Note \\d+\\)', '', regex=True)  # Remove (Note digit)\n",
    "    .str.strip()  # Strip leading/trailing whitespace\n",
    "    .str.title()  # Capitalize the first letter of each word\n",
    "    .str.replace(r'Upgrades$', 'Upgrade', regex=True)  # Fix plural endings\n",
    "    .replace('', pd.NA)  # Convert empty strings back to NaN\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mappings = {\n",
    "    'Reliability Network Upgrade': 'RNU',\n",
    "    'Reliability Network Upgrades': 'RNU',\n",
    "    'Local Delivery Network Upgrade': 'LDNU',\n",
    "    'Local Delivery Network': 'LDNU',\n",
    "    'Potential Local Delivery Network Upgrade': 'LDNU',\n",
    "    \"Ptos Interconnection Facilities\": 'PTO_IF',\n",
    "    'Area Delivery Network Upgrade': 'ADNU',\n",
    "    'Reliability Network Upgrade To Physically Interconnect': 'RNU',\n",
    "    \"Reliability Network upgrade To Physically Interconnect\": \"RNU\",\n",
    "     'Pto': 'PTO_IF',\n",
    "    \"Other Potential Network Upgrade\": \"OPNU\",\n",
    "    \"Conditionally Assigned Network Upgrade\": \"CANU\",\n",
    "    \"Canus\": \"CANU\",\n",
    "        \"Escalated Cost And Time To Construct For Reliability Network Upgrade4\": \"RNU\",\n",
    "    \"Escalated Cost And Time To Construct For Reliability Network Upgrade3\": \"RNU\",\n",
    "    \"Local Off-Peak Network Upgrade\": \"LOPNU\",\n",
    "    'Total PTO_IF': 'PTO_IF',\n",
    " 'Total RNU': 'RNU',\n",
    " 'Total LDNU': 'LDNU',\n",
    " 'Total OPNU' : 'OPNU',\n",
    " 'Total CANU': 'CANU',\n",
    " 'Total LOPNU': 'LOPNU',\n",
    "  \n",
    " 'Total ADNU': 'ADNU',\n",
    "  'Ptos Interconnect Ion Facilities' : 'PTO_IF',\n",
    "  'Local Off- Peak Network Upgrade': 'LOPNU',\n",
    " 'P Os Interconnection Facilities': 'PTO_IF',\n",
    "  \n",
    "\n",
    " \n",
    "}\n",
    "\n",
    "\n",
    "#Step 6: Apply mapping and ffill type of upgrade column\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: re.sub(r'\\bupgrades\\b', 'upgrade', x, flags=re.IGNORECASE).strip() if isinstance(x, str) else x\n",
    "    )\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: mappings.get(x, x) if isinstance(x, str) else x\n",
    "    )\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].ffill()  \n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def drop_rows_with_star_in_costs(df, cost_cols):\n",
    "    \"\"\"\n",
    "    Remove any row where any of the cost_cols contains a '*' character.\n",
    "    \"\"\"\n",
    "    mask = pd.Series(False, index=df.index)\n",
    "    for col in cost_cols:\n",
    "        if col in df.columns:\n",
    "            # star anywhere in the string\n",
    "            mask = mask | df[col].astype(str).str.contains(r\"\\*\", regex=True)\n",
    "    # keep only rows without a star\n",
    "    return df.loc[~mask].reset_index(drop=True)\n",
    "\n",
    "def drop_rows_with_dash_in_time(df, time_col):\n",
    "    \"\"\"\n",
    "    Remove any row where the time_col contains a dash '-' (e.g. '-').\n",
    "    \"\"\"\n",
    "    if time_col in df.columns:\n",
    "        mask = df[time_col].astype(str).str.contains(r\"^-+$\", regex=True)\n",
    "        return df.loc[~mask].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def keep_second_entry_in_cells(df, columns):\n",
    "    \"\"\"\n",
    "    For each column in columns, if the cell contains multiple space‑separated entries,\n",
    "    keep only the second one.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        def pick_second(cell):\n",
    "            parts = re.findall(r\"[\\d\\.\\$%,]+\", str(cell))\n",
    "            return parts[1] if len(parts) > 1 else (parts[0] if parts else cell)\n",
    "        df[col] = df[col].apply(pick_second)\n",
    "    return df\n",
    "\n",
    "# ── Integration ──\n",
    "# Place this just before your Step 7 clean_currency block:\n",
    "\n",
    "# 1) drop any row where estimated or escalated cost has '*'\n",
    "df = drop_rows_with_star_in_costs(\n",
    "    df,\n",
    "    cost_cols=[\n",
    "        'estimated_cost_x_1000',\n",
    "        'escalated_cost_x_1000',\n",
    "        'total_estimated_cost_x_1000',\n",
    "        'total_estimated_cost_x_1000_escalated'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 2) drop any row where estimated_time_to_construct is just a dash\n",
    "df = drop_rows_with_dash_in_time(df, 'estimated_time_to_construct')\n",
    "\n",
    "# 3) if multiple entries exist in a cell, keep only the second\n",
    "df = keep_second_entry_in_cells(\n",
    "    df,\n",
    "    columns=[\n",
    "        'cost_allocation_factor',\n",
    "        'estimated_cost_x_1000',\n",
    "        'escalated_cost_x_1000',\n",
    "        'total_estimated_cost_x_1000',\n",
    "        'total_estimated_cost_x_1000_escalated'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Now proceed with your clean_currency step…\n",
    "\n",
    "\n",
    "    \n",
    "# Step 7: Remove $ signs and convert to numeric\n",
    "import re\n",
    "\n",
    "def clean_currency(value):\n",
    "    \"\"\"\n",
    "    Cleans a string by explicitly removing $, *, (Note 2), and similar patterns,\n",
    "    then converts it to a numeric value.\n",
    "    \"\"\"\n",
    "    if isinstance(value, str):\n",
    "        # Explicitly remove $, *, and any \"(Note ...)\"\n",
    "        value = value.replace('$', '').replace('*', '')\n",
    "        value = re.sub(r'\\(Note \\d+\\)', '', value)  # Remove patterns like \"(Note 2)\"\n",
    "        value = value.replace(',', '').strip()  # Remove commas and extra spaces\n",
    "    try:\n",
    "        return pd.to_numeric(value)\n",
    "    except ValueError:\n",
    "        return pd.NA  # Return NaN for invalid entries\n",
    "\n",
    "\n",
    "# Clean the specific columns\n",
    "for col in ['estimated_cost_x_1000', 'escalated_cost_x_1000', 'total_estimated_cost_x_1000_escalated', 'total_estimated_cost_x_1000', 'adnu_cost_rate_x_1000', 'adnu_cost_rate_x_1000_escalated']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "# Create Total rows\n",
    "new_rows = []\n",
    "columns_to_sum = ['estimated_cost_x_1000', 'escalated_cost_x_1000', 'total_estimated_cost_x_1000_escalated',   'adnu_cost_rate_x_1000_escalated']\n",
    "columns_to_populate = ['cluster', 'req_deliverability', 'latitude', 'longitude', 'capacity', 'point_of_interconnection']\n",
    "\n",
    "for q_id, group in df.groupby('q_id', as_index=False):\n",
    "    unique_upgrades = group['type_of_upgrade'].dropna().unique()\n",
    "    for upgrade in unique_upgrades:\n",
    "        if pd.isna(upgrade):\n",
    "            continue\n",
    "        \n",
    "        rows = group[group['type_of_upgrade'] == upgrade]\n",
    "\n",
    "                # Check if a Total row already exists for this (q_id, upgrade)\n",
    "        total_exists = group[\n",
    "            (group['type_of_upgrade'] == upgrade) & (group['item'] == 'no')\n",
    "        ].shape[0] > 0\n",
    "        \n",
    "        if total_exists:\n",
    "             \n",
    "            continue\n",
    "\n",
    "\n",
    " \n",
    "        \n",
    "        \n",
    "        if not total_exists:\n",
    "            # If only one row exists, duplicate it as the total row\n",
    "            if len(rows) == 1:\n",
    "\n",
    "                total_row = {col: '' for col in df.columns}  # Initialize all columns as empty strings\n",
    "\n",
    "                # Populate the necessary fields\n",
    "                total_row['q_id'] = q_id\n",
    "                total_row['type_of_upgrade'] = f\"Total {upgrade}\"\n",
    "                total_row['item'] = 'no'\n",
    "\n",
    "                # Populate specified columns from the existing row\n",
    "                first_row = rows.iloc[0]\n",
    "                for col in columns_to_populate:\n",
    "                    if col in df.columns:\n",
    "                        total_row[col] = first_row[col]\n",
    "\n",
    "                # Sum the numeric columns (single row, so it remains the same)\n",
    "                for col in columns_to_sum:\n",
    "                    if col in rows.columns:\n",
    "                        total_row[col] = rows[col].sum()\n",
    "                    else:\n",
    "                        total_row[col] = 0  # Default to 0 if column is missing\n",
    "\n",
    "                new_rows.append(total_row)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "            \n",
    "            # If multiple rows exist, sum numeric columns and create a total row\n",
    "            elif len(rows) > 1:\n",
    "                total_row = {col: '' for col in df.columns}  # Initialize all columns as empty strings\n",
    "\n",
    "                # Populate the necessary fields\n",
    "                total_row['q_id'] = q_id\n",
    "                total_row['type_of_upgrade'] = f\"Total {upgrade}\"\n",
    "                total_row['item'] = 'no'\n",
    "\n",
    "                # Populate the specified columns from the first row in the group\n",
    "                first_row = rows.iloc[0]\n",
    "                for col in columns_to_populate:\n",
    "                    if col in df.columns:\n",
    "                        total_row[col] = first_row[col]\n",
    "\n",
    "                # Sum the numeric columns\n",
    "                for col in columns_to_sum:\n",
    "                    if col in rows.columns:\n",
    "                        total_row[col] = rows[col].sum()\n",
    "                    else:\n",
    "                        total_row[col] = 0  # Default to 0 if column is missing\n",
    "\n",
    "                new_rows.append(total_row)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "if new_rows:\n",
    "    total_rows_df = pd.DataFrame(new_rows)\n",
    "    for col in df.columns:\n",
    "        if col not in total_rows_df.columns:\n",
    "            total_rows_df[col] = None\n",
    "    total_rows_df = total_rows_df[df.columns]\n",
    "    df = pd.concat([df, total_rows_df], ignore_index=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Update 'item' column based on Total in type_of_upgrade or cost_allocation_factor\n",
    "df['item'] = df.apply(\n",
    "    lambda row: 'no' if (\n",
    "        'Total' in str(row.get('type_of_upgrade', '')) or \n",
    "        'Total' in str(row.get('cost_allocation_factor', ''))\n",
    "    ) else 'yes',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Step 8: Move 'item' column next to 'type_of_upgrade'\n",
    "if 'item' in df.columns and 'type_of_upgrade' in df.columns:\n",
    "    cols = df.columns.tolist()\n",
    "    item_index = cols.index('item')\n",
    "    type_index = cols.index('type_of_upgrade')\n",
    "    if item_index < type_index:\n",
    "        cols.insert(type_index + 1, cols.pop(item_index))\n",
    "    else:\n",
    "        cols.insert(type_index + 1, cols.pop(item_index))\n",
    "    df = df[cols]\n",
    "\n",
    "# Step 9: Remove \"Total\" values from cost_allocation_factor if they appear in type_of_upgrade\n",
    "if 'cost_allocation_factor' in df.columns and 'type_of_upgrade' in df.columns:\n",
    "    df['cost_allocation_factor'] = df.apply(\n",
    "        lambda row: None if (\n",
    "            pd.notna(row['type_of_upgrade']) and 'Total' in str(row['type_of_upgrade'])\n",
    "        ) else row.get('cost_allocation_factor'),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "\n",
    "if 'cost_allocation_factor' in df.columns and 'type_of_upgrade' in df.columns:\n",
    "    df['cost_allocation_factor'] = df.apply(\n",
    "        lambda row: None if 'Total' in str(row.get('cost_allocation_factor', '')) else row.get('cost_allocation_factor'),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def clean_estimated_time(value):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub(r'(\\d+(?:-\\w+)*)\\s+\\w+.*$', r'\\1', value, flags=re.IGNORECASE).strip()\n",
    "    return value\n",
    "\n",
    "if 'estimated_time_to_construct' in df.columns:\n",
    "    df['estimated_time_to_construct'] = df['estimated_time_to_construct'].apply(clean_estimated_time)\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: re.sub(r'\\s*\\(note \\d+\\)', '', x, flags=re.IGNORECASE).strip() if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: re.sub(r'\\bupgrades\\b', 'upgrade', x, flags=re.IGNORECASE).strip() if isinstance(x, str) else x\n",
    "    )\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].apply(\n",
    "        lambda x: mappings.get(x, x) if isinstance(x, str) else x\n",
    "    )\n",
    "    df['type_of_upgrade'] = df['type_of_upgrade'].ffill()\n",
    "\n",
    "if 'upgrade' in df.columns and 'type_of_upgrade' in df.columns and 'q_id' in df.columns:\n",
    "    df['upgrade'] = df.groupby(['q_id', 'type_of_upgrade'])['upgrade'].ffill()\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    previous_type_of_upgrade = None\n",
    "    for i in range(len(df)):\n",
    "        if df.at[i, 'type_of_upgrade'] == 'Total':\n",
    "            if previous_type_of_upgrade is not None:\n",
    "                df.at[i, 'type_of_upgrade'] = previous_type_of_upgrade\n",
    "        else:\n",
    "            previous_type_of_upgrade = df.at[i, 'type_of_upgrade']\n",
    "\n",
    "numeric_columns = [\n",
    "    'cost_allocation_factor',\n",
    "    'estimated_cost_x_1000',\n",
    "    'estimated_time_to_construct',\n",
    "    'total_estimated_cost_x_1000_escalated',\n",
    "    'adnu_cost_rate_x_1000',\n",
    "    'escalated_cost_x_1000',\n",
    "    'estimated_cost_x_1000_escalated_without_itcca',\n",
    "    'adnu_cost_rate_x_1000_escalated'\n",
    "]\n",
    "non_numeric_columns = ['type_of_upgrade', 'upgrade', 'description']\n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: 'None' if pd.isna(x) else x)\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace('-', pd.NA)\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "if 'original_order' in df.columns and 'q_id' in df.columns:\n",
    "    df['original_order'] = df.index\n",
    "    df = df.sort_values(by=['q_id', 'original_order'], ascending=[True, True])\n",
    "    df = df.drop(columns=['original_order'])\n",
    "\n",
    "\n",
    "def reorder_columns(df):\n",
    "    \"\"\"\n",
    "    Reorders the columns of the DataFrame based on the specified order.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to reorder.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The reordered DataFrame.\n",
    "    \"\"\"\n",
    "    desired_order = [\n",
    "        \"q_id\",\n",
    "        \"cluster\",\n",
    "        \"req_deliverability\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"capacity\",\n",
    "        \"point_of_interconnection\",\n",
    "        \"type_of_upgrade\",\n",
    "        \"upgrade\",\n",
    "        \"description\",\n",
    "        \"cost_allocation_factor\",\n",
    "        \"estimated_cost_x_1000\",\n",
    "        \"escalated_cost_x_1000\",\n",
    "        \"total_estimated_cost_x_1000\",\n",
    "        \"total_estimated_cost_x_1000_escalated\",\n",
    "        \"estimated_time_to_construct\",\n",
    "    ]\n",
    "\n",
    "    # Start with desired columns that exist in the DataFrame\n",
    "    existing_desired = [col for col in desired_order if col in df.columns]\n",
    "\n",
    "    # Then add the remaining columns\n",
    "    remaining = [col for col in df.columns if col not in existing_desired]\n",
    "\n",
    "    # Combine the two lists\n",
    "    new_order = existing_desired + remaining\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    df = df[new_order]\n",
    "\n",
    "    return df        \n",
    "\n",
    "\n",
    "df= reorder_columns(df)\n",
    "\n",
    "\n",
    "# Save itemized and totals separately\n",
    "if 'item' in df.columns:\n",
    "    itemized_df = df[df['item'] == 'yes']\n",
    "    itemized_df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_itemized_addendums.csv', index=False)\n",
    "\n",
    "    totals_columns = ['upgrade', 'description', 'cost_allocation_factor', 'estimated_time_to_construct']\n",
    "    totals_df = df[df['item'] == 'no'].drop(columns=totals_columns, errors='ignore')\n",
    "    totals_df.to_csv('/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_total_addendums.csv', index=False)\n",
    "\n",
    "print(f\"Itemized rows saved to 'costs_phase_2_cluster_12_style_Q_itemized.csv'.\")\n",
    "print(f\"Filtered Total rows saved to 'costs_phase_2_cluster_12_style_Q_total.csv'.\")\n",
    "\n",
    "\n",
    "if 'type_of_upgrade' in df.columns:\n",
    "    print(df['type_of_upgrade'].unique())\n",
    "\n",
    "if 'q_id' in df.columns:\n",
    "    print(df['q_id'].unique())\n",
    "\n",
    "if 'cluster' in df.columns:\n",
    "    print(df['cluster'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Original and Addendums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing itemized: q_id=1688, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 3\n",
      "Length of original_rows: 3\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "0  1688       13               Full  40.808931  -121.931726            \n",
      "1  1688       13               Full  40.808931  -121.931726            \n",
      "2  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "           point_of_interconnection type_of_upgrade  \\\n",
      "0  Round Mountain Substation 230 kV          PTO_IF   \n",
      "1  Round Mountain Substation 230 kV          PTO_IF   \n",
      "2  Round Mountain Substation 230 kV          PTO_IF   \n",
      "\n",
      "                     upgrade  \\\n",
      "0  Round Mountain Substation   \n",
      "1         Transmission Line:   \n",
      "2           Generation Site:   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Gen-Tie Line Terminal Equipment for DBSB and T...                100.00%   \n",
      "1         Gen-Tie T-Line on PG&E Substation Property                100.00%   \n",
      "2  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                 4470.0                 5343.0                        47.0   \n",
      "1                  250.0                  299.0                        33.0   \n",
      "2                  475.0                  568.0                        16.0   \n",
      "\n",
      "  item  \n",
      "0  yes  \n",
      "1  yes  \n",
      "2  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "16  1688       13               Full  40.808931  -121.931726            \n",
      "17  1688       13               Full  40.808931  -121.931726            \n",
      "18  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "            point_of_interconnection type_of_upgrade  \\\n",
      "16  Round Mountain Substation 230 kV          PTO_IF   \n",
      "17  Round Mountain Substation 230 kV          PTO_IF   \n",
      "18  Round Mountain Substation 230 kV          PTO_IF   \n",
      "\n",
      "                      upgrade  \\\n",
      "16  Round Mountain Substation   \n",
      "17         Transmission Line:   \n",
      "18           Generation Site:   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "16  Gen-Tie Line Terminal Equipment for DBSB and T...                100.00%   \n",
      "17         Gen-Tie T-Line on PG&E Substation Property                100.00%   \n",
      "18  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "16                 4470.0                 5343.0                        47.0   \n",
      "17                  250.0                  299.0                        33.0   \n",
      "18                  475.0                  568.0                        16.0   \n",
      "\n",
      "   item original  row_order  \n",
      "16  yes      yes         16  \n",
      "17  yes      yes         17  \n",
      "18  yes      yes         18  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "16    Full\n",
      "17    Full\n",
      "18    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    40.808931\n",
      "1    40.808931\n",
      "2    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "16    40.808931\n",
      "17    40.808931\n",
      "18    40.808931\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    40.808931\n",
      "1    40.808931\n",
      "2    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -121.931726\n",
      "1    -121.931726\n",
      "2    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "16    -121.931726\n",
      "17    -121.931726\n",
      "18    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -121.931726\n",
      "1    -121.931726\n",
      "2    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "16    \n",
      "17    \n",
      "18    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Round Mountain Substation 230 kV\n",
      "1    Round Mountain Substation 230 kV\n",
      "2    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "16    Round Mountain Substation 230 kV\n",
      "17    Round Mountain Substation 230 kV\n",
      "18    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Round Mountain Substation 230 kV\n",
      "1    Round Mountain Substation 230 kV\n",
      "2    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1688, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "3  1688       13               Full  40.808931  -121.931726            \n",
      "4  1688       13               Full  40.808931  -121.931726            \n",
      "5  1688       13               Full  40.808931  -121.931726            \n",
      "6  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "           point_of_interconnection type_of_upgrade  \\\n",
      "3  Round Mountain Substation 230 kV             RNU   \n",
      "4  Round Mountain Substation 230 kV             RNU   \n",
      "5  Round Mountain Substation 230 kV             RNU   \n",
      "6  Round Mountain Substation 230 kV             RNU   \n",
      "\n",
      "                                        upgrade  \\\n",
      "3                     Round Mountain Substation   \n",
      "4  Tesla 500 kV circuit breakers 622 overstress   \n",
      "5  Cottonwood 230kV CB Overstress, CB 222 & 232   \n",
      "6  Cottonwood 230kV CB Overstress, CB 212 & 282   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "3  Extend Yard, Security Wall, Grading DBSB Paral...                100.00%   \n",
      "4  Replace Tesla 500 kV circuit breaker 622 with ...                  5.57%   \n",
      "5  Cottonwood Sub: Replace 230kV CB's 222 & 232, ...                100.00%   \n",
      "6  Cottonwood Sub: Replace 230kV CB's 212 & 282, ...                100.00%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "3                 9160.0                10948.0                        47.0   \n",
      "4                  390.0                  440.0                        60.0   \n",
      "5                 4200.0                 4647.0                        48.0   \n",
      "6                 4200.0                 4647.0                        44.0   \n",
      "\n",
      "  item  \n",
      "3  yes  \n",
      "4  yes  \n",
      "5  yes  \n",
      "6  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "19  1688       13               Full  40.808931  -121.931726            \n",
      "20  1688       13               Full  40.808931  -121.931726            \n",
      "21  1688       13               Full  40.808931  -121.931726            \n",
      "22  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "            point_of_interconnection type_of_upgrade  \\\n",
      "19  Round Mountain Substation 230 kV             RNU   \n",
      "20  Round Mountain Substation 230 kV             RNU   \n",
      "21  Round Mountain Substation 230 kV             RNU   \n",
      "22  Round Mountain Substation 230 kV             RNU   \n",
      "\n",
      "                                         upgrade  \\\n",
      "19                     Round Mountain Substation   \n",
      "20  Tesla 500 kV circuit breakers 622 overstress   \n",
      "21  Cottonwood 230kV CB Overstress, CB 222 & 232   \n",
      "22  Cottonwood 230kV CB Overstress, CB 212 & 282   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "19  Extend Yard, Security Wall, Grading DBSB Paral...                100.00%   \n",
      "20  Replace Tesla 500 kV circuit breaker 622 with ...                  5.57%   \n",
      "21  Cottonwood Sub: Replace 230kV CB's 222 & 232, ...                100.00%   \n",
      "22  Cottonwood Sub: Replace 230kV CB's 212 & 282, ...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "19                 9160.0                10948.0                        47.0   \n",
      "20                  390.0                  440.0                        60.0   \n",
      "21                 4200.0                 4647.0                        48.0   \n",
      "22                 4200.0                 4647.0                        44.0   \n",
      "\n",
      "   item original  row_order  \n",
      "19  yes      yes         19  \n",
      "20  yes      yes         20  \n",
      "21  yes      yes         21  \n",
      "22  yes      yes         22  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "3    Full\n",
      "4    Full\n",
      "5    Full\n",
      "6    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "19    Full\n",
      "20    Full\n",
      "21    Full\n",
      "22    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "3    Full\n",
      "4    Full\n",
      "5    Full\n",
      "6    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "3    40.808931\n",
      "4    40.808931\n",
      "5    40.808931\n",
      "6    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "19    40.808931\n",
      "20    40.808931\n",
      "21    40.808931\n",
      "22    40.808931\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "3    40.808931\n",
      "4    40.808931\n",
      "5    40.808931\n",
      "6    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "3    -121.931726\n",
      "4    -121.931726\n",
      "5    -121.931726\n",
      "6    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "19    -121.931726\n",
      "20    -121.931726\n",
      "21    -121.931726\n",
      "22    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "3    -121.931726\n",
      "4    -121.931726\n",
      "5    -121.931726\n",
      "6    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "3    \n",
      "4    \n",
      "5    \n",
      "6    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "19    \n",
      "20    \n",
      "21    \n",
      "22    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "3    \n",
      "4    \n",
      "5    \n",
      "6    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "3    Round Mountain Substation 230 kV\n",
      "4    Round Mountain Substation 230 kV\n",
      "5    Round Mountain Substation 230 kV\n",
      "6    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "19    Round Mountain Substation 230 kV\n",
      "20    Round Mountain Substation 230 kV\n",
      "21    Round Mountain Substation 230 kV\n",
      "22    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "3    Round Mountain Substation 230 kV\n",
      "4    Round Mountain Substation 230 kV\n",
      "5    Round Mountain Substation 230 kV\n",
      "6    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1688, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 1\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "7  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "           point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "7  Round Mountain Substation 230 kV            LDNU    None        None   \n",
      "\n",
      "  cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "7                      0                    0.0                    0.0   \n",
      "\n",
      "  estimated_time_to_construct item  \n",
      "7                           0  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "23  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "            point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "23  Round Mountain Substation 230 kV            LDNU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "23                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item original  row_order  \n",
      "23                           0  yes      yes         23  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "7    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "23    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "7    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "7    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "23    40.808931\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "7    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "7    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "23    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "7    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "7    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "23    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "7    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "7    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "23    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "7    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1688, type_of_upgrade=LOPNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 1\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "8  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "           point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "8  Round Mountain Substation 230 kV           LOPNU    None        None   \n",
      "\n",
      "  cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "8                      0                    0.0                    0.0   \n",
      "\n",
      "  estimated_time_to_construct item  \n",
      "8                           0  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "24  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "            point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "24  Round Mountain Substation 230 kV           LOPNU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "24                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item original  row_order  \n",
      "24                           0  yes      yes         24  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "8    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "24    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "8    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "8    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "24    40.808931\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "8    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "8    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "24    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "8    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "8    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "24    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "8    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "8    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "24    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "8    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1688, type_of_upgrade=CANU\n",
      "Length of addendum_rows: 2\n",
      "Length of original_rows: 2\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "9   1688       13               Full  40.808931  -121.931726            \n",
      "10  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "            point_of_interconnection type_of_upgrade  \\\n",
      "9   Round Mountain Substation 230 kV            CANU   \n",
      "10  Round Mountain Substation 230 kV            CANU   \n",
      "\n",
      "                               upgrade  \\\n",
      "9   Cottonwood 230kV CB 242 overstress   \n",
      "10  Cottonwood 230kV CB 242 overstress   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "9   Cottonwood Sub: Replace 230kV CB 242, SW's and...                100.00%   \n",
      "10                                               None                      0   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "9                  2100.0                 2278.0                        36.0   \n",
      "10                 2100.0                 2278.0                           0   \n",
      "\n",
      "   item  \n",
      "9   yes  \n",
      "10  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "25  1688       13               Full  40.808931  -121.931726            \n",
      "26  1688       13               Full  40.808931  -121.931726            \n",
      "\n",
      "            point_of_interconnection type_of_upgrade  \\\n",
      "25  Round Mountain Substation 230 kV            CANU   \n",
      "26  Round Mountain Substation 230 kV            CANU   \n",
      "\n",
      "                               upgrade  \\\n",
      "25  Cottonwood 230kV CB 242 overstress   \n",
      "26  Cottonwood 230kV CB 242 overstress   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "25  Cottonwood Sub: Replace 230kV CB 242, SW's and...                100.00%   \n",
      "26                                               None                      0   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "25                 2100.0                 2278.0                        36.0   \n",
      "26                 2100.0                 2278.0                           0   \n",
      "\n",
      "   item original  row_order  \n",
      "25  yes      yes         25  \n",
      "26  yes      yes         26  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "9     Full\n",
      "10    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "25    Full\n",
      "26    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "9     Full\n",
      "10    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "9     40.808931\n",
      "10    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "25    40.808931\n",
      "26    40.808931\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "9     40.808931\n",
      "10    40.808931\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "9     -121.931726\n",
      "10    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "25    -121.931726\n",
      "26    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "9     -121.931726\n",
      "10    -121.931726\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "9     \n",
      "10    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "25    \n",
      "26    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "9     \n",
      "10    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "9     Round Mountain Substation 230 kV\n",
      "10    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "25    Round Mountain Substation 230 kV\n",
      "26    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "9     Round Mountain Substation 230 kV\n",
      "10    Round Mountain Substation 230 kV\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 3\n",
      "Length of original_rows: 3\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "11  1691       13               Full  38.215846  -121.840441            \n",
      "12  1691       13               Full  38.215846  -121.840441            \n",
      "13  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade             upgrade  \\\n",
      "11  Birds Landing Substation          PTO_IF    Birds Landing SS   \n",
      "12  Birds Landing Substation          PTO_IF  Transmission Line:   \n",
      "13  Birds Landing Substation          PTO_IF    Generation Site:   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "11  Gen-Tie Line Terminal Equipment and Terminatio...                100.00%   \n",
      "12  Gen-Tie T-Line on PG&E Substation Property & (...                100.00%   \n",
      "13  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "11                  970.0                 1095.0                        42.0   \n",
      "12                 2570.0                 2901.0                        41.0   \n",
      "13                  475.0                  536.0                        16.0   \n",
      "\n",
      "   item  \n",
      "11  yes  \n",
      "12  yes  \n",
      "13  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "38  1691       13               Full  38.215846  -121.840441            \n",
      "39  1691       13               Full  38.215846  -121.840441            \n",
      "40  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade             upgrade  \\\n",
      "38  Birds Landing Substation          PTO_IF    Birds Landing SS   \n",
      "39  Birds Landing Substation          PTO_IF  Transmission Line:   \n",
      "40  Birds Landing Substation          PTO_IF    Generation Site:   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "38  Gen-Tie Line Terminal Equipment and Terminatio...                100.00%   \n",
      "39  Gen-Tie T-Line on PG&E Substation Property & (...                100.00%   \n",
      "40  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "38                  970.0                 1095.0                        42.0   \n",
      "39                 2570.0                 2901.0                        41.0   \n",
      "40                  475.0                  536.0                        16.0   \n",
      "\n",
      "   item original  row_order  \n",
      "38  yes      yes         38  \n",
      "39  yes      yes         39  \n",
      "40  yes      yes         40  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "11    Full\n",
      "12    Full\n",
      "13    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "38    Full\n",
      "39    Full\n",
      "40    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "11    Full\n",
      "12    Full\n",
      "13    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "11    38.215846\n",
      "12    38.215846\n",
      "13    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "38    38.215846\n",
      "39    38.215846\n",
      "40    38.215846\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "11    38.215846\n",
      "12    38.215846\n",
      "13    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "11    -121.840441\n",
      "12    -121.840441\n",
      "13    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "38    -121.840441\n",
      "39    -121.840441\n",
      "40    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "11    -121.840441\n",
      "12    -121.840441\n",
      "13    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "11    \n",
      "12    \n",
      "13    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "38    \n",
      "39    \n",
      "40    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "11    \n",
      "12    \n",
      "13    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "11    Birds Landing Substation\n",
      "12    Birds Landing Substation\n",
      "13    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "38    Birds Landing Substation\n",
      "39    Birds Landing Substation\n",
      "40    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "11    Birds Landing Substation\n",
      "12    Birds Landing Substation\n",
      "13    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 2\n",
      "Length of original_rows: 2\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "14  1691       13               Full  38.215846  -121.840441            \n",
      "15  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade  \\\n",
      "14  Birds Landing Substation             RNU   \n",
      "15  Birds Landing Substation             RNU   \n",
      "\n",
      "                                         upgrade  \\\n",
      "14                              Birds Landing SS   \n",
      "15  Tesla 500 kV circuit breakers 622 overstress   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "14  Install (1) 230kV BAAH Bays with (3) circuit b...                100.00%   \n",
      "15  Replace Tesla 500 kV circuit breaker 622 with ...                  7.83%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "14                 5500.0                 6209.0                        42.0   \n",
      "15                  548.0                  618.0                        60.0   \n",
      "\n",
      "   item  \n",
      "14  yes  \n",
      "15  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "41  1691       13               Full  38.215846  -121.840441            \n",
      "42  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade  \\\n",
      "41  Birds Landing Substation             RNU   \n",
      "42  Birds Landing Substation             RNU   \n",
      "\n",
      "                                         upgrade  \\\n",
      "41                              Birds Landing SS   \n",
      "42  Tesla 500 kV circuit breakers 622 overstress   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "41  Install (1) 230kV BAAH Bays with (3) circuit b...                100.00%   \n",
      "42  Replace Tesla 500 kV circuit breaker 622 with ...                  7.83%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "41                 5500.0                 6209.0                        42.0   \n",
      "42                  548.0                  618.0                        60.0   \n",
      "\n",
      "   item original  row_order  \n",
      "41  yes      yes         41  \n",
      "42  yes      yes         42  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "14    Full\n",
      "15    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "41    Full\n",
      "42    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "14    Full\n",
      "15    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "14    38.215846\n",
      "15    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "41    38.215846\n",
      "42    38.215846\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "14    38.215846\n",
      "15    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "14    -121.840441\n",
      "15    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "41    -121.840441\n",
      "42    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "14    -121.840441\n",
      "15    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "14    \n",
      "15    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "41    \n",
      "42    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "14    \n",
      "15    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "14    Birds Landing Substation\n",
      "15    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "41    Birds Landing Substation\n",
      "42    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "14    Birds Landing Substation\n",
      "15    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 1\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "16  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "16  Birds Landing Substation            LDNU    none               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "16                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "16                           0  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "43  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "43  Birds Landing Substation            LDNU    none               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "43                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item original  row_order  \n",
      "43                           0  yes      yes         43  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "16    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "43    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "16    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "16    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "43    38.215846\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "16    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "16    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "43    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "16    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "16    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "43    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "16    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "16    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "43    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "16    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=LOPNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 1\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "17  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "17  Birds Landing Substation           LOPNU    none               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "17                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "17                           0  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "44  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "44  Birds Landing Substation           LOPNU    none               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "44                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item original  row_order  \n",
      "44                           0  yes      yes         44  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "17    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "44    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "17    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "17    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "44    38.215846\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "17    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "17    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "44    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "17    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "17    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "44    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "17    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "17    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "44    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "17    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=CANU\n",
      "Length of addendum_rows: 5\n",
      "Length of original_rows: 5\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "18  1691       13               Full  38.215846  -121.840441            \n",
      "19  1691       13               Full  38.215846  -121.840441            \n",
      "20  1691       13               Full  38.215846  -121.840441            \n",
      "21  1691       13               Full  38.215846  -121.840441            \n",
      "22  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "18  Birds Landing Substation            CANU    None               \n",
      "19  Birds Landing Substation            CANU    None               \n",
      "20  Birds Landing Substation            CANU    None               \n",
      "21  Birds Landing Substation            CANU    None               \n",
      "22  Birds Landing Substation            CANU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "18                      0                    0.0                    0.0   \n",
      "19                      0                    0.0                    0.0   \n",
      "20                      0                    0.0                    0.0   \n",
      "21                      0                    0.0                    0.0   \n",
      "22                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "18                           0  yes  \n",
      "19                           0  yes  \n",
      "20                           0  yes  \n",
      "21                           0  yes  \n",
      "22                           0  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "45  1691       13               Full  38.215846  -121.840441            \n",
      "46  1691       13               Full  38.215846  -121.840441            \n",
      "47  1691       13               Full  38.215846  -121.840441            \n",
      "48  1691       13               Full  38.215846  -121.840441            \n",
      "49  1691       13               Full  38.215846  -121.840441            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "45  Birds Landing Substation            CANU    None               \n",
      "46  Birds Landing Substation            CANU    None               \n",
      "47  Birds Landing Substation            CANU    None               \n",
      "48  Birds Landing Substation            CANU    None               \n",
      "49  Birds Landing Substation            CANU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "45                      0                    0.0                    0.0   \n",
      "46                      0                    0.0                    0.0   \n",
      "47                      0                    0.0                    0.0   \n",
      "48                      0                    0.0                    0.0   \n",
      "49                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item original  row_order  \n",
      "45                           0  yes      yes         45  \n",
      "46                           0  yes      yes         46  \n",
      "47                           0  yes      yes         47  \n",
      "48                           0  yes      yes         48  \n",
      "49                           0  yes      yes         49  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "18    Full\n",
      "19    Full\n",
      "20    Full\n",
      "21    Full\n",
      "22    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "45    Full\n",
      "46    Full\n",
      "47    Full\n",
      "48    Full\n",
      "49    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "18    Full\n",
      "19    Full\n",
      "20    Full\n",
      "21    Full\n",
      "22    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "18    38.215846\n",
      "19    38.215846\n",
      "20    38.215846\n",
      "21    38.215846\n",
      "22    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "45    38.215846\n",
      "46    38.215846\n",
      "47    38.215846\n",
      "48    38.215846\n",
      "49    38.215846\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "18    38.215846\n",
      "19    38.215846\n",
      "20    38.215846\n",
      "21    38.215846\n",
      "22    38.215846\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "18    -121.840441\n",
      "19    -121.840441\n",
      "20    -121.840441\n",
      "21    -121.840441\n",
      "22    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "45    -121.840441\n",
      "46    -121.840441\n",
      "47    -121.840441\n",
      "48    -121.840441\n",
      "49    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "18    -121.840441\n",
      "19    -121.840441\n",
      "20    -121.840441\n",
      "21    -121.840441\n",
      "22    -121.840441\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "18    \n",
      "19    \n",
      "20    \n",
      "21    \n",
      "22    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "45    \n",
      "46    \n",
      "47    \n",
      "48    \n",
      "49    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "18    \n",
      "19    \n",
      "20    \n",
      "21    \n",
      "22    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "18    Birds Landing Substation\n",
      "19    Birds Landing Substation\n",
      "20    Birds Landing Substation\n",
      "21    Birds Landing Substation\n",
      "22    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "45    Birds Landing Substation\n",
      "46    Birds Landing Substation\n",
      "47    Birds Landing Substation\n",
      "48    Birds Landing Substation\n",
      "49    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "18    Birds Landing Substation\n",
      "19    Birds Landing Substation\n",
      "20    Birds Landing Substation\n",
      "21    Birds Landing Substation\n",
      "22    Birds Landing Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 2\n",
      "Length of original_rows: 2\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "23  1713       13               Full  36.270212  -119.648275            \n",
      "24  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade                        upgrade  \\\n",
      "23  GWF Handford SW Station          PTO_IF  GWF Hanford Switching Station   \n",
      "24  GWF Handford SW Station          PTO_IF                Generation Site   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "23       Isolate 125VDC Battery from 3rd Party System                100.00%   \n",
      "24  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "23                   75.0                   80.0                        12.0   \n",
      "24                  375.0                  399.0                        16.0   \n",
      "\n",
      "   item  \n",
      "23  yes  \n",
      "24  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "94  1713       13               Full  36.270212  -119.648275            \n",
      "95  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade                        upgrade  \\\n",
      "94  GWF Handford SW Station          PTO_IF  GWF Hanford Switching Station   \n",
      "95  GWF Handford SW Station          PTO_IF                Generation Site   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "94       Isolate 125VDC Battery from 3rd Party System                100.00%   \n",
      "95  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "94                   75.0                   80.0                        12.0   \n",
      "95                  375.0                  399.0                        16.0   \n",
      "\n",
      "   item original  row_order  \n",
      "94  yes      yes         94  \n",
      "95  yes      yes         95  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "23    Full\n",
      "24    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "94    Full\n",
      "95    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "23    Full\n",
      "24    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "23    36.270212\n",
      "24    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "94    36.270212\n",
      "95    36.270212\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "23    36.270212\n",
      "24    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "23    -119.648275\n",
      "24    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "94    -119.648275\n",
      "95    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "23    -119.648275\n",
      "24    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "23    \n",
      "24    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "94    \n",
      "95    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "23    \n",
      "24    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "23    GWF Handford SW Station\n",
      "24    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "94    GWF Handford SW Station\n",
      "95    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "23    GWF Handford SW Station\n",
      "24    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 1\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "25  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "25  GWF Handford SW Station             RNU    None               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "25                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "25                           0  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "96  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "96  GWF Handford SW Station             RNU    None               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "96                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item original  row_order  \n",
      "96                           0  yes      yes         96  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "25    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "96    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "25    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "25    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "96    36.270212\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "25    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "25    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "96    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "25    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "25    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "96    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "25    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "25    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "96    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "25    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 1\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "26  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "26  GWF Handford SW Station            LDNU    None               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "26                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "26                           0  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "97  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "97  GWF Handford SW Station            LDNU    None               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "97                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item original  row_order  \n",
      "97                           0  yes      yes         97  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "26    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "97    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "26    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "26    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "97    36.270212\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "26    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "26    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "97    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "26    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "26    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "97    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "26    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "26    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "97    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "26    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=LOPNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 1\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "27  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "27  GWF Handford SW Station           LOPNU    None               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "27                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "27                           0  yes  \n",
      "original_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "98  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "98  GWF Handford SW Station           LOPNU    None               \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "98                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item original  row_order  \n",
      "98                           0  yes      yes         98  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "27    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "98    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "27    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "27    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "98    36.270212\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "27    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "27    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "98    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "27    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "27    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "98    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "27    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "27    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "98    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "27    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=CANU\n",
      "Length of addendum_rows: 2\n",
      "Length of original_rows: 2\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "28  1713       13               Full  36.270212  -119.648275            \n",
      "29  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "28  GWF Handford SW Station            CANU    None               \n",
      "29  GWF Handford SW Station            CANU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "28                      0                    0.0                    0.0   \n",
      "29                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "28                           0  yes  \n",
      "29                           0  yes  \n",
      "original_rows:\n",
      "     q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "99   1713       13               Full  36.270212  -119.648275            \n",
      "100  1713       13               Full  36.270212  -119.648275            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "99   GWF Handford SW Station            CANU    None               \n",
      "100  GWF Handford SW Station            CANU    None        None   \n",
      "\n",
      "    cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "99                       0                    0.0                    0.0   \n",
      "100                      0                    0.0                    0.0   \n",
      "\n",
      "    estimated_time_to_construct item original  row_order  \n",
      "99                            0  yes      yes         99  \n",
      "100                           0  yes      yes        100  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "28    Full\n",
      "29    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "99     Full\n",
      "100    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "28    Full\n",
      "29    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "28    36.270212\n",
      "29    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "99     36.270212\n",
      "100    36.270212\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "28    36.270212\n",
      "29    36.270212\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "28    -119.648275\n",
      "29    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "99     -119.648275\n",
      "100    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "28    -119.648275\n",
      "29    -119.648275\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "28    \n",
      "29    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "99     \n",
      "100    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "28    \n",
      "29    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "28    GWF Handford SW Station\n",
      "29    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "99     GWF Handford SW Station\n",
      "100    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "28    GWF Handford SW Station\n",
      "29    GWF Handford SW Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1718, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "30  1718       13               Full                               \n",
      "\n",
      "   point_of_interconnection type_of_upgrade          upgrade  \\\n",
      "30                                   PTO_IF  Generation Site   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "30  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "30                  375.0                  399.0                        16.0   \n",
      "\n",
      "   item  \n",
      "30  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "30    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "30    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "30    \n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "30    \n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "30    \n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "30    \n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "30    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "30    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "30    \n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "30    \n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1718, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "31  1718       13               Full                               \n",
      "\n",
      "   point_of_interconnection type_of_upgrade  \\\n",
      "31                                      RNU   \n",
      "\n",
      "                                              upgrade  \\\n",
      "31  QC13P2RAS-01 Los Banos-230/70 kV Transformer O...   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "31  QC13P2RAS-01 RAS to trip Q1718 for overload/ou...                 58.02%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "31                 2147.0                 2329.0                        36.0   \n",
      "\n",
      "   item  \n",
      "31  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "31    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "31    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "31    \n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "31    \n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "31    \n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "31    \n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "31    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "31    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "31    \n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "31    \n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1728, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 2\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "32  1728       13               Full  36.921358  -120.819683            \n",
      "33  1728       13               Full  36.921358  -120.819683            \n",
      "34  1728       13               Full  36.921358  -120.819683            \n",
      "35  1728       13               Full  36.921358  -120.819683            \n",
      "\n",
      "           point_of_interconnection type_of_upgrade  \\\n",
      "32  Mercy Springs Switching Station             RNU   \n",
      "33  Mercy Springs Switching Station             RNU   \n",
      "34  Mercy Springs Switching Station             RNU   \n",
      "35  Mercy Springs Switching Station             RNU   \n",
      "\n",
      "                                              upgrade  \\\n",
      "32                                      Mercy Springs   \n",
      "33  QC13P2RAS-01 Los Banos- 230/70 kV Transformer ...   \n",
      "34                                      Mercy Springs   \n",
      "35  QC13P2RAS-01 Los Banos- 230/70 kV Transformer ...   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "32  Install (1) circuit breaker to existing 70kV R...                100.00%   \n",
      "33  QC13P2RAS-01 RAS to trip Q1718 for overload/ou...                 41.98%   \n",
      "34  Install (1) circuit breaker to existing 70kV R...                100.00%   \n",
      "35  QC13P2RAS-01 RAS to trip Q1718 for overload/ou...                 41.98%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "32                 1220.0                 1350.0                        34.0   \n",
      "33                 1553.0                 1719.0                        36.0   \n",
      "34                 1220.0                 1350.0                        34.0   \n",
      "35                 1553.0                 1719.0                        36.0   \n",
      "\n",
      "   item  \n",
      "32  yes  \n",
      "33  yes  \n",
      "34  yes  \n",
      "35  yes  \n",
      "original_rows:\n",
      "     q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "104  1728       13               Full  36.921358  -120.819683            \n",
      "105  1728       13               Full  36.921358  -120.819683            \n",
      "\n",
      "            point_of_interconnection type_of_upgrade  \\\n",
      "104  Mercy Springs Switching Station             RNU   \n",
      "105  Mercy Springs Switching Station             RNU   \n",
      "\n",
      "                                               upgrade  \\\n",
      "104                                      Mercy Springs   \n",
      "105  QC13P2RAS-01 Los Banos-230/70 kV Transformer O...   \n",
      "\n",
      "                                           description cost_allocation_factor  \\\n",
      "104  Install (1) circuit breaker to existing 70kV R...                100.00%   \n",
      "105  QC13P2RAS-01 RAS to trip Q1718 for overload/ou...                 41.98%   \n",
      "\n",
      "     estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "104                 1220.0                 1350.0                        34.0   \n",
      "105                 1553.0                 1719.0                        36.0   \n",
      "\n",
      "    item original  row_order  \n",
      "104  yes      yes        104  \n",
      "105  yes      yes        105  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "32    Full\n",
      "33    Full\n",
      "34    Full\n",
      "35    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "104    Full\n",
      "105    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "32    Full\n",
      "33    Full\n",
      "34    Full\n",
      "35    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "32    36.921358\n",
      "33    36.921358\n",
      "34    36.921358\n",
      "35    36.921358\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "104    36.921358\n",
      "105    36.921358\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "32    36.921358\n",
      "33    36.921358\n",
      "34    36.921358\n",
      "35    36.921358\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "32    -120.819683\n",
      "33    -120.819683\n",
      "34    -120.819683\n",
      "35    -120.819683\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "104    -120.819683\n",
      "105    -120.819683\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "32    -120.819683\n",
      "33    -120.819683\n",
      "34    -120.819683\n",
      "35    -120.819683\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "32    \n",
      "33    \n",
      "34    \n",
      "35    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "104    \n",
      "105    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "32    \n",
      "33    \n",
      "34    \n",
      "35    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "32    Mercy Springs Switching Station\n",
      "33    Mercy Springs Switching Station\n",
      "34    Mercy Springs Switching Station\n",
      "35    Mercy Springs Switching Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "104    Mercy Springs Switching Station\n",
      "105    Mercy Springs Switching Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "32    Mercy Springs Switching Station\n",
      "33    Mercy Springs Switching Station\n",
      "34    Mercy Springs Switching Station\n",
      "35    Mercy Springs Switching Station\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1736, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 3\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability  latitude    longitude capacity  \\\n",
      "36  1736       13               Full  35.74692  -119.878883            \n",
      "37  1736       13               Full  35.74692  -119.878883            \n",
      "38  1736       13               Full  35.74692  -119.878883            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade             upgrade  \\\n",
      "36          Arco Substation          PTO_IF     Arco Substation   \n",
      "37          Arco Substation          PTO_IF  Transmission Line:   \n",
      "38          Arco Substation          PTO_IF    Generation Site:   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "36  Gen-Tie Line Terminal Equipment and Terminatio...                100.00%   \n",
      "37  Gen-Tie T-Line on PG&E Substation Property and...                100.00%   \n",
      "38  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "36                 1310.0                 1479.0                        48.0   \n",
      "37                  890.0                 1005.0                        41.0   \n",
      "38                  535.0                  604.0                        16.0   \n",
      "\n",
      "   item  \n",
      "36  yes  \n",
      "37  yes  \n",
      "38  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "36    Full\n",
      "37    Full\n",
      "38    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "36    Full\n",
      "37    Full\n",
      "38    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "36    35.74692\n",
      "37    35.74692\n",
      "38    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "36    35.74692\n",
      "37    35.74692\n",
      "38    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "36    -119.878883\n",
      "37    -119.878883\n",
      "38    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "36    -119.878883\n",
      "37    -119.878883\n",
      "38    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "36    \n",
      "37    \n",
      "38    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "36    \n",
      "37    \n",
      "38    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "36    Arco Substation\n",
      "37    Arco Substation\n",
      "38    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "36    Arco Substation\n",
      "37    Arco Substation\n",
      "38    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1736, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 5\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability  latitude    longitude capacity  \\\n",
      "39  1736       13               Full  35.74692  -119.878883            \n",
      "40  1736       13               Full  35.74692  -119.878883            \n",
      "41  1736       13               Full  35.74692  -119.878883            \n",
      "42  1736       13               Full  35.74692  -119.878883            \n",
      "43  1736       13               Full  35.74692  -119.878883            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade  \\\n",
      "39          Arco Substation             RNU   \n",
      "40          Arco Substation             RNU   \n",
      "41          Arco Substation             RNU   \n",
      "42          Arco Substation             RNU   \n",
      "43          Arco Substation             RNU   \n",
      "\n",
      "                                              upgrade  \\\n",
      "39                                    Arco Substation   \n",
      "40                                 Transmission Line:   \n",
      "41  Midway Substation 230 kV bus and circuit break...   \n",
      "42  Midway Substation 500 kV CB 722 Overload over ...   \n",
      "43  PGAE-QC13P2RAS-04 Midway 500/230 kV Transforme...   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "39  Install (3) 230kV CB 2512, 2522, & 2532 in new...                 50.00%   \n",
      "40  Relocate Line Switches from T- Line Structure ...                100.00%   \n",
      "41  Install series bus reactors between Midway Sub...                  7.75%   \n",
      "42  Replace Midway 500 kV CB 722 switches to achie...                  7.94%   \n",
      "43  PGAE-QC13P2RAS-04 Modify existing Midway 500/2...                 11.63%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "39                 2946.0                 3326.0                        48.0   \n",
      "40                  500.0                  564.0                        41.0   \n",
      "41                 1162.0                 1338.0                        72.0   \n",
      "42                   32.0                   37.0                        48.0   \n",
      "43                  407.0                  469.0                        36.0   \n",
      "\n",
      "   item  \n",
      "39  yes  \n",
      "40  yes  \n",
      "41  yes  \n",
      "42  yes  \n",
      "43  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "39    Full\n",
      "40    Full\n",
      "41    Full\n",
      "42    Full\n",
      "43    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "39    Full\n",
      "40    Full\n",
      "41    Full\n",
      "42    Full\n",
      "43    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "39    35.74692\n",
      "40    35.74692\n",
      "41    35.74692\n",
      "42    35.74692\n",
      "43    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "39    35.74692\n",
      "40    35.74692\n",
      "41    35.74692\n",
      "42    35.74692\n",
      "43    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "39    -119.878883\n",
      "40    -119.878883\n",
      "41    -119.878883\n",
      "42    -119.878883\n",
      "43    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "39    -119.878883\n",
      "40    -119.878883\n",
      "41    -119.878883\n",
      "42    -119.878883\n",
      "43    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "39    \n",
      "40    \n",
      "41    \n",
      "42    \n",
      "43    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "39    \n",
      "40    \n",
      "41    \n",
      "42    \n",
      "43    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "39    Arco Substation\n",
      "40    Arco Substation\n",
      "41    Arco Substation\n",
      "42    Arco Substation\n",
      "43    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "39    Arco Substation\n",
      "40    Arco Substation\n",
      "41    Arco Substation\n",
      "42    Arco Substation\n",
      "43    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1736, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability  latitude    longitude capacity  \\\n",
      "44  1736       13               Full  35.74692  -119.878883            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "44          Arco Substation            LDNU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "44                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "44                           0  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "44    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "44    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "44    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "44    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "44    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "44    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "44    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "44    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "44    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "44    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1736, type_of_upgrade=LOPNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability  latitude    longitude capacity  \\\n",
      "45  1736       13               Full  35.74692  -119.878883            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "45          Arco Substation           LOPNU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "45                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "45                           0  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "45    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "45    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "45    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "45    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "45    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "45    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "45    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "45    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "45    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "45    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1736, type_of_upgrade=CANU\n",
      "Length of addendum_rows: 5\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability  latitude    longitude capacity  \\\n",
      "46  1736       13               Full  35.74692  -119.878883            \n",
      "47  1736       13               Full  35.74692  -119.878883            \n",
      "48  1736       13               Full  35.74692  -119.878883            \n",
      "49  1736       13               Full  35.74692  -119.878883            \n",
      "50  1736       13               Full  35.74692  -119.878883            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade  \\\n",
      "46          Arco Substation            CANU   \n",
      "47          Arco Substation            CANU   \n",
      "48          Arco Substation            CANU   \n",
      "49          Arco Substation            CANU   \n",
      "50          Arco Substation            CANU   \n",
      "\n",
      "                                              upgrade  \\\n",
      "46                                    Arco Substation   \n",
      "47                                   Gates Substation   \n",
      "48                                  Midway Substation   \n",
      "49             Gates Substation 230 kV Bus Overstress   \n",
      "50  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "46  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "47            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "48              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "49  Install series bus reactors between Gates Subs...                 12.80%   \n",
      "50  Replace Midway 500 kV CB 722 to achieve 4000 A...                  7.94%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "46                11270.0                12723.0                        48.0   \n",
      "47                  193.0                  218.0                        48.0   \n",
      "48                  695.0                  785.0                        48.0   \n",
      "49                 1792.0                 1944.0                        36.0   \n",
      "50                  556.0                  615.0                        48.0   \n",
      "\n",
      "   item  \n",
      "46  yes  \n",
      "47  yes  \n",
      "48  yes  \n",
      "49  yes  \n",
      "50  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "46    Full\n",
      "47    Full\n",
      "48    Full\n",
      "49    Full\n",
      "50    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "46    Full\n",
      "47    Full\n",
      "48    Full\n",
      "49    Full\n",
      "50    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "46    35.74692\n",
      "47    35.74692\n",
      "48    35.74692\n",
      "49    35.74692\n",
      "50    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "46    35.74692\n",
      "47    35.74692\n",
      "48    35.74692\n",
      "49    35.74692\n",
      "50    35.74692\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "46    -119.878883\n",
      "47    -119.878883\n",
      "48    -119.878883\n",
      "49    -119.878883\n",
      "50    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "46    -119.878883\n",
      "47    -119.878883\n",
      "48    -119.878883\n",
      "49    -119.878883\n",
      "50    -119.878883\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "46    \n",
      "47    \n",
      "48    \n",
      "49    \n",
      "50    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "46    \n",
      "47    \n",
      "48    \n",
      "49    \n",
      "50    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "46    Arco Substation\n",
      "47    Arco Substation\n",
      "48    Arco Substation\n",
      "49    Arco Substation\n",
      "50    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "46    Arco Substation\n",
      "47    Arco Substation\n",
      "48    Arco Substation\n",
      "49    Arco Substation\n",
      "50    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1739, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 3\n",
      "Length of original_rows: 3\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "51  1739       13               Full  35.370369  -120.828165            \n",
      "52  1739       13               Full  35.370369  -120.828165            \n",
      "53  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade               upgrade  \\\n",
      "51     Morro Bay Substation          PTO_IF  Morro Bay Substation   \n",
      "52     Morro Bay Substation          PTO_IF    Transmission Line:   \n",
      "53     Morro Bay Substation          PTO_IF      Generation Site:   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "51  Gen-Tie Line Terminal Equipment and Terminatio...                100.00%   \n",
      "52         Gen-Tie T-Line on PG&E Substation Property                100.00%   \n",
      "53  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "51                 4260.0                 4809.0                        53.0   \n",
      "52                 3670.0                 4143.0                        55.0   \n",
      "53                  475.0                  536.0                        16.0   \n",
      "\n",
      "   item  \n",
      "51  yes  \n",
      "52  yes  \n",
      "53  yes  \n",
      "original_rows:\n",
      "     q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "110  1739       13               Full  35.370369  -120.828165            \n",
      "111  1739       13               Full  35.370369  -120.828165            \n",
      "112  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade               upgrade  \\\n",
      "110     Morro Bay Substation          PTO_IF  Morro Bay Substation   \n",
      "111     Morro Bay Substation          PTO_IF    Transmission Line:   \n",
      "112     Morro Bay Substation          PTO_IF      Generation Site:   \n",
      "\n",
      "                                           description cost_allocation_factor  \\\n",
      "110  Gen-Tie Line Terminal Equipment and Terminatio...                100.00%   \n",
      "111         Gen-Tie T-Line on PG&E Substation Property                100.00%   \n",
      "112  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "     estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "110                 4260.0                 4906.0                        53.0   \n",
      "111                 3670.0                 4226.0                        55.0   \n",
      "112                  475.0                  547.0                        16.0   \n",
      "\n",
      "    item original  row_order  \n",
      "110  yes      yes        110  \n",
      "111  yes      yes        111  \n",
      "112  yes      yes        112  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "51    Full\n",
      "52    Full\n",
      "53    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "110    Full\n",
      "111    Full\n",
      "112    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "51    Full\n",
      "52    Full\n",
      "53    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "51    35.370369\n",
      "52    35.370369\n",
      "53    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "110    35.370369\n",
      "111    35.370369\n",
      "112    35.370369\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "51    35.370369\n",
      "52    35.370369\n",
      "53    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "51    -120.828165\n",
      "52    -120.828165\n",
      "53    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "110    -120.828165\n",
      "111    -120.828165\n",
      "112    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "51    -120.828165\n",
      "52    -120.828165\n",
      "53    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "51    \n",
      "52    \n",
      "53    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "110    \n",
      "111    \n",
      "112    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "51    \n",
      "52    \n",
      "53    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "51    Morro Bay Substation\n",
      "52    Morro Bay Substation\n",
      "53    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "110    Morro Bay Substation\n",
      "111    Morro Bay Substation\n",
      "112    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "51    Morro Bay Substation\n",
      "52    Morro Bay Substation\n",
      "53    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1739, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 5\n",
      "Length of original_rows: 5\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "54  1739       13               Full  35.370369  -120.828165            \n",
      "55  1739       13               Full  35.370369  -120.828165            \n",
      "56  1739       13               Full  35.370369  -120.828165            \n",
      "57  1739       13               Full  35.370369  -120.828165            \n",
      "58  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade  \\\n",
      "54     Morro Bay Substation             RNU   \n",
      "55     Morro Bay Substation             RNU   \n",
      "56     Morro Bay Substation             RNU   \n",
      "57     Morro Bay Substation             RNU   \n",
      "58     Morro Bay Substation             RNU   \n",
      "\n",
      "                                              upgrade  \\\n",
      "54                               Morro Bay Substation   \n",
      "55         Mesa Substation 115 kV CBs 142 overstress6   \n",
      "56  Midway Substation 230 kV bus and circuit break...   \n",
      "57  Midway Substation 500 kV CB 722 Overload over ...   \n",
      "58  PGAE-QC13P2RAS-04 Midway 500/230 kV Transforme...   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "54                               Install (1) DBSB Bay                100.00%   \n",
      "55  Replace Mesa Substation 115 kV CB 142 with 63 ...                 25.44%   \n",
      "56  Install series bus reactors between Midway Sub...                  8.46%   \n",
      "57  Replace Midway 500 kV CB 722 switches to achie...                 15.87%   \n",
      "58  PGAE-QC13P2RAS-04 Modify existing Midway 500/2...                 23.26%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "54                 1079.0                 1218.0                        53.0   \n",
      "55                  458.0                  527.0                        36.0   \n",
      "56                 1269.0                 1461.0                        72.0   \n",
      "57                   63.0                   73.0                        48.0   \n",
      "58                  814.0                  937.0                        36.0   \n",
      "\n",
      "   item  \n",
      "54  yes  \n",
      "55  yes  \n",
      "56  yes  \n",
      "57  yes  \n",
      "58  yes  \n",
      "original_rows:\n",
      "     q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "113  1739       13               Full  35.370369  -120.828165            \n",
      "114  1739       13               Full  35.370369  -120.828165            \n",
      "115  1739       13               Full  35.370369  -120.828165            \n",
      "116  1739       13               Full  35.370369  -120.828165            \n",
      "117  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade  \\\n",
      "113     Morro Bay Substation             RNU   \n",
      "114     Morro Bay Substation             RNU   \n",
      "115     Morro Bay Substation             RNU   \n",
      "116     Morro Bay Substation             RNU   \n",
      "117     Morro Bay Substation             RNU   \n",
      "\n",
      "                                               upgrade  \\\n",
      "113                               Morro Bay Substation   \n",
      "114         Mesa Substation 115 kV CBs 142 overstress6   \n",
      "115  Midway Substation 230 kV bus and circuit break...   \n",
      "116  Midway Substation 500 kV CB 722 Overload over ...   \n",
      "117  PGAE-QC13P2RAS-04 Midway 500/230 kV Transforme...   \n",
      "\n",
      "                                           description cost_allocation_factor  \\\n",
      "113                               Install (1) DBSB Bay                100.00%   \n",
      "114  Replace Mesa Substation 115 kV CB 142 with 63 ...                 25.44%   \n",
      "115  Install series bus reactors between Midway Sub...                  8.46%   \n",
      "116  Replace Midway 500 kV CB 722 switches to achie...                 15.87%   \n",
      "117  PGAE-QC13P2RAS-04 Modify existing Midway 500/2...                 23.26%   \n",
      "\n",
      "     estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "113                 1079.0                 1243.0                        53.0   \n",
      "114                  458.0                  527.0                        36.0   \n",
      "115                 1269.0                 1461.0                        72.0   \n",
      "116                   63.0                   73.0                        48.0   \n",
      "117                  814.0                  937.0                        36.0   \n",
      "\n",
      "    item original  row_order  \n",
      "113  yes      yes        113  \n",
      "114  yes      yes        114  \n",
      "115  yes      yes        115  \n",
      "116  yes      yes        116  \n",
      "117  yes      yes        117  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "54    Full\n",
      "55    Full\n",
      "56    Full\n",
      "57    Full\n",
      "58    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "113    Full\n",
      "114    Full\n",
      "115    Full\n",
      "116    Full\n",
      "117    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "54    Full\n",
      "55    Full\n",
      "56    Full\n",
      "57    Full\n",
      "58    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "54    35.370369\n",
      "55    35.370369\n",
      "56    35.370369\n",
      "57    35.370369\n",
      "58    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "113    35.370369\n",
      "114    35.370369\n",
      "115    35.370369\n",
      "116    35.370369\n",
      "117    35.370369\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "54    35.370369\n",
      "55    35.370369\n",
      "56    35.370369\n",
      "57    35.370369\n",
      "58    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "54    -120.828165\n",
      "55    -120.828165\n",
      "56    -120.828165\n",
      "57    -120.828165\n",
      "58    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "113    -120.828165\n",
      "114    -120.828165\n",
      "115    -120.828165\n",
      "116    -120.828165\n",
      "117    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "54    -120.828165\n",
      "55    -120.828165\n",
      "56    -120.828165\n",
      "57    -120.828165\n",
      "58    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "54    \n",
      "55    \n",
      "56    \n",
      "57    \n",
      "58    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "113    \n",
      "114    \n",
      "115    \n",
      "116    \n",
      "117    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "54    \n",
      "55    \n",
      "56    \n",
      "57    \n",
      "58    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "54    Morro Bay Substation\n",
      "55    Morro Bay Substation\n",
      "56    Morro Bay Substation\n",
      "57    Morro Bay Substation\n",
      "58    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "113    Morro Bay Substation\n",
      "114    Morro Bay Substation\n",
      "115    Morro Bay Substation\n",
      "116    Morro Bay Substation\n",
      "117    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "54    Morro Bay Substation\n",
      "55    Morro Bay Substation\n",
      "56    Morro Bay Substation\n",
      "57    Morro Bay Substation\n",
      "58    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1739, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 1\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "59  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "59     Morro Bay Substation            LDNU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "59                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "59                           0  yes  \n",
      "original_rows:\n",
      "     q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "118  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "118     Morro Bay Substation            LDNU    None        None   \n",
      "\n",
      "    cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "118                      0                    0.0                    0.0   \n",
      "\n",
      "    estimated_time_to_construct item original  row_order  \n",
      "118                           0  yes      yes        118  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "59    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "118    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "59    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "59    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "118    35.370369\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "59    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "59    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "118    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "59    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "59    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "118    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "59    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "59    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "118    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "59    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:119: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  original_rows = pd.concat([original_rows, extra_rows], ignore_index=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing itemized: q_id=1739, type_of_upgrade=LOPNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 1\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "60  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "60     Morro Bay Substation           LOPNU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "60                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "60                           0  yes  \n",
      "original_rows:\n",
      "     q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "119  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "119     Morro Bay Substation           LOPNU    None        None   \n",
      "\n",
      "    cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "119                      0                    0.0                    0.0   \n",
      "\n",
      "    estimated_time_to_construct item original  row_order  \n",
      "119                           0  yes      yes        119  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "60    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "119    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "60    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "60    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "119    35.370369\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "60    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "60    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "119    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "60    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "60    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "119    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "60    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "60    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "119    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "60    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1739, type_of_upgrade=CANU\n",
      "Length of addendum_rows: 2\n",
      "Length of original_rows: 2\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "61  1739       13               Full  35.370369  -120.828165            \n",
      "62  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade  \\\n",
      "61     Morro Bay Substation            CANU   \n",
      "62     Morro Bay Substation            CANU   \n",
      "\n",
      "                                              upgrade  \\\n",
      "61             Gates Substation 230 kV Bus Overstress   \n",
      "62  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "61  Install series bus reactors between Gates Subs...                 43.64%   \n",
      "62  Replace Midway 500 kV CB 722 to achieve 4000 A...                 15.87%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "61                 6110.0                 6628.0                        36.0   \n",
      "62                 1111.0                 1229.0                        48.0   \n",
      "\n",
      "   item  \n",
      "61  yes  \n",
      "62  yes  \n",
      "original_rows:\n",
      "     q_id  cluster req_deliverability   latitude    longitude capacity  \\\n",
      "120  1739       13               Full  35.370369  -120.828165            \n",
      "121  1739       13               Full  35.370369  -120.828165            \n",
      "\n",
      "    point_of_interconnection type_of_upgrade  \\\n",
      "120     Morro Bay Substation            CANU   \n",
      "121     Morro Bay Substation            CANU   \n",
      "\n",
      "                                               upgrade  \\\n",
      "120             Gates Substation 230 kV Bus Overstress   \n",
      "121  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                           description cost_allocation_factor  \\\n",
      "120  Install series bus reactors between Gates Subs...                 43.64%   \n",
      "121  Replace Midway 500 kV CB 722 to achieve 4000 A...                 15.87%   \n",
      "\n",
      "     estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "120                 6110.0                 6628.0                        36.0   \n",
      "121                 1111.0                 1229.0                        48.0   \n",
      "\n",
      "    item original  row_order  \n",
      "120  yes      yes        120  \n",
      "121  yes      yes        121  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "61    Full\n",
      "62    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "120    Full\n",
      "121    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "61    Full\n",
      "62    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "61    35.370369\n",
      "62    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "120    35.370369\n",
      "121    35.370369\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "61    35.370369\n",
      "62    35.370369\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "61    -120.828165\n",
      "62    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "120    -120.828165\n",
      "121    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "61    -120.828165\n",
      "62    -120.828165\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "61    \n",
      "62    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "120    \n",
      "121    \n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "61    \n",
      "62    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "61    Morro Bay Substation\n",
      "62    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "120    Morro Bay Substation\n",
      "121    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "61    Morro Bay Substation\n",
      "62    Morro Bay Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1740, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 3\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "63  1740       13               Full   35.785  -119.895            \n",
      "64  1740       13               Full   35.785  -119.895            \n",
      "65  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade             upgrade  \\\n",
      "63          Arco Substation          PTO_IF     Arco Substation   \n",
      "64          Arco Substation          PTO_IF  Transmission Line:   \n",
      "65          Arco Substation          PTO_IF    Generation Site:   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "63  Gen-Tie Line Terminal Equipment and Terminatio...                100.00%   \n",
      "64  Gen-Tie T-Line on PG&E Substation Property and...                100.00%   \n",
      "65  Engineering Reviews, Metering, Pre-parallel In...                100.00%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "63                 1310.0                 1449.0                        48.0   \n",
      "64                  890.0                  985.0                        41.0   \n",
      "65                  535.0                  592.0                        16.0   \n",
      "\n",
      "   item  \n",
      "63  yes  \n",
      "64  yes  \n",
      "65  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "63    Full\n",
      "64    Full\n",
      "65    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "63    Full\n",
      "64    Full\n",
      "65    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "63    35.785\n",
      "64    35.785\n",
      "65    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "63    35.785\n",
      "64    35.785\n",
      "65    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "63    -119.895\n",
      "64    -119.895\n",
      "65    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "63    -119.895\n",
      "64    -119.895\n",
      "65    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "63    \n",
      "64    \n",
      "65    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "63    \n",
      "64    \n",
      "65    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "63    Arco Substation\n",
      "64    Arco Substation\n",
      "65    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "63    Arco Substation\n",
      "64    Arco Substation\n",
      "65    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1740, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 5\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "66  1740       13               Full   35.785  -119.895            \n",
      "67  1740       13               Full   35.785  -119.895            \n",
      "68  1740       13               Full   35.785  -119.895            \n",
      "69  1740       13               Full   35.785  -119.895            \n",
      "70  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade  \\\n",
      "66          Arco Substation             RNU   \n",
      "67          Arco Substation             RNU   \n",
      "68          Arco Substation             RNU   \n",
      "69          Arco Substation             RNU   \n",
      "70          Arco Substation             RNU   \n",
      "\n",
      "                                              upgrade  \\\n",
      "66                                    Arco Substation   \n",
      "67                                    Arco Substation   \n",
      "68                                 Transmission Line:   \n",
      "69  Midway Substation 500 kV CB 722 Overload over ...   \n",
      "70  PGAE-QC13P2RAS-04 Midway 500/230 kV Transforme...   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "66  Install (3) 230kV CB 2512, 2522, & 2532 in new...                 50.00%   \n",
      "67  Install (3) 230kV CB 2512, 2522, & 2532 in new...                 50.00%   \n",
      "68  Relocate Line Switches from T- Line Structure ...                100.00%   \n",
      "69  Replace Midway 500 kV CB 722 switches to achie...                  3.17%   \n",
      "70  PGAE-QC13P2RAS-04 Modify existing Midway 500/2...                  4.65%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "66                 2946.0                 3259.0                        48.0   \n",
      "67                 2946.0                 3259.0                        48.0   \n",
      "68                  500.0                  553.0                        41.0   \n",
      "69                   13.0                   15.0                        48.0   \n",
      "70                  163.0                  187.0                        36.0   \n",
      "\n",
      "   item  \n",
      "66  yes  \n",
      "67  yes  \n",
      "68  yes  \n",
      "69  yes  \n",
      "70  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "66    Full\n",
      "67    Full\n",
      "68    Full\n",
      "69    Full\n",
      "70    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "66    Full\n",
      "67    Full\n",
      "68    Full\n",
      "69    Full\n",
      "70    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "66    35.785\n",
      "67    35.785\n",
      "68    35.785\n",
      "69    35.785\n",
      "70    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "66    35.785\n",
      "67    35.785\n",
      "68    35.785\n",
      "69    35.785\n",
      "70    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "66    -119.895\n",
      "67    -119.895\n",
      "68    -119.895\n",
      "69    -119.895\n",
      "70    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "66    -119.895\n",
      "67    -119.895\n",
      "68    -119.895\n",
      "69    -119.895\n",
      "70    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "66    \n",
      "67    \n",
      "68    \n",
      "69    \n",
      "70    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "66    \n",
      "67    \n",
      "68    \n",
      "69    \n",
      "70    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "66    Arco Substation\n",
      "67    Arco Substation\n",
      "68    Arco Substation\n",
      "69    Arco Substation\n",
      "70    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "66    Arco Substation\n",
      "67    Arco Substation\n",
      "68    Arco Substation\n",
      "69    Arco Substation\n",
      "70    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1740, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "71  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "71          Arco Substation            LDNU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "71                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "71                           0  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "71    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "71    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "71    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "71    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "71    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "71    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "71    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "71    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "71    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "71    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1740, type_of_upgrade=LOPNU\n",
      "Length of addendum_rows: 1\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "72  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "72          Arco Substation           LOPNU    None        None   \n",
      "\n",
      "   cost_allocation_factor  estimated_cost_x_1000  escalated_cost_x_1000  \\\n",
      "72                      0                    0.0                    0.0   \n",
      "\n",
      "   estimated_time_to_construct item  \n",
      "72                           0  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "72    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "72    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "72    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "72    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "72    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "72    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "72    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "72    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "72    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "72    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1740, type_of_upgrade=CANU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 0\n",
      "addendum_rows:\n",
      "    q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "73  1740       13               Full   35.785  -119.895            \n",
      "74  1740       13               Full   35.785  -119.895            \n",
      "75  1740       13               Full   35.785  -119.895            \n",
      "76  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "   point_of_interconnection type_of_upgrade  \\\n",
      "73          Arco Substation            CANU   \n",
      "74          Arco Substation            CANU   \n",
      "75          Arco Substation            CANU   \n",
      "76          Arco Substation            CANU   \n",
      "\n",
      "                                              upgrade  \\\n",
      "73                                    Arco Substation   \n",
      "74                                   Gates Substation   \n",
      "75                                  Midway Substation   \n",
      "76  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                          description cost_allocation_factor  \\\n",
      "73  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "74            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "75              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "76  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "    estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "73                11270.0                12469.0                        48.0   \n",
      "74                  193.0                  214.0                        48.0   \n",
      "75                  695.0                  769.0                        48.0   \n",
      "76                  222.0                  246.0                        48.0   \n",
      "\n",
      "   item  \n",
      "73  yes  \n",
      "74  yes  \n",
      "75  yes  \n",
      "76  yes  \n",
      "original_rows:\n",
      "Empty DataFrame\n",
      "Columns: [q_id, cluster, req_deliverability, latitude, longitude, capacity, point_of_interconnection, type_of_upgrade, upgrade, description, cost_allocation_factor, estimated_cost_x_1000, escalated_cost_x_1000, estimated_time_to_construct, item, original, row_order]\n",
      "Index: []\n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "73    Full\n",
      "74    Full\n",
      "75    Full\n",
      "76    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "Series([], Name: req_deliverability, dtype: object)\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "73    Full\n",
      "74    Full\n",
      "75    Full\n",
      "76    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "73    35.785\n",
      "74    35.785\n",
      "75    35.785\n",
      "76    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: latitude, dtype: object)\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "73    35.785\n",
      "74    35.785\n",
      "75    35.785\n",
      "76    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "73    -119.895\n",
      "74    -119.895\n",
      "75    -119.895\n",
      "76    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "Series([], Name: longitude, dtype: object)\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "73    -119.895\n",
      "74    -119.895\n",
      "75    -119.895\n",
      "76    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "73    \n",
      "74    \n",
      "75    \n",
      "76    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "Series([], Name: capacity, dtype: object)\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "73    \n",
      "74    \n",
      "75    \n",
      "76    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "73    Arco Substation\n",
      "74    Arco Substation\n",
      "75    Arco Substation\n",
      "76    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "Series([], Name: point_of_interconnection, dtype: object)\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "73    Arco Substation\n",
      "74    Arco Substation\n",
      "75    Arco Substation\n",
      "76    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1688, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1688, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1688, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1688, type_of_upgrade=LOPNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1688, type_of_upgrade=CANU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=LOPNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1691, type_of_upgrade=CANU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=RNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=LDNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=LOPNU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1713, type_of_upgrade=CANU\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Processing itemized: q_id=1718, type_of_upgrade=PTO_IF\n",
      "Length of addendum_rows: 4\n",
      "Length of original_rows: 4\n",
      "addendum_rows:\n",
      "   q_id  cluster req_deliverability latitude longitude capacity  \\\n",
      "0  1740       13               Full   35.785  -119.895            \n",
      "1  1740       13               Full   35.785  -119.895            \n",
      "2  1740       13               Full   35.785  -119.895            \n",
      "3  1740       13               Full   35.785  -119.895            \n",
      "\n",
      "  point_of_interconnection type_of_upgrade  \\\n",
      "0          Arco Substation            CANU   \n",
      "1          Arco Substation            CANU   \n",
      "2          Arco Substation            CANU   \n",
      "3          Arco Substation            CANU   \n",
      "\n",
      "                                             upgrade  \\\n",
      "0                                    Arco Substation   \n",
      "1                                   Gates Substation   \n",
      "2                                  Midway Substation   \n",
      "3  Midway Substation 500kV CB 722 Overload mitiga...   \n",
      "\n",
      "                                         description cost_allocation_factor  \\\n",
      "0  Install Ctrl Bldg w/ Relays By Q1586/Q1587  In...                100.00%   \n",
      "1            Line Relay Modifications By Q1586/Q1587                100.00%   \n",
      "2              Line Relay Replacement By Q1586/Q1587                100.00%   \n",
      "3  Replace Midway 500 kV CB 722 to achieve 4000 A...                  3.17%   \n",
      "\n",
      "   estimated_cost_x_1000  escalated_cost_x_1000 estimated_time_to_construct  \\\n",
      "0                11270.0                12469.0                        48.0   \n",
      "1                  193.0                  214.0                        48.0   \n",
      "2                  695.0                  769.0                        48.0   \n",
      "3                  222.0                  246.0                        48.0   \n",
      "\n",
      "  item  row_order  \n",
      "0  yes          0  \n",
      "1  yes          0  \n",
      "2  yes          0  \n",
      "3  yes          0  \n",
      "original_rows:\n",
      "   q_id cluster req_deliverability latitude longitude capacity  \\\n",
      "0  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "1  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "2  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "3  <NA>    <NA>                NaN      NaN       NaN      NaN   \n",
      "\n",
      "  point_of_interconnection type_of_upgrade upgrade description  \\\n",
      "0                      NaN             NaN     NaN         NaN   \n",
      "1                      NaN             NaN     NaN         NaN   \n",
      "2                      NaN             NaN     NaN         NaN   \n",
      "3                      NaN             NaN     NaN         NaN   \n",
      "\n",
      "  cost_allocation_factor estimated_cost_x_1000 escalated_cost_x_1000  \\\n",
      "0                    NaN                   NaN                   NaN   \n",
      "1                    NaN                   NaN                   NaN   \n",
      "2                    NaN                   NaN                   NaN   \n",
      "3                    NaN                   NaN                   NaN   \n",
      "\n",
      "  estimated_time_to_construct item original row_order  \n",
      "0                         NaN  NaN      NaN      <NA>  \n",
      "1                         NaN  NaN      NaN      <NA>  \n",
      "2                         NaN  NaN      NaN      <NA>  \n",
      "3                         NaN  NaN      NaN      <NA>  \n",
      "Before replacement: req_deliverability\n",
      "Addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: req_deliverability, dtype: object\n",
      "After replacement: req_deliverability\n",
      "Updated addendum values:\n",
      "0    Full\n",
      "1    Full\n",
      "2    Full\n",
      "3    Full\n",
      "Name: req_deliverability, dtype: object\n",
      "Before replacement: latitude\n",
      "Addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: latitude, dtype: object\n",
      "After replacement: latitude\n",
      "Updated addendum values:\n",
      "0    35.785\n",
      "1    35.785\n",
      "2    35.785\n",
      "3    35.785\n",
      "Name: latitude, dtype: object\n",
      "Before replacement: longitude\n",
      "Addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: longitude, dtype: object\n",
      "After replacement: longitude\n",
      "Updated addendum values:\n",
      "0    -119.895\n",
      "1    -119.895\n",
      "2    -119.895\n",
      "3    -119.895\n",
      "Name: longitude, dtype: object\n",
      "Before replacement: capacity\n",
      "Addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: capacity, dtype: object\n",
      "After replacement: capacity\n",
      "Updated addendum values:\n",
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "Name: capacity, dtype: object\n",
      "Before replacement: point_of_interconnection\n",
      "Addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n",
      "Original values:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "Name: point_of_interconnection, dtype: object\n",
      "After replacement: point_of_interconnection\n",
      "Updated addendum values:\n",
      "0    Arco Substation\n",
      "1    Arco Substation\n",
      "2    Arco Substation\n",
      "3    Arco Substation\n",
      "Name: point_of_interconnection, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_95588/92317565.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addendum_row[col] = 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 254\u001b[0m\n\u001b[1;32m    250\u001b[0m total \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_total.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, char_columns)\n\u001b[1;32m    251\u001b[0m total_addendums \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_total_addendums.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, char_columns)\n\u001b[0;32m--> 254\u001b[0m updated_itemized, updated_total \u001b[38;5;241m=\u001b[39m merge_with_addendums(itemized, itemized_addendums, total, total_addendums)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Drop the specified columns from the updated datasets\u001b[39;00m\n\u001b[1;32m    257\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupgrade_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimated\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaiso_queue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdependent_system_upgrade\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[2], line 191\u001b[0m, in \u001b[0;36mmerge_with_addendums\u001b[0;34m(itemized, itemized_addendums, total, total_addendums)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 addendum_row[col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[1;32m    190\u001b[0m             total\u001b[38;5;241m.\u001b[39mloc[mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 191\u001b[0m             updated_total_rows\u001b[38;5;241m.\u001b[39mappend(addendum_row\u001b[38;5;241m.\u001b[39massign(original\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m, row_order\u001b[38;5;241m=\u001b[39moriginal_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_order\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[:\u001b[38;5;28mlen\u001b[39m(addendum_row)]))\n\u001b[1;32m    192\u001b[0m             total \u001b[38;5;241m=\u001b[39m total[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m updated_total_rows:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:5239\u001b[0m, in \u001b[0;36mDataFrame.assign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   5236\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   5238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 5239\u001b[0m     data[k] \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(v, data)\n\u001b[1;32m   5240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m     ):\n\u001b[1;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (0) does not match length of index (1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path, char_columns):\n",
    "    \"\"\"\n",
    "    Load a CSV file and ensure specific columns are treated as character, others as numeric.\n",
    "    \"\"\"\n",
    " # Get columns available in the dataset\n",
    "    available_columns = pd.read_csv(file_path, nrows=0).columns\n",
    "    \n",
    "    # Restrict to char_columns that are present in the dataset\n",
    "    char_columns_in_dataset = [col for col in char_columns if col in available_columns]\n",
    "    \n",
    "    # Load the dataset, treating char_columns_in_dataset as strings\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        dtype={col: str for col in char_columns_in_dataset},\n",
    "        na_values=[],  # Disable automatic NaN interpretation\n",
    "        keep_default_na=False  # Prevent treating \"None\" as NaN\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Convert all other columns to numeric\n",
    "    #for col in df.columns:\n",
    "    #    if col not in char_columns:\n",
    "    #        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_data(df, file_path, char_columns):\n",
    "    \"\"\"\n",
    "    Save a dataframe to a CSV file, ensuring specific columns are treated as character.\n",
    "    \"\"\"\n",
    "    for col in char_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def merge_with_addendums(itemized, itemized_addendums, total, total_addendums):\n",
    "    # Add an 'original' column to the datasets\n",
    "    itemized['original'] = \"yes\"\n",
    "    total['original'] = \"yes\"\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Preserve the original row order\n",
    "    itemized['row_order'] = pd.to_numeric(itemized.index, errors=\"coerce\")\n",
    "    total['row_order'] = pd.to_numeric(total.index, errors=\"coerce\")\n",
    "    \n",
    "    # Ensure q_id is numeric for comparison\n",
    "    itemized['q_id'] = pd.to_numeric(itemized['q_id'], errors=\"coerce\")\n",
    "    itemized_addendums['q_id'] = pd.to_numeric(itemized_addendums['q_id'], errors=\"coerce\")\n",
    "    total['q_id'] = pd.to_numeric(total['q_id'], errors=\"coerce\")\n",
    "    total_addendums['q_id'] = pd.to_numeric(total_addendums['q_id'], errors=\"coerce\")\n",
    "\n",
    "\n",
    "    \n",
    "    # Columns for conditional replacement\n",
    "    conditional_columns = [\"req_deliverability\", \"latitude\", \"longitude\", \"capacity\", \"point_of_interconnection\"]\n",
    "    \n",
    "    # Prepare a list to collect the updated itemized rows\n",
    "    updated_itemized_rows = []\n",
    "    \n",
    "    # Merge itemized and itemized_addendums\n",
    "    for q_id in itemized_addendums['q_id'].unique():\n",
    "        for upgrade_type in itemized_addendums['type_of_upgrade'].unique():\n",
    "            addendum_rows = itemized_addendums[\n",
    "                (itemized_addendums['q_id'] == q_id) &\n",
    "                (itemized_addendums['type_of_upgrade'] == upgrade_type)\n",
    "            ]\n",
    "            if not addendum_rows.empty:\n",
    "                mask = (itemized['q_id'] == q_id) & (itemized['type_of_upgrade'] == upgrade_type)\n",
    "                original_rows = itemized[mask]\n",
    "                print(f\"Processing itemized: q_id={q_id}, type_of_upgrade={upgrade_type}\")\n",
    "                print(f\"Length of addendum_rows: {len(addendum_rows)}\")\n",
    "                print(f\"Length of original_rows: {len(original_rows)}\")\n",
    "                print(f\"addendum_rows:\\n{addendum_rows}\")\n",
    "                print(f\"original_rows:\\n{original_rows}\")\n",
    "\n",
    "                # For specified columns, replace only if addendum values are non-empty\n",
    "                for col in conditional_columns:\n",
    "                    if col in addendum_rows.columns and col in original_rows.columns:\n",
    "                        # Debugging outputs\n",
    "                        print(f\"Before replacement: {col}\")\n",
    "                        print(f\"Addendum values:\\n{addendum_rows[col]}\")\n",
    "                        print(f\"Original values:\\n{original_rows[col]}\")\n",
    "\n",
    "                        # Replace blanks with NaN in addendum\n",
    "                        addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
    "\n",
    "                        # Combine values: prefer addendum if not NaN, else take original\n",
    "                        addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
    "\n",
    "                        # Replace NaN back with blank string for consistency\n",
    "                        addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
    "\n",
    "                        print(f\"After replacement: {col}\")\n",
    "                        print(f\"Updated addendum values:\\n{addendum_rows[col]}\")\n",
    "\n",
    "                # Match row_order with addendum_rows length\n",
    "                # Adjust lengths by truncating the longer one\n",
    "                '''\n",
    "                if len(addendum_rows) > len(original_rows):\n",
    "                    addendum_rows = addendum_rows.iloc[:len(original_rows)]\n",
    "                elif len(addendum_rows) < len(original_rows):\n",
    "                    original_rows = original_rows.iloc[:len(addendum_rows)]\n",
    "                '''\n",
    "\n",
    "                # Align the length of original_rows to addendum_rows\n",
    "                original_rows = original_rows.reset_index(drop=True)\n",
    "                addendum_rows = addendum_rows.reset_index(drop=True)\n",
    "                \n",
    "                if len(addendum_rows) > len(original_rows):\n",
    "                    # Pad original_rows\n",
    "                    extra_rows = pd.DataFrame({col: pd.NA for col in original_rows.columns}, index=range(len(addendum_rows) - len(original_rows)))\n",
    "                    original_rows = pd.concat([original_rows, extra_rows], ignore_index=True)\n",
    "                elif len(addendum_rows) < len(original_rows):\n",
    "                    # Truncate original_rows\n",
    "                    original_rows = original_rows.iloc[:len(addendum_rows)].reset_index(drop=True)\n",
    "                \n",
    "\n",
    "                     \n",
    "                \n",
    "                # Find non-character columns missing in the addendum dataset\n",
    "                missing_cols = set(itemized.columns) - set(addendum_rows.columns) - set(char_columns)\n",
    "                for col in missing_cols:\n",
    "                    addendum_rows[col] = 0 \n",
    "                itemized.loc[mask, 'original'] = \"no\"\n",
    "                updated_itemized_rows.append(addendum_rows.assign(original=\"no\", row_order=original_rows['row_order'].values[:len(addendum_rows)]))\n",
    "                itemized = itemized[~mask]\n",
    "    \n",
    "    if updated_itemized_rows:\n",
    "        updated_itemized = pd.concat([itemized] + updated_itemized_rows, ignore_index=True)\n",
    "    else:\n",
    "        updated_itemized = itemized.copy()\n",
    "    \n",
    "\n",
    "    updated_itemized[\"row_order\"] = pd.to_numeric(updated_itemized[\"row_order\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    updated_itemized = updated_itemized.sort_values(by=\"row_order\").drop(columns=[\"row_order\"]).reset_index(drop=True)\n",
    "    \n",
    "    updated_total_rows = []\n",
    "    \n",
    "    for q_id in total_addendums['q_id'].unique():\n",
    "        for upgrade_type in total_addendums['type_of_upgrade'].unique():\n",
    "            addendum_row = total_addendums[\n",
    "                (total_addendums['q_id'] == q_id) &\n",
    "                (total_addendums['type_of_upgrade'] == upgrade_type)\n",
    "            ]\n",
    "            if not addendum_row.empty:\n",
    "                mask = (total['q_id'] == q_id) & (total['type_of_upgrade'] == upgrade_type)\n",
    "                original_row = total[mask]\n",
    "                print(f\"Processing itemized: q_id={q_id}, type_of_upgrade={upgrade_type}\")\n",
    "                print(f\"Length of addendum_rows: {len(addendum_rows)}\")\n",
    "                print(f\"Length of original_rows: {len(original_rows)}\")\n",
    "                print(f\"addendum_rows:\\n{addendum_rows}\")\n",
    "                print(f\"original_rows:\\n{original_rows}\")\n",
    "\n",
    "                # For specified columns, replace only if addendum values are non-empty\n",
    "                for col in conditional_columns:\n",
    "                    if col in addendum_rows.columns and col in original_rows.columns:\n",
    "                        # Debugging outputs\n",
    "                        print(f\"Before replacement: {col}\")\n",
    "                        print(f\"Addendum values:\\n{addendum_rows[col]}\")\n",
    "                        print(f\"Original values:\\n{original_rows[col]}\")\n",
    "\n",
    "                        # Replace blanks with NaN in addendum\n",
    "                        addendum_rows[col] = addendum_rows[col].replace(\"\", pd.NA)\n",
    "\n",
    "                        # Combine values: prefer addendum if not NaN, else take original\n",
    "                        addendum_rows[col] = addendum_rows[col].combine_first(original_rows[col].reset_index(drop=True))\n",
    "\n",
    "                        # Replace NaN back with blank string for consistency\n",
    "                        addendum_rows[col] = addendum_rows[col].fillna(\"\")\n",
    "\n",
    "                        print(f\"After replacement: {col}\")\n",
    "                        print(f\"Updated addendum values:\\n{addendum_rows[col]}\")\n",
    "\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        \n",
    "                \n",
    "                # Find non-character columns missing in the addendum dataset\n",
    "                missing_cols = set(total.columns) - set(addendum_row.columns) - set(char_columns)\n",
    "                for col in missing_cols:\n",
    "                    addendum_row[col] = 0 \n",
    "                total.loc[mask, 'original'] = \"no\"\n",
    "                updated_total_rows.append(addendum_row.assign(original=\"no\", row_order=original_row['row_order'].values[:len(addendum_row)]))\n",
    "                total = total[~mask]\n",
    "    \n",
    "    if updated_total_rows:\n",
    "        updated_total = pd.concat([total] + updated_total_rows, ignore_index=True)\n",
    "    else:\n",
    "        updated_total = total.copy()\n",
    "    \n",
    "     \n",
    "    \n",
    "\n",
    "    updated_total[\"row_order\"] = pd.to_numeric(updated_total[\"row_order\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    updated_total = updated_total.sort_values(by=\"row_order\").drop(columns=[\"row_order\"]).reset_index(drop=True)\n",
    "    # Fill missing columns with zeros in the updated datasets\n",
    "    for col in set(itemized.columns) - set(updated_itemized.columns):\n",
    "        updated_itemized[col] = 0\n",
    "    \n",
    "    for col in set(total.columns) - set(updated_total.columns):\n",
    "        updated_total[col] = 0\n",
    "\n",
    "    # Move the 'original' column to the last position\n",
    "    updated_itemized = updated_itemized[[col for col in updated_itemized.columns if col != 'original'] + ['original']]\n",
    "    updated_total = updated_total[[col for col in updated_total.columns if col != 'original'] + ['original']]\n",
    "\n",
    "     \n",
    "\n",
    "    \n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "        # Drop the row_order column directly\n",
    "    if \"row_order\" in updated_itemized.columns:\n",
    "        updated_itemized = updated_itemized.drop(columns=[\"row_order\"]).reset_index(drop=True)\n",
    "\n",
    "    if \"row_order\" in updated_total.columns:\n",
    "        updated_total = updated_total.drop(columns=[\"row_order\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "  \n",
    " \n",
    "    \n",
    "    \n",
    "    return updated_itemized, updated_total\n",
    "\n",
    "# Define the character columns\n",
    "char_columns = [\n",
    "    \"req_deliverability\", \"point_of_interconnection\", \"type_of_upgrade\",\n",
    "    \"upgrade\", \"description\", \"estimated_time_to_construct\", \"original\", \"item\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "itemized = load_data(\"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_itemized.csv\", char_columns)\n",
    "itemized_addendums = load_data(\"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_itemized_addendums.csv\", char_columns)\n",
    "total = load_data(\"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_total.csv\", char_columns)\n",
    "total_addendums = load_data(\"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate/costs_phase_2_cluster_13_style_Q_total_addendums.csv\", char_columns)\n",
    "\n",
    "\n",
    "updated_itemized, updated_total = merge_with_addendums(itemized, itemized_addendums, total, total_addendums)\n",
    "\n",
    "# Drop the specified columns from the updated datasets\n",
    "columns_to_drop = [ \"upgrade_classification\",\"estimated\", \"caiso_queue\", \"project_type\", \"dependent_system_upgrade\"]\n",
    "\n",
    "# For the itemized dataset\n",
    "updated_itemized = updated_itemized.drop(columns=[col for col in columns_to_drop if col in updated_itemized.columns], errors='ignore')\n",
    "\n",
    "# For the total dataset\n",
    "updated_total = updated_total.drop(columns=[col for col in columns_to_drop if col in updated_total.columns], errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "# List of columns to process with ffill and bfill\n",
    "columns_to_fill = [\"point_of_interconnection\", \"latitude\", \"longitude\", \"req_deliverability\", \"capacity\"]\n",
    "\n",
    "# Replace empty strings with NaN for the specified columns\n",
    "for col in columns_to_fill:\n",
    "    updated_itemized[col] = updated_itemized[col].replace('', np.nan)\n",
    "    updated_total[col] = updated_total[col].replace('', np.nan)\n",
    "\n",
    "# Sort by q_id while maintaining other column order (stable sorting)\n",
    "updated_itemized = updated_itemized.sort_values(by=[\"q_id\"], kind=\"stable\").reset_index(drop=True)\n",
    "updated_total = updated_total.sort_values(by=[\"q_id\"], kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "# Apply forward-fill and backward-fill for the specified columns within each q_id group\n",
    "for col in columns_to_fill:\n",
    "    updated_itemized[col] = (\n",
    "        updated_itemized.groupby(\"q_id\")[col]\n",
    "        .apply(lambda group: group.ffill().bfill())\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    updated_total[col] = (\n",
    "        updated_total.groupby(\"q_id\")[col]\n",
    "        .apply(lambda group: group.ffill().bfill())\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# Replace NaN back with empty strings for consistency\n",
    "for col in columns_to_fill:\n",
    "    updated_itemized[col] = updated_itemized[col].replace(np.nan, '')\n",
    "    updated_total[col] = updated_total[col].replace(np.nan, '')\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the updated datasets\n",
    "save_data(updated_itemized, \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_itemized_updated.csv\", char_columns)\n",
    "save_data(updated_total, \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_total_updated.csv\", char_columns)\n",
    "\n",
    "\n",
    "\n",
    "# Save the results\n",
    "save_data(updated_itemized, \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_itemized_updated.csv\", char_columns)\n",
    "save_data(updated_total, \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_total_updated.csv\", char_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → /Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_itemized_updated.csv\n",
      "Saved → /Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_total_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) I/O helpers\n",
    "# -------------------------------------------------------------------\n",
    "def load_data(file_path, char_columns):\n",
    "    \"\"\"\n",
    "    Load a CSV file and ensure specific columns are treated as character.\n",
    "    \"\"\"\n",
    "    # Read only header to get available columns\n",
    "    available = pd.read_csv(file_path, nrows=0).columns\n",
    "    # Only enforce dtype for those char_columns present\n",
    "    dtypes = {c: str for c in char_columns if c in available}\n",
    "    return pd.read_csv(\n",
    "        file_path,\n",
    "        dtype=dtypes,\n",
    "        na_values=[],            # don’t auto‑convert blanks to NaN\n",
    "        keep_default_na=False\n",
    "    )\n",
    "\n",
    "def save_data(df, file_path, char_columns):\n",
    "    \"\"\"\n",
    "    Save df to CSV, casting char_columns back to strings.\n",
    "    \"\"\"\n",
    "    for c in char_columns:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Saved → {file_path}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Merge logic\n",
    "# -------------------------------------------------------------------\n",
    "def merge_with_addendums(orig, add, on=[\"q_id\",\"type_of_upgrade\"]):\n",
    "    \"\"\"\n",
    "    For any group defined by `on` columns, if it appears in `add`, drop it from `orig`\n",
    "    and then concatenate all of `add`.  Otherwise keep orig.\n",
    "    \"\"\"\n",
    "    add_idx = add.set_index(on).index\n",
    "    orig_idxed = orig.set_index(on, drop=False)\n",
    "    mask = ~orig_idxed.index.isin(add_idx)\n",
    "    orig_kept = orig_idxed[mask].reset_index(drop=True)\n",
    "    merged = pd.concat([orig_kept, add], ignore_index=True, sort=False)\n",
    "    return merged.sort_values(by=on, kind=\"stable\").reset_index(drop=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) Main\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # character columns you never want auto‑converted\n",
    "    char_columns = [\n",
    "        \"req_deliverability\",\n",
    "        \"point_of_interconnection\",\n",
    "        \"type_of_upgrade\",\n",
    "        \"upgrade\",\n",
    "        \"description\",\n",
    "        \"estimated_time_to_construct\",\n",
    "        \"original\",\n",
    "        \"item\"\n",
    "    ]\n",
    "\n",
    "    # file‑paths (Cluster 13, Style Q)\n",
    "    BASE = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/02_intermediate\"\n",
    "    ITEM    = f\"{BASE}/costs_phase_2_cluster_13_style_Q_itemized.csv\"\n",
    "    ITEM_AD = f\"{BASE}/costs_phase_2_cluster_13_style_Q_itemized_addendums.csv\"\n",
    "    TOT     = f\"{BASE}/costs_phase_2_cluster_13_style_Q_total.csv\"\n",
    "    TOT_AD  = f\"{BASE}/costs_phase_2_cluster_13_style_Q_total_addendums.csv\"\n",
    "\n",
    "    CLEAN_BASE = \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean\"\n",
    "    ITEM_OUT = f\"{CLEAN_BASE}/costs_phase_2_cluster_13_style_Q_itemized_updated.csv\"\n",
    "    TOT_OUT  = f\"{CLEAN_BASE}/costs_phase_2_cluster_13_style_Q_total_updated.csv\"\n",
    "\n",
    "    # load\n",
    "    itemized           = load_data(ITEM,    char_columns)\n",
    "    itemized_addendums = load_data(ITEM_AD, char_columns)\n",
    "    total              = load_data(TOT,     char_columns)\n",
    "    total_addendums    = load_data(TOT_AD,  char_columns)\n",
    "\n",
    "    # merge\n",
    "    updated_itemized = merge_with_addendums(itemized,           itemized_addendums)\n",
    "    updated_total    = merge_with_addendums(total,              total_addendums)\n",
    "\n",
    "    # save\n",
    "    save_data(updated_itemized, ITEM_OUT, char_columns)\n",
    "    save_data(updated_total,    TOT_OUT,  char_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:71: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  updated_itemized['row_order'] = updated_itemized['row_order'].fillna(-1).astype(int)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  orig = pd.concat([orig, extra], ignore_index=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:119: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  updated_total['row_order'] = updated_total['row_order'].fillna(-1).astype(int)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:190: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[c] = df[c].replace('', np.nan)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:194: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[c] = df.groupby('q_id')[c].apply(lambda g: g.ffill().bfill()).reset_index(drop=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:194: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[c] = df.groupby('q_id')[c].apply(lambda g: g.ffill().bfill()).reset_index(drop=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:194: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[c] = df.groupby('q_id')[c].apply(lambda g: g.ffill().bfill()).reset_index(drop=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:196: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].replace(np.nan, '', inplace=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:190: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[c] = df[c].replace('', np.nan)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:194: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[c] = df.groupby('q_id')[c].apply(lambda g: g.ffill().bfill()).reset_index(drop=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:194: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[c] = df.groupby('q_id')[c].apply(lambda g: g.ffill().bfill()).reset_index(drop=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:194: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[c] = df.groupby('q_id')[c].apply(lambda g: g.ffill().bfill()).reset_index(drop=True)\n",
      "/var/folders/l5/3g5pj1nj2j108yb2yjngfmcmcmdwpt/T/ipykernel_61751/2960078519.py:196: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].replace(np.nan, '', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path, char_columns):\n",
    "    \"\"\"\n",
    "    Load a CSV file and ensure specific columns are treated as character.\n",
    "    \"\"\"\n",
    "    available_columns = pd.read_csv(file_path, nrows=0).columns\n",
    "    char_cols = [c for c in char_columns if c in available_columns]\n",
    "    return pd.read_csv(\n",
    "        file_path,\n",
    "        dtype={c: str for c in char_cols},\n",
    "        na_values=[], \n",
    "        keep_default_na=False\n",
    "    )\n",
    "\n",
    "def save_data(df, file_path, char_columns):\n",
    "    \"\"\"\n",
    "    Save a dataframe to CSV, forcing certain columns to string.\n",
    "    \"\"\"\n",
    "    for col in char_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def merge_with_addendums(itemized, itemized_addendums, total, total_addendums):\n",
    "    # mark originals & keep row order\n",
    "    itemized['original'] = \"yes\"\n",
    "    total['original']    = \"yes\"\n",
    "    itemized['row_order'] = itemized.index\n",
    "    total['row_order']    = total.index\n",
    "\n",
    "    # ensure numeric q_id\n",
    "    for df in (itemized, itemized_addendums, total, total_addendums):\n",
    "        df['q_id'] = pd.to_numeric(df['q_id'], errors=\"coerce\")\n",
    "\n",
    "    conditional_columns = [\n",
    "        \"req_deliverability\",\"latitude\",\"longitude\",\n",
    "        \"capacity\",\"point_of_interconnection\"\n",
    "    ]\n",
    "\n",
    "    # --- ITEMIZED: replace all rows by q_id ---\n",
    "    updated_itemized_rows = []\n",
    "    for q in itemized_addendums['q_id'].unique():\n",
    "        adds = itemized_addendums[itemized_addendums['q_id']==q].reset_index(drop=True)\n",
    "        orig = itemized[itemized['q_id']==q].reset_index(drop=True)\n",
    "\n",
    "        if not orig.empty:\n",
    "            # combine conditional columns\n",
    "            for col in conditional_columns:\n",
    "                if col in adds.columns and col in orig.columns:\n",
    "                    adds[col] = (\n",
    "                        adds[col].replace(\"\", pd.NA)\n",
    "                                .combine_first(orig[col])\n",
    "                                .fillna(\"\")\n",
    "                    )\n",
    "            ro = orig['row_order'].tolist()\n",
    "            # pad if addendum has more rows\n",
    "            if len(ro) < len(adds):\n",
    "                ro += [pd.NA] * (len(adds) - len(ro))\n",
    "        else:\n",
    "            ro = [pd.NA] * len(adds)\n",
    "\n",
    "        adds = adds.assign(original=\"no\", row_order=ro[:len(adds)])\n",
    "        # drop original q_id rows\n",
    "        itemized = itemized[itemized['q_id'] != q]\n",
    "        updated_itemized_rows.append(adds)\n",
    "\n",
    "    updated_itemized = pd.concat([itemized] + updated_itemized_rows, ignore_index=True) \\\n",
    "                        if updated_itemized_rows else itemized.copy()\n",
    "    updated_itemized['row_order'] = updated_itemized['row_order'].fillna(-1).astype(int)\n",
    "    updated_itemized = (\n",
    "        updated_itemized\n",
    "        .sort_values('row_order')\n",
    "        .drop(columns='row_order')\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # --- TOTAL: per type_of_upgrade (unchanged logic) ---\n",
    "    updated_total_rows = []\n",
    "    for q in total_addendums['q_id'].unique():\n",
    "        for t in total_addendums['type_of_upgrade'].unique():\n",
    "            adds = total_addendums[\n",
    "                (total_addendums['q_id']==q)&\n",
    "                (total_addendums['type_of_upgrade']==t)\n",
    "            ].reset_index(drop=True)\n",
    "            if adds.empty:\n",
    "                continue\n",
    "\n",
    "            mask = (total['q_id']==q)&(total['type_of_upgrade']==t)\n",
    "            orig = total[mask].reset_index(drop=True)\n",
    "            if orig.empty:\n",
    "                orig = pd.DataFrame({'row_order':[pd.NA]*len(adds)}, index=adds.index)\n",
    "\n",
    "            # align lengths\n",
    "            if len(adds) > len(orig):\n",
    "                extra = pd.DataFrame({c: pd.NA for c in orig.columns},\n",
    "                                     index=range(len(adds)-len(orig)))\n",
    "                orig = pd.concat([orig, extra], ignore_index=True)\n",
    "            elif len(adds) < len(orig):\n",
    "                orig = orig.iloc[:len(adds)].reset_index(drop=True)\n",
    "\n",
    "            for col in conditional_columns:\n",
    "                if col in adds.columns and col in orig.columns:\n",
    "                    adds[col] = (\n",
    "                        adds[col].replace(\"\", pd.NA)\n",
    "                                  .combine_first(orig[col])\n",
    "                                  .fillna(\"\")\n",
    "                    )\n",
    "\n",
    "            total.loc[mask, 'original'] = \"no\"\n",
    "            updated_total_rows.append(\n",
    "                adds.assign(original=\"no\", row_order=orig['row_order'].tolist()[:len(adds)])\n",
    "            )\n",
    "            total = total[~mask]\n",
    "\n",
    "    updated_total = pd.concat([total] + updated_total_rows, ignore_index=True) \\\n",
    "                    if updated_total_rows else total.copy()\n",
    "    updated_total['row_order'] = updated_total['row_order'].fillna(-1).astype(int)\n",
    "    updated_total = (\n",
    "        updated_total\n",
    "        .sort_values('row_order')\n",
    "        .drop(columns='row_order')\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # move 'original' to end\n",
    "    def move_last(df):\n",
    "        cols = [c for c in df.columns if c!='original'] + ['original']\n",
    "        return df[cols]\n",
    "\n",
    "    return move_last(updated_itemized), move_last(updated_total)\n",
    "\n",
    "\n",
    "# ── main script ──\n",
    "\n",
    "char_columns = [\n",
    "    \"req_deliverability\",\"point_of_interconnection\",\"type_of_upgrade\",\n",
    "    \"upgrade\",\"description\",\"estimated_time_to_construct\",\"original\",\"item\"\n",
    "]\n",
    "\n",
    "itemized = load_data(\n",
    "    \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/\"\n",
    "    \"04_intermediate_scraped_data/phase_2_cost_data/\"\n",
    "    \"Cluster 13/02_intermediate/\"\n",
    "    \"costs_phase_2_cluster_13_style_Q_itemized.csv\",\n",
    "    char_columns\n",
    ")\n",
    "itemized_addendums = load_data(\n",
    "    \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/\"\n",
    "    \"04_intermediate_scraped_data/phase_2_cost_data/\"\n",
    "    \"Cluster 13/02_intermediate/\"\n",
    "    \"costs_phase_2_cluster_13_style_Q_itemized_addendums.csv\",\n",
    "    char_columns\n",
    ")\n",
    "total = load_data(\n",
    "    \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/\"\n",
    "    \"04_intermediate_scraped_data/phase_2_cost_data/\"\n",
    "    \"Cluster 13/02_intermediate/\"\n",
    "    \"costs_phase_2_cluster_13_style_Q_total.csv\",\n",
    "    char_columns\n",
    ")\n",
    "total_addendums = load_data(\n",
    "    \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/\"\n",
    "    \"04_intermediate_scraped_data/phase_2_cost_data/\"\n",
    "    \"Cluster 13/02_intermediate/\"\n",
    "    \"costs_phase_2_cluster_13_style_Q_total_addendums.csv\",\n",
    "    char_columns\n",
    ")\n",
    "\n",
    "updated_itemized, updated_total = merge_with_addendums(\n",
    "    itemized, itemized_addendums, total, total_addendums\n",
    ")\n",
    "\n",
    "# drop unwanted columns\n",
    "to_drop = [\n",
    "    \"upgrade_classification\",\"estimated\",\"caiso_queue\",\n",
    "    \"project_type\",\"dependent_system_upgrade\"\n",
    "]\n",
    "updated_itemized = updated_itemized.drop(columns=[c for c in to_drop if c in updated_itemized], errors='ignore')\n",
    "updated_total   = updated_total.drop(columns=[c for c in to_drop if c in updated_total],   errors='ignore')\n",
    "\n",
    "# fill & sort\n",
    "fill_cols = [\n",
    "    \"point_of_interconnection\",\"latitude\",\"longitude\",\n",
    "    \"req_deliverability\",\"capacity\"\n",
    "]\n",
    "for df in (updated_itemized, updated_total):\n",
    "    for c in fill_cols:\n",
    "        df[c] = df[c].replace('', np.nan)\n",
    "    df.sort_values('q_id', kind='stable', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    for c in fill_cols:\n",
    "        df[c] = df.groupby('q_id')[c].apply(lambda g: g.ffill().bfill()).reset_index(drop=True)\n",
    "    for c in fill_cols:\n",
    "        df[c].replace(np.nan, '', inplace=True)\n",
    "\n",
    "# save\n",
    "save_data(\n",
    "    updated_itemized,\n",
    "    \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/\"\n",
    "    \"04_intermediate_scraped_data/phase_2_cost_data/\"\n",
    "    \"Cluster 13/01_clean/\"\n",
    "    \"costs_phase_2_cluster_13_style_Q_itemized_updated.csv\",\n",
    "    char_columns\n",
    ")\n",
    "save_data(\n",
    "    updated_total,\n",
    "    \"/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/\"\n",
    "    \"04_intermediate_scraped_data/phase_2_cost_data/\"\n",
    "    \"Cluster 13/01_clean/\"\n",
    "    \"costs_phase_2_cluster_13_style_Q_total_updated.csv\",\n",
    "    char_columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded itemized data from /Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_itemized_updated.csv\n",
      "Loaded totals data from /Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_total_updated.csv\n",
      "\n",
      "Q_ids with missing upgrades:\n",
      "  Q_id 1683 is missing upgrades: ADNU\n",
      "  Q_id 1687 is missing upgrades: ADNU\n",
      "  Q_id 1688 is missing upgrades: ADNU\n",
      "  Q_id 1690 is missing upgrades: ADNU\n",
      "  Q_id 1691 is missing upgrades: ADNU\n",
      "  Q_id 1695 is missing upgrades: ADNU\n",
      "  Q_id 1700 is missing upgrades: ADNU\n",
      "  Q_id 1702 is missing upgrades: ADNU\n",
      "  Q_id 1705 is missing upgrades: ADNU\n",
      "  Q_id 1709 is missing upgrades: ADNU\n",
      "  Q_id 1713 is missing upgrades: ADNU\n",
      "  Q_id 1718 is missing upgrades: LDNU, ADNU, CANU, LOPNU\n",
      "  Q_id 1728 is missing upgrades: ADNU\n",
      "  Q_id 1736 is missing upgrades: ADNU\n",
      "  Q_id 1739 is missing upgrades: ADNU\n",
      "  Q_id 1740 is missing upgrades: ADNU\n",
      "  Q_id 1744 is missing upgrades: ADNU\n",
      "  Q_id 1745 is missing upgrades: ADNU\n",
      "  Q_id 1750 is missing upgrades: ADNU\n",
      "  Q_id 1751 is missing upgrades: ADNU\n",
      "\n",
      "Duplicate upgrade types detected:\n",
      "  Q_id 1728 has repeated upgrade types: RNU\n",
      "Mismatch: Q_id 1736, Upgrade 'RNU' - Manual Total: 5047.0, Reported Total: 7993.0\n",
      "\n",
      "Mismatches saved to '/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/ph2_mismatches.csv'.\n",
      "\n",
      "Direct Matches (Exact Point of Interconnection Names):\n",
      "   point_of_interconnection          q_id\n",
      "0           ARCO SUBSTATION  [1736, 1740]\n",
      "10        MIDWAY SUBSTATION  [1745, 1751]\n",
      "\n",
      "Fuzzy Matches (>=80% Similarity in Point of Interconnection):\n",
      "          point_of_interconnection_1       q_ids_1 point_of_interconnection_2  \\\n",
      "0   ROUND MOUNTAIN SUBSTATION 230 KV        [1688]            ARCO SUBSTATION   \n",
      "1           VIERRA SUBSTATION 115 KV        [1690]            ARCO SUBSTATION   \n",
      "2           BIRDS LANDING SUBSTATION        [1691]            ARCO SUBSTATION   \n",
      "3                ATLANTIC SUBSTATION        [1695]          LAMONT SUBSTATION   \n",
      "4                ATLANTIC SUBSTATION        [1695]           TESLA SUBSTATION   \n",
      "5                ATLANTIC SUBSTATION        [1695]            ARCO SUBSTATION   \n",
      "6               LAKEVILLE SUBSTATION        [1700]            ARCO SUBSTATION   \n",
      "7                   TESLA SUBSTATION        [1702]            ARCO SUBSTATION   \n",
      "8               PITTSBURG SUBSTATION        [1705]            ARCO SUBSTATION   \n",
      "9                    ARCO SUBSTATION  [1736, 1740]          LAMONT SUBSTATION   \n",
      "10                   ARCO SUBSTATION  [1736, 1740]       MORRO BAY SUBSTATION   \n",
      "11                   ARCO SUBSTATION  [1736, 1740]          MIDWAY SUBSTATION   \n",
      "\n",
      "         q_ids_2  similarity_score  \n",
      "0   [1736, 1740]                80  \n",
      "1   [1736, 1740]                80  \n",
      "2   [1736, 1740]                80  \n",
      "3         [1744]                83  \n",
      "4         [1702]                80  \n",
      "5   [1736, 1740]                80  \n",
      "6   [1736, 1740]                80  \n",
      "7   [1736, 1740]                80  \n",
      "8   [1736, 1740]                80  \n",
      "9         [1744]                81  \n",
      "10        [1739]                80  \n",
      "11  [1745, 1751]                80  \n",
      "Matched Q_ids saved to '/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/ph2_matched_qids.csv'.\n",
      "\n",
      "Total checks performed: 97\n",
      "Total mismatches found: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# ---------------------- Configuration ---------------------- #\n",
    "\n",
    "# Paths to the CSV files\n",
    "ITEMIZED_CSV_PATH = '/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_itemized_updated.csv'\n",
    "TOTALS_CSV_PATH = '/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/01_clean/costs_phase_2_cluster_13_style_Q_total_updated.csv'\n",
    "\n",
    "# Columns in totals_df that hold the reported total costs\n",
    "TOTALS_ESTIMATED_COLUMN = 'estimated_cost_x_1000'\n",
    "TOTALS_ESCALATED_COLUMN = 'escalated_cost_x_1000'\n",
    "\n",
    "# Upgrade types to check\n",
    "REQUIRED_UPGRADES = ['PTO_IF', 'RNU', 'LDNU', 'ADNU', 'CANU', \"LOPNU\"]\n",
    "\n",
    "# Output paths\n",
    "MISMATCHES_CSV_PATH = '/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/ph2_mismatches.csv'\n",
    "MATCHED_QIDS_CSV_PATH = '/Users/vk365/Dropbox/Interconnections_data/data/ic_studies/raw/04_intermediate_scraped_data/phase_2_cost_data/Cluster 13/ph2_matched_qids.csv'\n",
    "\n",
    "# ---------------------- Load Data ---------------------- #\n",
    "\n",
    "def load_csv(path, dataset_name):\n",
    "    \"\"\"\n",
    "    Loads a CSV file into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"Loaded {dataset_name} from {path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {path}\")\n",
    "        exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset_name}: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "# Load datasets\n",
    "itemized_df = load_csv(ITEMIZED_CSV_PATH, \"itemized data\")\n",
    "totals_df = load_csv(TOTALS_CSV_PATH, \"totals data\")\n",
    "\n",
    "# ---------------------- Data Cleaning ---------------------- #\n",
    "\n",
    "def clean_text(df, column):\n",
    "    \"\"\"\n",
    "    Cleans text data by stripping leading/trailing spaces and converting to uppercase.\n",
    "    \"\"\"\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].astype(str).str.strip().str.upper()\n",
    "    else:\n",
    "        print(f\"Warning: '{column}' column is missing in the dataset. Filling with 'UNKNOWN'.\")\n",
    "        df[column] = 'UNKNOWN'\n",
    "    return df\n",
    "\n",
    "# Clean 'type_of_upgrade' and 'point_of_interconnection' in both datasets\n",
    "itemized_df = clean_text(itemized_df, 'type_of_upgrade')\n",
    "itemized_df = clean_text(itemized_df, 'point_of_interconnection')\n",
    "\n",
    "totals_df = clean_text(totals_df, 'type_of_upgrade')\n",
    "totals_df = clean_text(totals_df, 'point_of_interconnection')\n",
    "\n",
    "# ---------------------- Data Preparation ---------------------- #\n",
    "\n",
    "# Ensure necessary columns exist in itemized_df\n",
    "required_itemized_columns = ['q_id', 'type_of_upgrade', 'point_of_interconnection', 'estimated_cost_x_1000', 'escalated_cost_x_1000']\n",
    "for col in required_itemized_columns:\n",
    "    if col not in itemized_df.columns:\n",
    "        print(f\"Warning: '{col}' column is missing in the itemized dataset.\")\n",
    "        if col in ['q_id', 'type_of_upgrade', 'point_of_interconnection']:\n",
    "            itemized_df[col] = 'UNKNOWN'\n",
    "        else:\n",
    "            itemized_df[col] = 0\n",
    "\n",
    "# Ensure necessary columns exist in totals_df\n",
    "required_totals_columns = ['q_id', 'type_of_upgrade', 'point_of_interconnection', TOTALS_ESTIMATED_COLUMN, TOTALS_ESCALATED_COLUMN]\n",
    "for col in required_totals_columns:\n",
    "    if col not in totals_df.columns:\n",
    "        print(f\"Error: '{col}' column is missing in the totals dataset. Cannot proceed.\")\n",
    "        exit(1)\n",
    "\n",
    "# Convert cost columns to numeric, coercing errors to NaN and filling with 0\n",
    "cost_columns_itemized = ['estimated_cost_x_1000', 'escalated_cost_x_1000']\n",
    "for col in cost_columns_itemized:\n",
    "    itemized_df[col] = pd.to_numeric(itemized_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "cost_columns_totals = [TOTALS_ESTIMATED_COLUMN, TOTALS_ESCALATED_COLUMN]\n",
    "for col in cost_columns_totals:\n",
    "    totals_df[col] = pd.to_numeric(totals_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# ---------------------- Calculate Manual Totals ---------------------- #\n",
    "\n",
    "# Group itemized data by q_id and type_of_upgrade and calculate sums\n",
    "itemized_grouped = itemized_df.groupby(['q_id', 'type_of_upgrade']).agg({\n",
    "    'estimated_cost_x_1000': 'sum',\n",
    "    'escalated_cost_x_1000': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Apply preference: Use estimated_cost_x_1000 if sum > 0, else use escalated_cost_x_1000\n",
    "itemized_grouped['manual_total'] = itemized_grouped.apply(\n",
    "    lambda row: row['estimated_cost_x_1000'] if row['estimated_cost_x_1000'] > 0 else row['escalated_cost_x_1000'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ---------------------- Prepare Totals Data ---------------------- #\n",
    "\n",
    "# Group totals data by q_id and type_of_upgrade and calculate sums\n",
    "totals_grouped = totals_df.groupby(['q_id', 'type_of_upgrade']).agg({\n",
    "    TOTALS_ESTIMATED_COLUMN: 'sum',\n",
    "    TOTALS_ESCALATED_COLUMN: 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Apply preference: Use estimated_cost_x_1000 if sum > 0, else use escalated_cost_x_1000\n",
    "totals_grouped['reported_total'] = totals_grouped.apply(\n",
    "    lambda row: row[TOTALS_ESTIMATED_COLUMN] if row[TOTALS_ESTIMATED_COLUMN] > 0 else row[TOTALS_ESCALATED_COLUMN],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ---------------------- Merge Data ---------------------- #\n",
    "\n",
    "# Merge the itemized and totals data on q_id and type_of_upgrade\n",
    "comparison_df = pd.merge(\n",
    "    itemized_grouped,\n",
    "    totals_grouped[['q_id', 'type_of_upgrade', 'reported_total']],\n",
    "    on=['q_id', 'type_of_upgrade'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ---------------------- Check for Missing Upgrades ---------------------- #\n",
    "\n",
    "# Identify q_ids that are missing any of the required upgrades\n",
    "missing_upgrades_report = []\n",
    "for q_id in comparison_df['q_id'].unique():\n",
    "    upgrades_present = comparison_df[comparison_df['q_id'] == q_id]['type_of_upgrade'].unique()\n",
    "    missing_upgrades = [upgrade for upgrade in REQUIRED_UPGRADES if upgrade not in upgrades_present]\n",
    "    if missing_upgrades:\n",
    "        missing_upgrades_report.append((q_id, missing_upgrades))\n",
    "\n",
    "# Report missing upgrades\n",
    "if missing_upgrades_report:\n",
    "    print(\"\\nQ_ids with missing upgrades:\")\n",
    "    for q_id, missing in missing_upgrades_report:\n",
    "        print(f\"  Q_id {q_id} is missing upgrades: {', '.join(missing)}\")\n",
    "else:\n",
    "    print(\"\\nAll q_ids have all required upgrades.\")\n",
    "\n",
    "\n",
    "# ------------------------ Check for no duplicates in type of upgrade in total data ------------------------ #\n",
    "\n",
    " \n",
    "\n",
    "# Identify duplicates by grouping by q_id and type_of_upgrade\n",
    "duplicates = totals_df[totals_df.duplicated(subset=['q_id', 'type_of_upgrade'], keep=False)]\n",
    "\n",
    "if not duplicates.empty:\n",
    "    print(\"\\nDuplicate upgrade types detected:\")\n",
    "    for q_id, group in duplicates.groupby('q_id'):\n",
    "        upgrade_types = group['type_of_upgrade'].unique()\n",
    "        print(f\"  Q_id {q_id} has repeated upgrade types: {', '.join(upgrade_types)}\")\n",
    "else:\n",
    "    print(\"\\nNo type of upgrade is repeated for any Q_id.\")        \n",
    "\n",
    "# ---------------------- Compare Totals and Identify Mismatches ---------------------- #\n",
    "\n",
    "# Initialize list to store mismatches\n",
    "mismatches = []\n",
    "\n",
    "# Iterate through each row to compare manual_total with reported_total\n",
    "for index, row in comparison_df.iterrows():\n",
    "    q_id = row['q_id']\n",
    "    upgrade = row['type_of_upgrade']\n",
    "    manual_total = row['manual_total']\n",
    "    reported_total = row['reported_total']\n",
    "    \n",
    "    # Determine if both manual_total and reported_total are zero\n",
    "    if manual_total == 0.0 and reported_total == 0.0:\n",
    "        continue  # No mismatch\n",
    "    # Determine if manual_total is zero and reported_total is missing or zero\n",
    "    elif manual_total == 0.0 and (pd.isna(row['reported_total']) or reported_total == 0.0):\n",
    "        continue  # No mismatch\n",
    "    # If reported_total is missing (NaN) and manual_total is not zero\n",
    "    elif pd.isna(row['reported_total']) and manual_total != 0.0:\n",
    "        print(f\"Mismatch: Q_id {q_id}, Upgrade '{upgrade}' - Manual Total: {manual_total}, Reported Total: Missing\")\n",
    "        mismatches.append({\n",
    "            'q_id': q_id,\n",
    "            'type_of_upgrade': upgrade,\n",
    "            'manual_total': manual_total,\n",
    "            'reported_total': 'Missing'\n",
    "        })\n",
    "    # If manual_total is not zero and reported_total is zero\n",
    "    elif manual_total != 0.0 and reported_total == 0.0:\n",
    "        print(f\"Mismatch: Q_id {q_id}, Upgrade '{upgrade}' - Manual Total: {manual_total}, Reported Total: 0.0\")\n",
    "        mismatches.append({\n",
    "            'q_id': q_id,\n",
    "            'type_of_upgrade': upgrade,\n",
    "            'manual_total': manual_total,\n",
    "            'reported_total': reported_total\n",
    "        })\n",
    "    # If both totals are non-zero but differ beyond tolerance\n",
    "    elif abs(manual_total - reported_total) > 1e+2:\n",
    "        print(f\"Mismatch: Q_id {q_id}, Upgrade '{upgrade}' - Manual Total: {manual_total}, Reported Total: {reported_total}\")\n",
    "        mismatches.append({\n",
    "            'q_id': q_id,\n",
    "            'type_of_upgrade': upgrade,\n",
    "            'manual_total': manual_total,\n",
    "            'reported_total': reported_total\n",
    "        })\n",
    "    # Else, totals match; do nothing\n",
    "\n",
    "# Create a DataFrame for mismatches\n",
    "mismatches_df = pd.DataFrame(mismatches, columns=['q_id', 'type_of_upgrade', 'manual_total', 'reported_total'])\n",
    "\n",
    "# Save mismatches to a CSV file\n",
    "try:\n",
    "    mismatches_df.to_csv(MISMATCHES_CSV_PATH, index=False)\n",
    "    print(f\"\\nMismatches saved to '{MISMATCHES_CSV_PATH}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving mismatches CSV: {e}\")\n",
    "\n",
    "# ---------------------- Point of Interconnection Matching ---------------------- #\n",
    "\n",
    "# Extract unique q_id and point_of_interconnection from itemized dataset\n",
    "itemized_poi = itemized_df[['q_id', 'point_of_interconnection']].drop_duplicates()\n",
    "\n",
    "# Extract unique q_id and point_of_interconnection from totals dataset\n",
    "totals_poi = totals_df[['q_id', 'point_of_interconnection']].drop_duplicates()\n",
    "\n",
    "# Merge both to have a complete list of q_id and point_of_interconnection\n",
    "all_poi = pd.concat([itemized_poi, totals_poi]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ---------------------- Direct Match Identification ---------------------- #\n",
    "\n",
    "# Group by point_of_interconnection to find q_ids sharing the same point_of_interconnection\n",
    "direct_matches = all_poi.groupby('point_of_interconnection')['q_id'].apply(list).reset_index()\n",
    "\n",
    "# Filter groups with more than one q_id (i.e., shared points_of_interconnection)\n",
    "direct_matches = direct_matches[direct_matches['q_id'].apply(len) > 1]\n",
    "\n",
    "print(\"\\nDirect Matches (Exact Point of Interconnection Names):\")\n",
    "if not direct_matches.empty:\n",
    "    print(direct_matches)\n",
    "else:\n",
    "    print(\"No direct matches found.\")\n",
    "\n",
    "# ---------------------- Fuzzy Match Identification ---------------------- #\n",
    "\n",
    "# Prepare list of points_of_interconnection for fuzzy matching\n",
    "poi_list = all_poi['point_of_interconnection'].unique().tolist()\n",
    "\n",
    "# Initialize list to store fuzzy matches\n",
    "fuzzy_matches = []\n",
    "\n",
    "# Iterate through each point_of_interconnection to find similar ones\n",
    "for i, poi in enumerate(poi_list):\n",
    "    # Compare with the rest of the points to avoid redundant comparisons\n",
    "    similar_pois = process.extract(poi, poi_list[i+1:], scorer=fuzz.token_set_ratio)\n",
    "    \n",
    "    # Filter matches with similarity >= 80%\n",
    "    for match_poi, score in similar_pois:\n",
    "        if score >= 80:\n",
    "            # Retrieve q_ids for both points_of_interconnection\n",
    "            qids_poi1 = all_poi[all_poi['point_of_interconnection'] == poi]['q_id'].tolist()\n",
    "            qids_poi2 = all_poi[all_poi['point_of_interconnection'] == match_poi]['q_id'].tolist()\n",
    "            \n",
    "            # Append the matched pairs with their points_of_interconnection and similarity score\n",
    "            fuzzy_matches.append({\n",
    "                'point_of_interconnection_1': poi,\n",
    "                'q_ids_1': qids_poi1,\n",
    "                'point_of_interconnection_2': match_poi,\n",
    "                'q_ids_2': qids_poi2,\n",
    "                'similarity_score': score\n",
    "            })\n",
    "\n",
    "# Convert fuzzy matches to DataFrame\n",
    "fuzzy_matches_df = pd.DataFrame(fuzzy_matches)\n",
    "\n",
    "print(\"\\nFuzzy Matches (>=80% Similarity in Point of Interconnection):\")\n",
    "if not fuzzy_matches_df.empty:\n",
    "    print(fuzzy_matches_df)\n",
    "else:\n",
    "    print(\"No fuzzy matches found.\")\n",
    "\n",
    "# ---------------------- Save Matched Q_ids to CSV ---------------------- #\n",
    "\n",
    "# For clarity, create a combined DataFrame for direct and fuzzy matches\n",
    "\n",
    "# Direct matches: list each pair of q_ids sharing the same point_of_interconnection\n",
    "direct_matches_expanded = []\n",
    "for _, row in direct_matches.iterrows():\n",
    "    qids = row['q_id']\n",
    "    poi = row['point_of_interconnection']\n",
    "    # Generate all possible unique pairs\n",
    "    for i in range(len(qids)):\n",
    "        for j in range(i+1, len(qids)):\n",
    "            direct_matches_expanded.append({\n",
    "                'match_type': 'Direct',\n",
    "                'point_of_interconnection_1': poi,\n",
    "                'q_id_1': qids[i],\n",
    "                'point_of_interconnection_2': poi,\n",
    "                'q_id_2': qids[j],\n",
    "                'similarity_score': 100\n",
    "            })\n",
    "\n",
    "# Fuzzy matches: already have pairs\n",
    "fuzzy_matches_expanded = []\n",
    "for _, row in fuzzy_matches_df.iterrows():\n",
    "    fuzzy_matches_expanded.append({\n",
    "        'match_type': 'Fuzzy',\n",
    "        'point_of_interconnection_1': row['point_of_interconnection_1'],\n",
    "        'q_id_1': row['q_ids_1'],\n",
    "        'point_of_interconnection_2': row['point_of_interconnection_2'],\n",
    "        'q_id_2': row['q_ids_2'],\n",
    "        'similarity_score': row['similarity_score']\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "matched_qids_df = pd.DataFrame(direct_matches_expanded + fuzzy_matches_expanded)\n",
    "\n",
    "# Save matched q_ids to CSV\n",
    "try:\n",
    "    matched_qids_df.to_csv(MATCHED_QIDS_CSV_PATH, index=False)\n",
    "    print(f\"Matched Q_ids saved to '{MATCHED_QIDS_CSV_PATH}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving matched Q_ids CSV: {e}\")\n",
    "\n",
    "# ---------------------- Summary ---------------------- #\n",
    "\n",
    "# Print a summary\n",
    "total_checked = len(comparison_df)\n",
    "total_mismatches = len(mismatches_df)\n",
    "print(f\"\\nTotal checks performed: {total_checked}\")\n",
    "print(f\"Total mismatches found: {total_mismatches}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
